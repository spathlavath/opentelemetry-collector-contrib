// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"time"

	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/filter"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
	"go.opentelemetry.io/collector/receiver"
)

var MetricsInfo = metricsInfo{
	NewrelicoracledbPdbCPUUsagePerSecond: metricInfo{
		Name: "newrelicoracledb.pdb.cpu.usage_per_second",
	},
	NewrelicoracledbPdbCPUUsagePerTransaction: metricInfo{
		Name: "newrelicoracledb.pdb.cpu.usage_per_transaction",
	},
	NewrelicoracledbPdbDatabaseCPUTimeRatio: metricInfo{
		Name: "newrelicoracledb.pdb.database.cpu_time_ratio",
	},
	NewrelicoracledbPdbDatabaseWaitTimeRatio: metricInfo{
		Name: "newrelicoracledb.pdb.database.wait_time_ratio",
	},
	NewrelicoracledbPdbExecutionsPerSecond: metricInfo{
		Name: "newrelicoracledb.pdb.executions.per_second",
	},
	NewrelicoracledbPdbExecutionsPerTransaction: metricInfo{
		Name: "newrelicoracledb.pdb.executions.per_transaction",
	},
	NewrelicoracledbPdbNetworkTrafficVolumePerSecond: metricInfo{
		Name: "newrelicoracledb.pdb.network.traffic_volume_per_second",
	},
	NewrelicoracledbPdbPhysicalReadsBytesPerSecond: metricInfo{
		Name: "newrelicoracledb.pdb.physical_reads.bytes_per_second",
	},
	NewrelicoracledbPdbResponseTimeSQLService: metricInfo{
		Name: "newrelicoracledb.pdb.response_time.sql_service",
	},
	NewrelicoracledbPdbSessionsActiveParallel: metricInfo{
		Name: "newrelicoracledb.pdb.sessions.active_parallel",
	},
	NewrelicoracledbPdbSessionsActiveSerial: metricInfo{
		Name: "newrelicoracledb.pdb.sessions.active_serial",
	},
	NewrelicoracledbPdbSessionsAverageActive: metricInfo{
		Name: "newrelicoracledb.pdb.sessions.average_active",
	},
	NewrelicoracledbPdbSessionsCount: metricInfo{
		Name: "newrelicoracledb.pdb.sessions.count",
	},
	NewrelicoracledbPdbSessionsCurrentLogons: metricInfo{
		Name: "newrelicoracledb.pdb.sessions.current_logons",
	},
	NewrelicoracledbPdbSessionsCurrentOpenCursors: metricInfo{
		Name: "newrelicoracledb.pdb.sessions.current_open_cursors",
	},
	NewrelicoracledbPdbTransactionsPerSecond: metricInfo{
		Name: "newrelicoracledb.pdb.transactions.per_second",
	},
	NewrelicoracledbRedoLogLogFileSwitch: metricInfo{
		Name: "newrelicoracledb.redo_log.log_file_switch",
	},
	NewrelicoracledbRedoLogLogFileSwitchArchivingNeeded: metricInfo{
		Name: "newrelicoracledb.redo_log.log_file_switch_archiving_needed",
	},
	NewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete: metricInfo{
		Name: "newrelicoracledb.redo_log.log_file_switch_checkpoint_incomplete",
	},
	NewrelicoracledbRedoLogWaits: metricInfo{
		Name: "newrelicoracledb.redo_log.waits",
	},
	NewrelicoracledbSessionsCount: metricInfo{
		Name: "newrelicoracledb.sessions.count",
	},
	NewrelicoracledbSgaBufferBusyWaits: metricInfo{
		Name: "newrelicoracledb.sga.buffer_busy_waits",
	},
	NewrelicoracledbSgaFreeBufferInspected: metricInfo{
		Name: "newrelicoracledb.sga.free_buffer_inspected",
	},
	NewrelicoracledbSgaFreeBufferWaits: metricInfo{
		Name: "newrelicoracledb.sga.free_buffer_waits",
	},
}

type metricsInfo struct {
	NewrelicoracledbPdbCPUUsagePerSecond                     metricInfo
	NewrelicoracledbPdbCPUUsagePerTransaction                metricInfo
	NewrelicoracledbPdbDatabaseCPUTimeRatio                  metricInfo
	NewrelicoracledbPdbDatabaseWaitTimeRatio                 metricInfo
	NewrelicoracledbPdbExecutionsPerSecond                   metricInfo
	NewrelicoracledbPdbExecutionsPerTransaction              metricInfo
	NewrelicoracledbPdbNetworkTrafficVolumePerSecond         metricInfo
	NewrelicoracledbPdbPhysicalReadsBytesPerSecond           metricInfo
	NewrelicoracledbPdbResponseTimeSQLService                metricInfo
	NewrelicoracledbPdbSessionsActiveParallel                metricInfo
	NewrelicoracledbPdbSessionsActiveSerial                  metricInfo
	NewrelicoracledbPdbSessionsAverageActive                 metricInfo
	NewrelicoracledbPdbSessionsCount                         metricInfo
	NewrelicoracledbPdbSessionsCurrentLogons                 metricInfo
	NewrelicoracledbPdbSessionsCurrentOpenCursors            metricInfo
	NewrelicoracledbPdbTransactionsPerSecond                 metricInfo
	NewrelicoracledbRedoLogLogFileSwitch                     metricInfo
	NewrelicoracledbRedoLogLogFileSwitchArchivingNeeded      metricInfo
	NewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete metricInfo
	NewrelicoracledbRedoLogWaits                             metricInfo
	NewrelicoracledbSessionsCount                            metricInfo
	NewrelicoracledbSgaBufferBusyWaits                       metricInfo
	NewrelicoracledbSgaFreeBufferInspected                   metricInfo
	NewrelicoracledbSgaFreeBufferWaits                       metricInfo
}

type metricInfo struct {
	Name string
}

type metricNewrelicoracledbPdbCPUUsagePerSecond struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.cpu.usage_per_second metric with initial data.
func (m *metricNewrelicoracledbPdbCPUUsagePerSecond) init() {
	m.data.SetName("newrelicoracledb.pdb.cpu.usage_per_second")
	m.data.SetDescription("CPU Usage Per Second in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbCPUUsagePerSecond) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbCPUUsagePerSecond) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbCPUUsagePerSecond) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbCPUUsagePerSecond(cfg MetricConfig) metricNewrelicoracledbPdbCPUUsagePerSecond {
	m := metricNewrelicoracledbPdbCPUUsagePerSecond{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbCPUUsagePerTransaction struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.cpu.usage_per_transaction metric with initial data.
func (m *metricNewrelicoracledbPdbCPUUsagePerTransaction) init() {
	m.data.SetName("newrelicoracledb.pdb.cpu.usage_per_transaction")
	m.data.SetDescription("CPU Usage Per Transaction in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbCPUUsagePerTransaction) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbCPUUsagePerTransaction) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbCPUUsagePerTransaction) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbCPUUsagePerTransaction(cfg MetricConfig) metricNewrelicoracledbPdbCPUUsagePerTransaction {
	m := metricNewrelicoracledbPdbCPUUsagePerTransaction{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbDatabaseCPUTimeRatio struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.database.cpu_time_ratio metric with initial data.
func (m *metricNewrelicoracledbPdbDatabaseCPUTimeRatio) init() {
	m.data.SetName("newrelicoracledb.pdb.database.cpu_time_ratio")
	m.data.SetDescription("Database CPU Time Ratio in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbDatabaseCPUTimeRatio) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbDatabaseCPUTimeRatio) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbDatabaseCPUTimeRatio) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbDatabaseCPUTimeRatio(cfg MetricConfig) metricNewrelicoracledbPdbDatabaseCPUTimeRatio {
	m := metricNewrelicoracledbPdbDatabaseCPUTimeRatio{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbDatabaseWaitTimeRatio struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.database.wait_time_ratio metric with initial data.
func (m *metricNewrelicoracledbPdbDatabaseWaitTimeRatio) init() {
	m.data.SetName("newrelicoracledb.pdb.database.wait_time_ratio")
	m.data.SetDescription("Database Wait Time Ratio in PDB")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbDatabaseWaitTimeRatio) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbDatabaseWaitTimeRatio) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbDatabaseWaitTimeRatio) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbDatabaseWaitTimeRatio(cfg MetricConfig) metricNewrelicoracledbPdbDatabaseWaitTimeRatio {
	m := metricNewrelicoracledbPdbDatabaseWaitTimeRatio{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbExecutionsPerSecond struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.executions.per_second metric with initial data.
func (m *metricNewrelicoracledbPdbExecutionsPerSecond) init() {
	m.data.SetName("newrelicoracledb.pdb.executions.per_second")
	m.data.SetDescription("Executions Per Second in PDB")
	m.data.SetUnit("{executions}/s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbExecutionsPerSecond) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbExecutionsPerSecond) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbExecutionsPerSecond) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbExecutionsPerSecond(cfg MetricConfig) metricNewrelicoracledbPdbExecutionsPerSecond {
	m := metricNewrelicoracledbPdbExecutionsPerSecond{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbExecutionsPerTransaction struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.executions.per_transaction metric with initial data.
func (m *metricNewrelicoracledbPdbExecutionsPerTransaction) init() {
	m.data.SetName("newrelicoracledb.pdb.executions.per_transaction")
	m.data.SetDescription("Executions Per Transaction in PDB")
	m.data.SetUnit("{executions}/{transaction}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbExecutionsPerTransaction) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbExecutionsPerTransaction) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbExecutionsPerTransaction) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbExecutionsPerTransaction(cfg MetricConfig) metricNewrelicoracledbPdbExecutionsPerTransaction {
	m := metricNewrelicoracledbPdbExecutionsPerTransaction{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbNetworkTrafficVolumePerSecond struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.network.traffic_volume_per_second metric with initial data.
func (m *metricNewrelicoracledbPdbNetworkTrafficVolumePerSecond) init() {
	m.data.SetName("newrelicoracledb.pdb.network.traffic_volume_per_second")
	m.data.SetDescription("Network Traffic Volume Per Second in PDB")
	m.data.SetUnit("By/s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbNetworkTrafficVolumePerSecond) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbNetworkTrafficVolumePerSecond) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbNetworkTrafficVolumePerSecond) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbNetworkTrafficVolumePerSecond(cfg MetricConfig) metricNewrelicoracledbPdbNetworkTrafficVolumePerSecond {
	m := metricNewrelicoracledbPdbNetworkTrafficVolumePerSecond{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbPhysicalReadsBytesPerSecond struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.physical_reads.bytes_per_second metric with initial data.
func (m *metricNewrelicoracledbPdbPhysicalReadsBytesPerSecond) init() {
	m.data.SetName("newrelicoracledb.pdb.physical_reads.bytes_per_second")
	m.data.SetDescription("Physical Read Total Bytes Per Second in PDB")
	m.data.SetUnit("By/s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbPhysicalReadsBytesPerSecond) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbPhysicalReadsBytesPerSecond) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbPhysicalReadsBytesPerSecond) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbPhysicalReadsBytesPerSecond(cfg MetricConfig) metricNewrelicoracledbPdbPhysicalReadsBytesPerSecond {
	m := metricNewrelicoracledbPdbPhysicalReadsBytesPerSecond{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbResponseTimeSQLService struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.response_time.sql_service metric with initial data.
func (m *metricNewrelicoracledbPdbResponseTimeSQLService) init() {
	m.data.SetName("newrelicoracledb.pdb.response_time.sql_service")
	m.data.SetDescription("SQL Service Response Time in PDB")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbResponseTimeSQLService) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbResponseTimeSQLService) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbResponseTimeSQLService) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbResponseTimeSQLService(cfg MetricConfig) metricNewrelicoracledbPdbResponseTimeSQLService {
	m := metricNewrelicoracledbPdbResponseTimeSQLService{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbSessionsActiveParallel struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.sessions.active_parallel metric with initial data.
func (m *metricNewrelicoracledbPdbSessionsActiveParallel) init() {
	m.data.SetName("newrelicoracledb.pdb.sessions.active_parallel")
	m.data.SetDescription("Active Parallel Sessions in PDB")
	m.data.SetUnit("{sessions}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbSessionsActiveParallel) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbSessionsActiveParallel) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbSessionsActiveParallel) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbSessionsActiveParallel(cfg MetricConfig) metricNewrelicoracledbPdbSessionsActiveParallel {
	m := metricNewrelicoracledbPdbSessionsActiveParallel{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbSessionsActiveSerial struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.sessions.active_serial metric with initial data.
func (m *metricNewrelicoracledbPdbSessionsActiveSerial) init() {
	m.data.SetName("newrelicoracledb.pdb.sessions.active_serial")
	m.data.SetDescription("Active Serial Sessions in PDB")
	m.data.SetUnit("{sessions}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbSessionsActiveSerial) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbSessionsActiveSerial) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbSessionsActiveSerial) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbSessionsActiveSerial(cfg MetricConfig) metricNewrelicoracledbPdbSessionsActiveSerial {
	m := metricNewrelicoracledbPdbSessionsActiveSerial{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbSessionsAverageActive struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.sessions.average_active metric with initial data.
func (m *metricNewrelicoracledbPdbSessionsAverageActive) init() {
	m.data.SetName("newrelicoracledb.pdb.sessions.average_active")
	m.data.SetDescription("Average Active Sessions in PDB")
	m.data.SetUnit("{sessions}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbSessionsAverageActive) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbSessionsAverageActive) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbSessionsAverageActive) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbSessionsAverageActive(cfg MetricConfig) metricNewrelicoracledbPdbSessionsAverageActive {
	m := metricNewrelicoracledbPdbSessionsAverageActive{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbSessionsCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.sessions.count metric with initial data.
func (m *metricNewrelicoracledbPdbSessionsCount) init() {
	m.data.SetName("newrelicoracledb.pdb.sessions.count")
	m.data.SetDescription("Session Count in PDB")
	m.data.SetUnit("{sessions}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbSessionsCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbSessionsCount) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbSessionsCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbSessionsCount(cfg MetricConfig) metricNewrelicoracledbPdbSessionsCount {
	m := metricNewrelicoracledbPdbSessionsCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbSessionsCurrentLogons struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.sessions.current_logons metric with initial data.
func (m *metricNewrelicoracledbPdbSessionsCurrentLogons) init() {
	m.data.SetName("newrelicoracledb.pdb.sessions.current_logons")
	m.data.SetDescription("Current Logons Count in PDB")
	m.data.SetUnit("{logons}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbSessionsCurrentLogons) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbSessionsCurrentLogons) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbSessionsCurrentLogons) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbSessionsCurrentLogons(cfg MetricConfig) metricNewrelicoracledbPdbSessionsCurrentLogons {
	m := metricNewrelicoracledbPdbSessionsCurrentLogons{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbSessionsCurrentOpenCursors struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.sessions.current_open_cursors metric with initial data.
func (m *metricNewrelicoracledbPdbSessionsCurrentOpenCursors) init() {
	m.data.SetName("newrelicoracledb.pdb.sessions.current_open_cursors")
	m.data.SetDescription("Current Open Cursors Count in PDB")
	m.data.SetUnit("{cursors}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbSessionsCurrentOpenCursors) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbSessionsCurrentOpenCursors) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbSessionsCurrentOpenCursors) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbSessionsCurrentOpenCursors(cfg MetricConfig) metricNewrelicoracledbPdbSessionsCurrentOpenCursors {
	m := metricNewrelicoracledbPdbSessionsCurrentOpenCursors{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbPdbTransactionsPerSecond struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.pdb.transactions.per_second metric with initial data.
func (m *metricNewrelicoracledbPdbTransactionsPerSecond) init() {
	m.data.SetName("newrelicoracledb.pdb.transactions.per_second")
	m.data.SetDescription("User Transaction Per Second in PDB")
	m.data.SetUnit("{transactions}/s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbPdbTransactionsPerSecond) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbPdbTransactionsPerSecond) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbPdbTransactionsPerSecond) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbPdbTransactionsPerSecond(cfg MetricConfig) metricNewrelicoracledbPdbTransactionsPerSecond {
	m := metricNewrelicoracledbPdbTransactionsPerSecond{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbRedoLogLogFileSwitch struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.redo_log.log_file_switch metric with initial data.
func (m *metricNewrelicoracledbRedoLogLogFileSwitch) init() {
	m.data.SetName("newrelicoracledb.redo_log.log_file_switch")
	m.data.SetDescription("Log file switch completion waits")
	m.data.SetUnit("{waits}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbRedoLogLogFileSwitch) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbRedoLogLogFileSwitch) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbRedoLogLogFileSwitch) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbRedoLogLogFileSwitch(cfg MetricConfig) metricNewrelicoracledbRedoLogLogFileSwitch {
	m := metricNewrelicoracledbRedoLogLogFileSwitch{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbRedoLogLogFileSwitchArchivingNeeded struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.redo_log.log_file_switch_archiving_needed metric with initial data.
func (m *metricNewrelicoracledbRedoLogLogFileSwitchArchivingNeeded) init() {
	m.data.SetName("newrelicoracledb.redo_log.log_file_switch_archiving_needed")
	m.data.SetDescription("Log file switch (archiving needed) waits")
	m.data.SetUnit("{waits}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbRedoLogLogFileSwitchArchivingNeeded) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbRedoLogLogFileSwitchArchivingNeeded) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbRedoLogLogFileSwitchArchivingNeeded) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbRedoLogLogFileSwitchArchivingNeeded(cfg MetricConfig) metricNewrelicoracledbRedoLogLogFileSwitchArchivingNeeded {
	m := metricNewrelicoracledbRedoLogLogFileSwitchArchivingNeeded{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.redo_log.log_file_switch_checkpoint_incomplete metric with initial data.
func (m *metricNewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete) init() {
	m.data.SetName("newrelicoracledb.redo_log.log_file_switch_checkpoint_incomplete")
	m.data.SetDescription("Log file switch (checkpoint incomplete) waits")
	m.data.SetUnit("{waits}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete(cfg MetricConfig) metricNewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete {
	m := metricNewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbRedoLogWaits struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.redo_log.waits metric with initial data.
func (m *metricNewrelicoracledbRedoLogWaits) init() {
	m.data.SetName("newrelicoracledb.redo_log.waits")
	m.data.SetDescription("Log file parallel write waits")
	m.data.SetUnit("{waits}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbRedoLogWaits) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbRedoLogWaits) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbRedoLogWaits) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbRedoLogWaits(cfg MetricConfig) metricNewrelicoracledbRedoLogWaits {
	m := metricNewrelicoracledbRedoLogWaits{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbSessionsCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.sessions.count metric with initial data.
func (m *metricNewrelicoracledbSessionsCount) init() {
	m.data.SetName("newrelicoracledb.sessions.count")
	m.data.SetDescription("Total number of active Oracle database sessions")
	m.data.SetUnit("{sessions}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbSessionsCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbSessionsCount) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbSessionsCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbSessionsCount(cfg MetricConfig) metricNewrelicoracledbSessionsCount {
	m := metricNewrelicoracledbSessionsCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbSgaBufferBusyWaits struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.sga.buffer_busy_waits metric with initial data.
func (m *metricNewrelicoracledbSgaBufferBusyWaits) init() {
	m.data.SetName("newrelicoracledb.sga.buffer_busy_waits")
	m.data.SetDescription("Buffer busy waits")
	m.data.SetUnit("{waits}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbSgaBufferBusyWaits) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbSgaBufferBusyWaits) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbSgaBufferBusyWaits) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbSgaBufferBusyWaits(cfg MetricConfig) metricNewrelicoracledbSgaBufferBusyWaits {
	m := metricNewrelicoracledbSgaBufferBusyWaits{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbSgaFreeBufferInspected struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.sga.free_buffer_inspected metric with initial data.
func (m *metricNewrelicoracledbSgaFreeBufferInspected) init() {
	m.data.SetName("newrelicoracledb.sga.free_buffer_inspected")
	m.data.SetDescription("Free buffer inspected waits")
	m.data.SetUnit("{waits}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbSgaFreeBufferInspected) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbSgaFreeBufferInspected) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbSgaFreeBufferInspected) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbSgaFreeBufferInspected(cfg MetricConfig) metricNewrelicoracledbSgaFreeBufferInspected {
	m := metricNewrelicoracledbSgaFreeBufferInspected{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbSgaFreeBufferWaits struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.sga.free_buffer_waits metric with initial data.
func (m *metricNewrelicoracledbSgaFreeBufferWaits) init() {
	m.data.SetName("newrelicoracledb.sga.free_buffer_waits")
	m.data.SetDescription("Free buffer waits")
	m.data.SetUnit("{waits}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbSgaFreeBufferWaits) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbSgaFreeBufferWaits) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbSgaFreeBufferWaits) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbSgaFreeBufferWaits(cfg MetricConfig) metricNewrelicoracledbSgaFreeBufferWaits {
	m := metricNewrelicoracledbSgaFreeBufferWaits{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

// MetricsBuilder provides an interface for scrapers to report metrics while taking care of all the transformations
// required to produce metric representation defined in metadata and user config.
type MetricsBuilder struct {
	config                                                         MetricsBuilderConfig // config of the metrics builder.
	startTime                                                      pcommon.Timestamp    // start time that will be applied to all recorded data points.
	metricsCapacity                                                int                  // maximum observed number of metrics per resource.
	metricsBuffer                                                  pmetric.Metrics      // accumulates metrics data before emitting.
	buildInfo                                                      component.BuildInfo  // contains version information.
	resourceAttributeIncludeFilter                                 map[string]filter.Filter
	resourceAttributeExcludeFilter                                 map[string]filter.Filter
	metricNewrelicoracledbPdbCPUUsagePerSecond                     metricNewrelicoracledbPdbCPUUsagePerSecond
	metricNewrelicoracledbPdbCPUUsagePerTransaction                metricNewrelicoracledbPdbCPUUsagePerTransaction
	metricNewrelicoracledbPdbDatabaseCPUTimeRatio                  metricNewrelicoracledbPdbDatabaseCPUTimeRatio
	metricNewrelicoracledbPdbDatabaseWaitTimeRatio                 metricNewrelicoracledbPdbDatabaseWaitTimeRatio
	metricNewrelicoracledbPdbExecutionsPerSecond                   metricNewrelicoracledbPdbExecutionsPerSecond
	metricNewrelicoracledbPdbExecutionsPerTransaction              metricNewrelicoracledbPdbExecutionsPerTransaction
	metricNewrelicoracledbPdbNetworkTrafficVolumePerSecond         metricNewrelicoracledbPdbNetworkTrafficVolumePerSecond
	metricNewrelicoracledbPdbPhysicalReadsBytesPerSecond           metricNewrelicoracledbPdbPhysicalReadsBytesPerSecond
	metricNewrelicoracledbPdbResponseTimeSQLService                metricNewrelicoracledbPdbResponseTimeSQLService
	metricNewrelicoracledbPdbSessionsActiveParallel                metricNewrelicoracledbPdbSessionsActiveParallel
	metricNewrelicoracledbPdbSessionsActiveSerial                  metricNewrelicoracledbPdbSessionsActiveSerial
	metricNewrelicoracledbPdbSessionsAverageActive                 metricNewrelicoracledbPdbSessionsAverageActive
	metricNewrelicoracledbPdbSessionsCount                         metricNewrelicoracledbPdbSessionsCount
	metricNewrelicoracledbPdbSessionsCurrentLogons                 metricNewrelicoracledbPdbSessionsCurrentLogons
	metricNewrelicoracledbPdbSessionsCurrentOpenCursors            metricNewrelicoracledbPdbSessionsCurrentOpenCursors
	metricNewrelicoracledbPdbTransactionsPerSecond                 metricNewrelicoracledbPdbTransactionsPerSecond
	metricNewrelicoracledbRedoLogLogFileSwitch                     metricNewrelicoracledbRedoLogLogFileSwitch
	metricNewrelicoracledbRedoLogLogFileSwitchArchivingNeeded      metricNewrelicoracledbRedoLogLogFileSwitchArchivingNeeded
	metricNewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete metricNewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete
	metricNewrelicoracledbRedoLogWaits                             metricNewrelicoracledbRedoLogWaits
	metricNewrelicoracledbSessionsCount                            metricNewrelicoracledbSessionsCount
	metricNewrelicoracledbSgaBufferBusyWaits                       metricNewrelicoracledbSgaBufferBusyWaits
	metricNewrelicoracledbSgaFreeBufferInspected                   metricNewrelicoracledbSgaFreeBufferInspected
	metricNewrelicoracledbSgaFreeBufferWaits                       metricNewrelicoracledbSgaFreeBufferWaits
}

// MetricBuilderOption applies changes to default metrics builder.
type MetricBuilderOption interface {
	apply(*MetricsBuilder)
}

type metricBuilderOptionFunc func(mb *MetricsBuilder)

func (mbof metricBuilderOptionFunc) apply(mb *MetricsBuilder) {
	mbof(mb)
}

// WithStartTime sets startTime on the metrics builder.
func WithStartTime(startTime pcommon.Timestamp) MetricBuilderOption {
	return metricBuilderOptionFunc(func(mb *MetricsBuilder) {
		mb.startTime = startTime
	})
}
func NewMetricsBuilder(mbc MetricsBuilderConfig, settings receiver.Settings, options ...MetricBuilderOption) *MetricsBuilder {
	mb := &MetricsBuilder{
		config:        mbc,
		startTime:     pcommon.NewTimestampFromTime(time.Now()),
		metricsBuffer: pmetric.NewMetrics(),
		buildInfo:     settings.BuildInfo,
		metricNewrelicoracledbPdbCPUUsagePerSecond:                     newMetricNewrelicoracledbPdbCPUUsagePerSecond(mbc.Metrics.NewrelicoracledbPdbCPUUsagePerSecond),
		metricNewrelicoracledbPdbCPUUsagePerTransaction:                newMetricNewrelicoracledbPdbCPUUsagePerTransaction(mbc.Metrics.NewrelicoracledbPdbCPUUsagePerTransaction),
		metricNewrelicoracledbPdbDatabaseCPUTimeRatio:                  newMetricNewrelicoracledbPdbDatabaseCPUTimeRatio(mbc.Metrics.NewrelicoracledbPdbDatabaseCPUTimeRatio),
		metricNewrelicoracledbPdbDatabaseWaitTimeRatio:                 newMetricNewrelicoracledbPdbDatabaseWaitTimeRatio(mbc.Metrics.NewrelicoracledbPdbDatabaseWaitTimeRatio),
		metricNewrelicoracledbPdbExecutionsPerSecond:                   newMetricNewrelicoracledbPdbExecutionsPerSecond(mbc.Metrics.NewrelicoracledbPdbExecutionsPerSecond),
		metricNewrelicoracledbPdbExecutionsPerTransaction:              newMetricNewrelicoracledbPdbExecutionsPerTransaction(mbc.Metrics.NewrelicoracledbPdbExecutionsPerTransaction),
		metricNewrelicoracledbPdbNetworkTrafficVolumePerSecond:         newMetricNewrelicoracledbPdbNetworkTrafficVolumePerSecond(mbc.Metrics.NewrelicoracledbPdbNetworkTrafficVolumePerSecond),
		metricNewrelicoracledbPdbPhysicalReadsBytesPerSecond:           newMetricNewrelicoracledbPdbPhysicalReadsBytesPerSecond(mbc.Metrics.NewrelicoracledbPdbPhysicalReadsBytesPerSecond),
		metricNewrelicoracledbPdbResponseTimeSQLService:                newMetricNewrelicoracledbPdbResponseTimeSQLService(mbc.Metrics.NewrelicoracledbPdbResponseTimeSQLService),
		metricNewrelicoracledbPdbSessionsActiveParallel:                newMetricNewrelicoracledbPdbSessionsActiveParallel(mbc.Metrics.NewrelicoracledbPdbSessionsActiveParallel),
		metricNewrelicoracledbPdbSessionsActiveSerial:                  newMetricNewrelicoracledbPdbSessionsActiveSerial(mbc.Metrics.NewrelicoracledbPdbSessionsActiveSerial),
		metricNewrelicoracledbPdbSessionsAverageActive:                 newMetricNewrelicoracledbPdbSessionsAverageActive(mbc.Metrics.NewrelicoracledbPdbSessionsAverageActive),
		metricNewrelicoracledbPdbSessionsCount:                         newMetricNewrelicoracledbPdbSessionsCount(mbc.Metrics.NewrelicoracledbPdbSessionsCount),
		metricNewrelicoracledbPdbSessionsCurrentLogons:                 newMetricNewrelicoracledbPdbSessionsCurrentLogons(mbc.Metrics.NewrelicoracledbPdbSessionsCurrentLogons),
		metricNewrelicoracledbPdbSessionsCurrentOpenCursors:            newMetricNewrelicoracledbPdbSessionsCurrentOpenCursors(mbc.Metrics.NewrelicoracledbPdbSessionsCurrentOpenCursors),
		metricNewrelicoracledbPdbTransactionsPerSecond:                 newMetricNewrelicoracledbPdbTransactionsPerSecond(mbc.Metrics.NewrelicoracledbPdbTransactionsPerSecond),
		metricNewrelicoracledbRedoLogLogFileSwitch:                     newMetricNewrelicoracledbRedoLogLogFileSwitch(mbc.Metrics.NewrelicoracledbRedoLogLogFileSwitch),
		metricNewrelicoracledbRedoLogLogFileSwitchArchivingNeeded:      newMetricNewrelicoracledbRedoLogLogFileSwitchArchivingNeeded(mbc.Metrics.NewrelicoracledbRedoLogLogFileSwitchArchivingNeeded),
		metricNewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete: newMetricNewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete(mbc.Metrics.NewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete),
		metricNewrelicoracledbRedoLogWaits:                             newMetricNewrelicoracledbRedoLogWaits(mbc.Metrics.NewrelicoracledbRedoLogWaits),
		metricNewrelicoracledbSessionsCount:                            newMetricNewrelicoracledbSessionsCount(mbc.Metrics.NewrelicoracledbSessionsCount),
		metricNewrelicoracledbSgaBufferBusyWaits:                       newMetricNewrelicoracledbSgaBufferBusyWaits(mbc.Metrics.NewrelicoracledbSgaBufferBusyWaits),
		metricNewrelicoracledbSgaFreeBufferInspected:                   newMetricNewrelicoracledbSgaFreeBufferInspected(mbc.Metrics.NewrelicoracledbSgaFreeBufferInspected),
		metricNewrelicoracledbSgaFreeBufferWaits:                       newMetricNewrelicoracledbSgaFreeBufferWaits(mbc.Metrics.NewrelicoracledbSgaFreeBufferWaits),
		resourceAttributeIncludeFilter:                                 make(map[string]filter.Filter),
		resourceAttributeExcludeFilter:                                 make(map[string]filter.Filter),
	}
	if mbc.ResourceAttributes.HostName.MetricsInclude != nil {
		mb.resourceAttributeIncludeFilter["host.name"] = filter.CreateFilter(mbc.ResourceAttributes.HostName.MetricsInclude)
	}
	if mbc.ResourceAttributes.HostName.MetricsExclude != nil {
		mb.resourceAttributeExcludeFilter["host.name"] = filter.CreateFilter(mbc.ResourceAttributes.HostName.MetricsExclude)
	}
	if mbc.ResourceAttributes.NewrelicoracledbInstanceName.MetricsInclude != nil {
		mb.resourceAttributeIncludeFilter["newrelicoracledb.instance.name"] = filter.CreateFilter(mbc.ResourceAttributes.NewrelicoracledbInstanceName.MetricsInclude)
	}
	if mbc.ResourceAttributes.NewrelicoracledbInstanceName.MetricsExclude != nil {
		mb.resourceAttributeExcludeFilter["newrelicoracledb.instance.name"] = filter.CreateFilter(mbc.ResourceAttributes.NewrelicoracledbInstanceName.MetricsExclude)
	}

	for _, op := range options {
		op.apply(mb)
	}
	return mb
}

// NewResourceBuilder returns a new resource builder that should be used to build a resource associated with for the emitted metrics.
func (mb *MetricsBuilder) NewResourceBuilder() *ResourceBuilder {
	return NewResourceBuilder(mb.config.ResourceAttributes)
}

// updateCapacity updates max length of metrics and resource attributes that will be used for the slice capacity.
func (mb *MetricsBuilder) updateCapacity(rm pmetric.ResourceMetrics) {
	if mb.metricsCapacity < rm.ScopeMetrics().At(0).Metrics().Len() {
		mb.metricsCapacity = rm.ScopeMetrics().At(0).Metrics().Len()
	}
}

// ResourceMetricsOption applies changes to provided resource metrics.
type ResourceMetricsOption interface {
	apply(pmetric.ResourceMetrics)
}

type resourceMetricsOptionFunc func(pmetric.ResourceMetrics)

func (rmof resourceMetricsOptionFunc) apply(rm pmetric.ResourceMetrics) {
	rmof(rm)
}

// WithResource sets the provided resource on the emitted ResourceMetrics.
// It's recommended to use ResourceBuilder to create the resource.
func WithResource(res pcommon.Resource) ResourceMetricsOption {
	return resourceMetricsOptionFunc(func(rm pmetric.ResourceMetrics) {
		res.CopyTo(rm.Resource())
	})
}

// WithStartTimeOverride overrides start time for all the resource metrics data points.
// This option should be only used if different start time has to be set on metrics coming from different resources.
func WithStartTimeOverride(start pcommon.Timestamp) ResourceMetricsOption {
	return resourceMetricsOptionFunc(func(rm pmetric.ResourceMetrics) {
		var dps pmetric.NumberDataPointSlice
		metrics := rm.ScopeMetrics().At(0).Metrics()
		for i := 0; i < metrics.Len(); i++ {
			switch metrics.At(i).Type() {
			case pmetric.MetricTypeGauge:
				dps = metrics.At(i).Gauge().DataPoints()
			case pmetric.MetricTypeSum:
				dps = metrics.At(i).Sum().DataPoints()
			}
			for j := 0; j < dps.Len(); j++ {
				dps.At(j).SetStartTimestamp(start)
			}
		}
	})
}

// EmitForResource saves all the generated metrics under a new resource and updates the internal state to be ready for
// recording another set of data points as part of another resource. This function can be helpful when one scraper
// needs to emit metrics from several resources. Otherwise calling this function is not required,
// just `Emit` function can be called instead.
// Resource attributes should be provided as ResourceMetricsOption arguments.
func (mb *MetricsBuilder) EmitForResource(options ...ResourceMetricsOption) {
	rm := pmetric.NewResourceMetrics()
	ils := rm.ScopeMetrics().AppendEmpty()
	ils.Scope().SetName(ScopeName)
	ils.Scope().SetVersion(mb.buildInfo.Version)
	ils.Metrics().EnsureCapacity(mb.metricsCapacity)
	mb.metricNewrelicoracledbPdbCPUUsagePerSecond.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbCPUUsagePerTransaction.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbDatabaseCPUTimeRatio.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbDatabaseWaitTimeRatio.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbExecutionsPerSecond.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbExecutionsPerTransaction.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbNetworkTrafficVolumePerSecond.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbPhysicalReadsBytesPerSecond.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbResponseTimeSQLService.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbSessionsActiveParallel.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbSessionsActiveSerial.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbSessionsAverageActive.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbSessionsCount.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbSessionsCurrentLogons.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbSessionsCurrentOpenCursors.emit(ils.Metrics())
	mb.metricNewrelicoracledbPdbTransactionsPerSecond.emit(ils.Metrics())
	mb.metricNewrelicoracledbRedoLogLogFileSwitch.emit(ils.Metrics())
	mb.metricNewrelicoracledbRedoLogLogFileSwitchArchivingNeeded.emit(ils.Metrics())
	mb.metricNewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete.emit(ils.Metrics())
	mb.metricNewrelicoracledbRedoLogWaits.emit(ils.Metrics())
	mb.metricNewrelicoracledbSessionsCount.emit(ils.Metrics())
	mb.metricNewrelicoracledbSgaBufferBusyWaits.emit(ils.Metrics())
	mb.metricNewrelicoracledbSgaFreeBufferInspected.emit(ils.Metrics())
	mb.metricNewrelicoracledbSgaFreeBufferWaits.emit(ils.Metrics())

	for _, op := range options {
		op.apply(rm)
	}
	for attr, filter := range mb.resourceAttributeIncludeFilter {
		if val, ok := rm.Resource().Attributes().Get(attr); ok && !filter.Matches(val.AsString()) {
			return
		}
	}
	for attr, filter := range mb.resourceAttributeExcludeFilter {
		if val, ok := rm.Resource().Attributes().Get(attr); ok && filter.Matches(val.AsString()) {
			return
		}
	}

	if ils.Metrics().Len() > 0 {
		mb.updateCapacity(rm)
		rm.MoveTo(mb.metricsBuffer.ResourceMetrics().AppendEmpty())
	}
}

// Emit returns all the metrics accumulated by the metrics builder and updates the internal state to be ready for
// recording another set of metrics. This function will be responsible for applying all the transformations required to
// produce metric representation defined in metadata and user config, e.g. delta or cumulative.
func (mb *MetricsBuilder) Emit(options ...ResourceMetricsOption) pmetric.Metrics {
	mb.EmitForResource(options...)
	metrics := mb.metricsBuffer
	mb.metricsBuffer = pmetric.NewMetrics()
	return metrics
}

// RecordNewrelicoracledbPdbCPUUsagePerSecondDataPoint adds a data point to newrelicoracledb.pdb.cpu.usage_per_second metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbCPUUsagePerSecondDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbCPUUsagePerSecond.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbCPUUsagePerTransactionDataPoint adds a data point to newrelicoracledb.pdb.cpu.usage_per_transaction metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbCPUUsagePerTransactionDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbCPUUsagePerTransaction.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbDatabaseCPUTimeRatioDataPoint adds a data point to newrelicoracledb.pdb.database.cpu_time_ratio metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbDatabaseCPUTimeRatioDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbDatabaseCPUTimeRatio.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbDatabaseWaitTimeRatioDataPoint adds a data point to newrelicoracledb.pdb.database.wait_time_ratio metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbDatabaseWaitTimeRatioDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbDatabaseWaitTimeRatio.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbExecutionsPerSecondDataPoint adds a data point to newrelicoracledb.pdb.executions.per_second metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbExecutionsPerSecondDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbExecutionsPerSecond.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbExecutionsPerTransactionDataPoint adds a data point to newrelicoracledb.pdb.executions.per_transaction metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbExecutionsPerTransactionDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbExecutionsPerTransaction.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbNetworkTrafficVolumePerSecondDataPoint adds a data point to newrelicoracledb.pdb.network.traffic_volume_per_second metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbNetworkTrafficVolumePerSecondDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbNetworkTrafficVolumePerSecond.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbPhysicalReadsBytesPerSecondDataPoint adds a data point to newrelicoracledb.pdb.physical_reads.bytes_per_second metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbPhysicalReadsBytesPerSecondDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbPhysicalReadsBytesPerSecond.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbResponseTimeSQLServiceDataPoint adds a data point to newrelicoracledb.pdb.response_time.sql_service metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbResponseTimeSQLServiceDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbResponseTimeSQLService.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbSessionsActiveParallelDataPoint adds a data point to newrelicoracledb.pdb.sessions.active_parallel metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbSessionsActiveParallelDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbSessionsActiveParallel.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbSessionsActiveSerialDataPoint adds a data point to newrelicoracledb.pdb.sessions.active_serial metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbSessionsActiveSerialDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbSessionsActiveSerial.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbSessionsAverageActiveDataPoint adds a data point to newrelicoracledb.pdb.sessions.average_active metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbSessionsAverageActiveDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbSessionsAverageActive.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbSessionsCountDataPoint adds a data point to newrelicoracledb.pdb.sessions.count metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbSessionsCountDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbSessionsCount.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbSessionsCurrentLogonsDataPoint adds a data point to newrelicoracledb.pdb.sessions.current_logons metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbSessionsCurrentLogonsDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbSessionsCurrentLogons.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbSessionsCurrentOpenCursorsDataPoint adds a data point to newrelicoracledb.pdb.sessions.current_open_cursors metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbSessionsCurrentOpenCursorsDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbSessionsCurrentOpenCursors.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbPdbTransactionsPerSecondDataPoint adds a data point to newrelicoracledb.pdb.transactions.per_second metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbPdbTransactionsPerSecondDataPoint(ts pcommon.Timestamp, val float64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbPdbTransactionsPerSecond.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbRedoLogLogFileSwitchDataPoint adds a data point to newrelicoracledb.redo_log.log_file_switch metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbRedoLogLogFileSwitchDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbRedoLogLogFileSwitch.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbRedoLogLogFileSwitchArchivingNeededDataPoint adds a data point to newrelicoracledb.redo_log.log_file_switch_archiving_needed metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbRedoLogLogFileSwitchArchivingNeededDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbRedoLogLogFileSwitchArchivingNeeded.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbRedoLogLogFileSwitchCheckpointIncompleteDataPoint adds a data point to newrelicoracledb.redo_log.log_file_switch_checkpoint_incomplete metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbRedoLogLogFileSwitchCheckpointIncompleteDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbRedoLogWaitsDataPoint adds a data point to newrelicoracledb.redo_log.waits metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbRedoLogWaitsDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbRedoLogWaits.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbSessionsCountDataPoint adds a data point to newrelicoracledb.sessions.count metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbSessionsCountDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string) {
	mb.metricNewrelicoracledbSessionsCount.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue)
}

// RecordNewrelicoracledbSgaBufferBusyWaitsDataPoint adds a data point to newrelicoracledb.sga.buffer_busy_waits metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbSgaBufferBusyWaitsDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbSgaBufferBusyWaits.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbSgaFreeBufferInspectedDataPoint adds a data point to newrelicoracledb.sga.free_buffer_inspected metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbSgaFreeBufferInspectedDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbSgaFreeBufferInspected.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbSgaFreeBufferWaitsDataPoint adds a data point to newrelicoracledb.sga.free_buffer_waits metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbSgaFreeBufferWaitsDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbSgaFreeBufferWaits.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// Reset resets metrics builder to its initial state. It should be used when external metrics source is restarted,
// and metrics builder should update its startTime and reset it's internal state accordingly.
func (mb *MetricsBuilder) Reset(options ...MetricBuilderOption) {
	mb.startTime = pcommon.NewTimestampFromTime(time.Now())
	for _, op := range options {
		op.apply(mb)
	}
}
