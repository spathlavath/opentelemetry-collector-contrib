// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"fmt"
	"strconv"
	"time"

	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/filter"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
	"go.opentelemetry.io/collector/receiver"
)

// AttributeCommand specifies the value command attribute.
type AttributeCommand int

const (
	_ AttributeCommand = iota
	AttributeCommandDelete
	AttributeCommandDeleteMulti
	AttributeCommandInsert
	AttributeCommandSelect
	AttributeCommandUpdate
	AttributeCommandUpdateMulti
)

// String returns the string representation of the AttributeCommand.
func (av AttributeCommand) String() string {
	switch av {
	case AttributeCommandDelete:
		return "delete"
	case AttributeCommandDeleteMulti:
		return "delete_multi"
	case AttributeCommandInsert:
		return "insert"
	case AttributeCommandSelect:
		return "select"
	case AttributeCommandUpdate:
		return "update"
	case AttributeCommandUpdateMulti:
		return "update_multi"
	}
	return ""
}

// MapAttributeCommand is a helper map of string to AttributeCommand attribute value.
var MapAttributeCommand = map[string]AttributeCommand{
	"delete":       AttributeCommandDelete,
	"delete_multi": AttributeCommandDeleteMulti,
	"insert":       AttributeCommandInsert,
	"select":       AttributeCommandSelect,
	"update":       AttributeCommandUpdate,
	"update_multi": AttributeCommandUpdateMulti,
}

var MetricsInfo = metricsInfo{
	NewrelicmysqlCommands: metricInfo{
		Name: "newrelicmysql.commands",
	},
	NewrelicmysqlConnectionCount: metricInfo{
		Name: "newrelicmysql.connection.count",
	},
	NewrelicmysqlQueryCount: metricInfo{
		Name: "newrelicmysql.query.count",
	},
	NewrelicmysqlSlowqueryAvgCPUTime: metricInfo{
		Name: "newrelicmysql.slowquery.avg_cpu_time",
	},
	NewrelicmysqlSlowqueryAvgElapsedTime: metricInfo{
		Name: "newrelicmysql.slowquery.avg_elapsed_time",
	},
	NewrelicmysqlSlowqueryAvgLockTime: metricInfo{
		Name: "newrelicmysql.slowquery.avg_lock_time",
	},
	NewrelicmysqlSlowqueryAvgRowsAffected: metricInfo{
		Name: "newrelicmysql.slowquery.avg_rows_affected",
	},
	NewrelicmysqlSlowqueryAvgRowsExamined: metricInfo{
		Name: "newrelicmysql.slowquery.avg_rows_examined",
	},
	NewrelicmysqlSlowqueryAvgRowsSent: metricInfo{
		Name: "newrelicmysql.slowquery.avg_rows_sent",
	},
	NewrelicmysqlSlowqueryExecutionCount: metricInfo{
		Name: "newrelicmysql.slowquery.execution_count",
	},
	NewrelicmysqlSlowqueryIntervalAvgElapsedTime: metricInfo{
		Name: "newrelicmysql.slowquery.interval_avg_elapsed_time",
	},
	NewrelicmysqlSlowqueryIntervalExecutionCount: metricInfo{
		Name: "newrelicmysql.slowquery.interval_execution_count",
	},
	NewrelicmysqlSlowqueryMaxElapsedTime: metricInfo{
		Name: "newrelicmysql.slowquery.max_elapsed_time",
	},
	NewrelicmysqlSlowqueryMinElapsedTime: metricInfo{
		Name: "newrelicmysql.slowquery.min_elapsed_time",
	},
	NewrelicmysqlSlowqueryTotalErrors: metricInfo{
		Name: "newrelicmysql.slowquery.total_errors",
	},
	NewrelicmysqlSlowqueryTotalLockTime: metricInfo{
		Name: "newrelicmysql.slowquery.total_lock_time",
	},
	NewrelicmysqlSlowqueryTotalNoGoodIndexUsed: metricInfo{
		Name: "newrelicmysql.slowquery.total_no_good_index_used",
	},
	NewrelicmysqlSlowqueryTotalNoIndexUsed: metricInfo{
		Name: "newrelicmysql.slowquery.total_no_index_used",
	},
	NewrelicmysqlSlowqueryTotalSelectFullJoin: metricInfo{
		Name: "newrelicmysql.slowquery.total_select_full_join",
	},
	NewrelicmysqlSlowqueryTotalSelectScan: metricInfo{
		Name: "newrelicmysql.slowquery.total_select_scan",
	},
	NewrelicmysqlSlowqueryTotalTmpDiskTables: metricInfo{
		Name: "newrelicmysql.slowquery.total_tmp_disk_tables",
	},
	NewrelicmysqlSlowqueryTotalTmpTables: metricInfo{
		Name: "newrelicmysql.slowquery.total_tmp_tables",
	},
	NewrelicmysqlSlowqueryTotalWarnings: metricInfo{
		Name: "newrelicmysql.slowquery.total_warnings",
	},
	NewrelicmysqlUptime: metricInfo{
		Name: "newrelicmysql.uptime",
	},
}

type metricsInfo struct {
	NewrelicmysqlCommands                        metricInfo
	NewrelicmysqlConnectionCount                 metricInfo
	NewrelicmysqlQueryCount                      metricInfo
	NewrelicmysqlSlowqueryAvgCPUTime             metricInfo
	NewrelicmysqlSlowqueryAvgElapsedTime         metricInfo
	NewrelicmysqlSlowqueryAvgLockTime            metricInfo
	NewrelicmysqlSlowqueryAvgRowsAffected        metricInfo
	NewrelicmysqlSlowqueryAvgRowsExamined        metricInfo
	NewrelicmysqlSlowqueryAvgRowsSent            metricInfo
	NewrelicmysqlSlowqueryExecutionCount         metricInfo
	NewrelicmysqlSlowqueryIntervalAvgElapsedTime metricInfo
	NewrelicmysqlSlowqueryIntervalExecutionCount metricInfo
	NewrelicmysqlSlowqueryMaxElapsedTime         metricInfo
	NewrelicmysqlSlowqueryMinElapsedTime         metricInfo
	NewrelicmysqlSlowqueryTotalErrors            metricInfo
	NewrelicmysqlSlowqueryTotalLockTime          metricInfo
	NewrelicmysqlSlowqueryTotalNoGoodIndexUsed   metricInfo
	NewrelicmysqlSlowqueryTotalNoIndexUsed       metricInfo
	NewrelicmysqlSlowqueryTotalSelectFullJoin    metricInfo
	NewrelicmysqlSlowqueryTotalSelectScan        metricInfo
	NewrelicmysqlSlowqueryTotalTmpDiskTables     metricInfo
	NewrelicmysqlSlowqueryTotalTmpTables         metricInfo
	NewrelicmysqlSlowqueryTotalWarnings          metricInfo
	NewrelicmysqlUptime                          metricInfo
}

type metricInfo struct {
	Name string
}

type metricNewrelicmysqlCommands struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicmysql.commands metric with initial data.
func (m *metricNewrelicmysqlCommands) init() {
	m.data.SetName("newrelicmysql.commands")
	m.data.SetDescription("The number of times each type of command has been executed.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicmysqlCommands) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, commandAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("command", commandAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicmysqlCommands) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicmysqlCommands) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicmysqlCommands(cfg MetricConfig) metricNewrelicmysqlCommands {
	m := metricNewrelicmysqlCommands{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicmysqlConnectionCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicmysql.connection.count metric with initial data.
func (m *metricNewrelicmysqlConnectionCount) init() {
	m.data.SetName("newrelicmysql.connection.count")
	m.data.SetDescription("The number of connection attempts (successful or not) to the MySQL server.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricNewrelicmysqlConnectionCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicmysqlConnectionCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicmysqlConnectionCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicmysqlConnectionCount(cfg MetricConfig) metricNewrelicmysqlConnectionCount {
	m := metricNewrelicmysqlConnectionCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicmysqlQueryCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicmysql.query.count metric with initial data.
func (m *metricNewrelicmysqlQueryCount) init() {
	m.data.SetName("newrelicmysql.query.count")
	m.data.SetDescription("The number of statements executed by the server.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricNewrelicmysqlQueryCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicmysqlQueryCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicmysqlQueryCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicmysqlQueryCount(cfg MetricConfig) metricNewrelicmysqlQueryCount {
	m := metricNewrelicmysqlQueryCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicmysqlSlowqueryAvgCPUTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicmysql.slowquery.avg_cpu_time metric with initial data.
func (m *metricNewrelicmysqlSlowqueryAvgCPUTime) init() {
	m.data.SetName("newrelicmysql.slowquery.avg_cpu_time")
	m.data.SetDescription("Historical average CPU time per query execution.")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicmysqlSlowqueryAvgCPUTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("database_name", databaseNameAttributeValue)
	dp.Attributes().PutStr("query_id", queryIDAttributeValue)
	dp.Attributes().PutStr("query_text", queryTextAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicmysqlSlowqueryAvgCPUTime) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicmysqlSlowqueryAvgCPUTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicmysqlSlowqueryAvgCPUTime(cfg MetricConfig) metricNewrelicmysqlSlowqueryAvgCPUTime {
	m := metricNewrelicmysqlSlowqueryAvgCPUTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicmysqlSlowqueryAvgElapsedTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicmysql.slowquery.avg_elapsed_time metric with initial data.
func (m *metricNewrelicmysqlSlowqueryAvgElapsedTime) init() {
	m.data.SetName("newrelicmysql.slowquery.avg_elapsed_time")
	m.data.SetDescription("Historical average query elapsed time (all-time average since server start).")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicmysqlSlowqueryAvgElapsedTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("database_name", databaseNameAttributeValue)
	dp.Attributes().PutStr("query_id", queryIDAttributeValue)
	dp.Attributes().PutStr("query_text", queryTextAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicmysqlSlowqueryAvgElapsedTime) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicmysqlSlowqueryAvgElapsedTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicmysqlSlowqueryAvgElapsedTime(cfg MetricConfig) metricNewrelicmysqlSlowqueryAvgElapsedTime {
	m := metricNewrelicmysqlSlowqueryAvgElapsedTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicmysqlSlowqueryAvgLockTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicmysql.slowquery.avg_lock_time metric with initial data.
func (m *metricNewrelicmysqlSlowqueryAvgLockTime) init() {
	m.data.SetName("newrelicmysql.slowquery.avg_lock_time")
	m.data.SetDescription("Historical average lock wait time per query execution.")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicmysqlSlowqueryAvgLockTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("database_name", databaseNameAttributeValue)
	dp.Attributes().PutStr("query_id", queryIDAttributeValue)
	dp.Attributes().PutStr("query_text", queryTextAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicmysqlSlowqueryAvgLockTime) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicmysqlSlowqueryAvgLockTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicmysqlSlowqueryAvgLockTime(cfg MetricConfig) metricNewrelicmysqlSlowqueryAvgLockTime {
	m := metricNewrelicmysqlSlowqueryAvgLockTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicmysqlSlowqueryAvgRowsAffected struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicmysql.slowquery.avg_rows_affected metric with initial data.
func (m *metricNewrelicmysqlSlowqueryAvgRowsAffected) init() {
	m.data.SetName("newrelicmysql.slowquery.avg_rows_affected")
	m.data.SetDescription("Average number of rows modified per query execution (INSERT/UPDATE/DELETE).")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicmysqlSlowqueryAvgRowsAffected) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("database_name", databaseNameAttributeValue)
	dp.Attributes().PutStr("query_id", queryIDAttributeValue)
	dp.Attributes().PutStr("query_text", queryTextAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicmysqlSlowqueryAvgRowsAffected) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicmysqlSlowqueryAvgRowsAffected) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicmysqlSlowqueryAvgRowsAffected(cfg MetricConfig) metricNewrelicmysqlSlowqueryAvgRowsAffected {
	m := metricNewrelicmysqlSlowqueryAvgRowsAffected{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicmysqlSlowqueryAvgRowsExamined struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicmysql.slowquery.avg_rows_examined metric with initial data.
func (m *metricNewrelicmysqlSlowqueryAvgRowsExamined) init() {
	m.data.SetName("newrelicmysql.slowquery.avg_rows_examined")
	m.data.SetDescription("Average number of rows examined per query execution.")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicmysqlSlowqueryAvgRowsExamined) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("database_name", databaseNameAttributeValue)
	dp.Attributes().PutStr("query_id", queryIDAttributeValue)
	dp.Attributes().PutStr("query_text", queryTextAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicmysqlSlowqueryAvgRowsExamined) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicmysqlSlowqueryAvgRowsExamined) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicmysqlSlowqueryAvgRowsExamined(cfg MetricConfig) metricNewrelicmysqlSlowqueryAvgRowsExamined {
	m := metricNewrelicmysqlSlowqueryAvgRowsExamined{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicmysqlSlowqueryAvgRowsSent struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicmysql.slowquery.avg_rows_sent metric with initial data.
func (m *metricNewrelicmysqlSlowqueryAvgRowsSent) init() {
	m.data.SetName("newrelicmysql.slowquery.avg_rows_sent")
	m.data.SetDescription("Average number of rows returned per query execution.")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicmysqlSlowqueryAvgRowsSent) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("database_name", databaseNameAttributeValue)
	dp.Attributes().PutStr("query_id", queryIDAttributeValue)
	dp.Attributes().PutStr("query_text", queryTextAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicmysqlSlowqueryAvgRowsSent) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicmysqlSlowqueryAvgRowsSent) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicmysqlSlowqueryAvgRowsSent(cfg MetricConfig) metricNewrelicmysqlSlowqueryAvgRowsSent {
	m := metricNewrelicmysqlSlowqueryAvgRowsSent{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicmysqlSlowqueryExecutionCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicmysql.slowquery.execution_count metric with initial data.
func (m *metricNewrelicmysqlSlowqueryExecutionCount) init() {
	m.data.SetName("newrelicmysql.slowquery.execution_count")
	m.data.SetDescription("Total number of times this query pattern has been executed (cumulative).")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicmysqlSlowqueryExecutionCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("database_name", databaseNameAttributeValue)
	dp.Attributes().PutStr("query_id", queryIDAttributeValue)
	dp.Attributes().PutStr("query_text", queryTextAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicmysqlSlowqueryExecutionCount) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicmysqlSlowqueryExecutionCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicmysqlSlowqueryExecutionCount(cfg MetricConfig) metricNewrelicmysqlSlowqueryExecutionCount {
	m := metricNewrelicmysqlSlowqueryExecutionCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicmysqlSlowqueryIntervalAvgElapsedTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicmysql.slowquery.interval_avg_elapsed_time metric with initial data.
func (m *metricNewrelicmysqlSlowqueryIntervalAvgElapsedTime) init() {
	m.data.SetName("newrelicmysql.slowquery.interval_avg_elapsed_time")
	m.data.SetDescription("Average query elapsed time in the current interval (delta between scrapes). This is the primary metric for Top N selection.")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicmysqlSlowqueryIntervalAvgElapsedTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("database_name", databaseNameAttributeValue)
	dp.Attributes().PutStr("query_id", queryIDAttributeValue)
	dp.Attributes().PutStr("query_text", queryTextAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicmysqlSlowqueryIntervalAvgElapsedTime) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicmysqlSlowqueryIntervalAvgElapsedTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicmysqlSlowqueryIntervalAvgElapsedTime(cfg MetricConfig) metricNewrelicmysqlSlowqueryIntervalAvgElapsedTime {
	m := metricNewrelicmysqlSlowqueryIntervalAvgElapsedTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicmysqlSlowqueryIntervalExecutionCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicmysql.slowquery.interval_execution_count metric with initial data.
func (m *metricNewrelicmysqlSlowqueryIntervalExecutionCount) init() {
	m.data.SetName("newrelicmysql.slowquery.interval_execution_count")
	m.data.SetDescription("Number of query executions in the current interval (delta between scrapes).")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicmysqlSlowqueryIntervalExecutionCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("database_name", databaseNameAttributeValue)
	dp.Attributes().PutStr("query_id", queryIDAttributeValue)
	dp.Attributes().PutStr("query_text", queryTextAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicmysqlSlowqueryIntervalExecutionCount) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicmysqlSlowqueryIntervalExecutionCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicmysqlSlowqueryIntervalExecutionCount(cfg MetricConfig) metricNewrelicmysqlSlowqueryIntervalExecutionCount {
	m := metricNewrelicmysqlSlowqueryIntervalExecutionCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicmysqlSlowqueryMaxElapsedTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicmysql.slowquery.max_elapsed_time metric with initial data.
func (m *metricNewrelicmysqlSlowqueryMaxElapsedTime) init() {
	m.data.SetName("newrelicmysql.slowquery.max_elapsed_time")
	m.data.SetDescription("Maximum (slowest) query execution time observed.")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicmysqlSlowqueryMaxElapsedTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("database_name", databaseNameAttributeValue)
	dp.Attributes().PutStr("query_id", queryIDAttributeValue)
	dp.Attributes().PutStr("query_text", queryTextAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicmysqlSlowqueryMaxElapsedTime) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicmysqlSlowqueryMaxElapsedTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicmysqlSlowqueryMaxElapsedTime(cfg MetricConfig) metricNewrelicmysqlSlowqueryMaxElapsedTime {
	m := metricNewrelicmysqlSlowqueryMaxElapsedTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicmysqlSlowqueryMinElapsedTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicmysql.slowquery.min_elapsed_time metric with initial data.
func (m *metricNewrelicmysqlSlowqueryMinElapsedTime) init() {
	m.data.SetName("newrelicmysql.slowquery.min_elapsed_time")
	m.data.SetDescription("Minimum (fastest) query execution time observed.")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicmysqlSlowqueryMinElapsedTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("database_name", databaseNameAttributeValue)
	dp.Attributes().PutStr("query_id", queryIDAttributeValue)
	dp.Attributes().PutStr("query_text", queryTextAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicmysqlSlowqueryMinElapsedTime) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicmysqlSlowqueryMinElapsedTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicmysqlSlowqueryMinElapsedTime(cfg MetricConfig) metricNewrelicmysqlSlowqueryMinElapsedTime {
	m := metricNewrelicmysqlSlowqueryMinElapsedTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicmysqlSlowqueryTotalErrors struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicmysql.slowquery.total_errors metric with initial data.
func (m *metricNewrelicmysqlSlowqueryTotalErrors) init() {
	m.data.SetName("newrelicmysql.slowquery.total_errors")
	m.data.SetDescription("Total number of errors encountered during query execution. Common causes include syntax errors, constraint violations, and permission issues.")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicmysqlSlowqueryTotalErrors) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("database_name", databaseNameAttributeValue)
	dp.Attributes().PutStr("query_id", queryIDAttributeValue)
	dp.Attributes().PutStr("query_text", queryTextAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicmysqlSlowqueryTotalErrors) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicmysqlSlowqueryTotalErrors) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicmysqlSlowqueryTotalErrors(cfg MetricConfig) metricNewrelicmysqlSlowqueryTotalErrors {
	m := metricNewrelicmysqlSlowqueryTotalErrors{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicmysqlSlowqueryTotalLockTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicmysql.slowquery.total_lock_time metric with initial data.
func (m *metricNewrelicmysqlSlowqueryTotalLockTime) init() {
	m.data.SetName("newrelicmysql.slowquery.total_lock_time")
	m.data.SetDescription("Total cumulative time spent waiting for locks. High value indicates lock contention issues.")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicmysqlSlowqueryTotalLockTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("database_name", databaseNameAttributeValue)
	dp.Attributes().PutStr("query_id", queryIDAttributeValue)
	dp.Attributes().PutStr("query_text", queryTextAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicmysqlSlowqueryTotalLockTime) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicmysqlSlowqueryTotalLockTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicmysqlSlowqueryTotalLockTime(cfg MetricConfig) metricNewrelicmysqlSlowqueryTotalLockTime {
	m := metricNewrelicmysqlSlowqueryTotalLockTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicmysqlSlowqueryTotalNoGoodIndexUsed struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicmysql.slowquery.total_no_good_index_used metric with initial data.
func (m *metricNewrelicmysqlSlowqueryTotalNoGoodIndexUsed) init() {
	m.data.SetName("newrelicmysql.slowquery.total_no_good_index_used")
	m.data.SetDescription("Total number of times MySQL couldn't find a good index to use. Non-zero = YELLOW FLAG.")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicmysqlSlowqueryTotalNoGoodIndexUsed) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("database_name", databaseNameAttributeValue)
	dp.Attributes().PutStr("query_id", queryIDAttributeValue)
	dp.Attributes().PutStr("query_text", queryTextAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicmysqlSlowqueryTotalNoGoodIndexUsed) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicmysqlSlowqueryTotalNoGoodIndexUsed) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicmysqlSlowqueryTotalNoGoodIndexUsed(cfg MetricConfig) metricNewrelicmysqlSlowqueryTotalNoGoodIndexUsed {
	m := metricNewrelicmysqlSlowqueryTotalNoGoodIndexUsed{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicmysqlSlowqueryTotalNoIndexUsed struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicmysql.slowquery.total_no_index_used metric with initial data.
func (m *metricNewrelicmysqlSlowqueryTotalNoIndexUsed) init() {
	m.data.SetName("newrelicmysql.slowquery.total_no_index_used")
	m.data.SetDescription("Total number of queries that performed table scans without using an index. Non-zero = RED FLAG.")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicmysqlSlowqueryTotalNoIndexUsed) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("database_name", databaseNameAttributeValue)
	dp.Attributes().PutStr("query_id", queryIDAttributeValue)
	dp.Attributes().PutStr("query_text", queryTextAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicmysqlSlowqueryTotalNoIndexUsed) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicmysqlSlowqueryTotalNoIndexUsed) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicmysqlSlowqueryTotalNoIndexUsed(cfg MetricConfig) metricNewrelicmysqlSlowqueryTotalNoIndexUsed {
	m := metricNewrelicmysqlSlowqueryTotalNoIndexUsed{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicmysqlSlowqueryTotalSelectFullJoin struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicmysql.slowquery.total_select_full_join metric with initial data.
func (m *metricNewrelicmysqlSlowqueryTotalSelectFullJoin) init() {
	m.data.SetName("newrelicmysql.slowquery.total_select_full_join")
	m.data.SetDescription("Total number of joins without indexes. High value indicates missing join indexes.")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicmysqlSlowqueryTotalSelectFullJoin) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("database_name", databaseNameAttributeValue)
	dp.Attributes().PutStr("query_id", queryIDAttributeValue)
	dp.Attributes().PutStr("query_text", queryTextAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicmysqlSlowqueryTotalSelectFullJoin) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicmysqlSlowqueryTotalSelectFullJoin) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicmysqlSlowqueryTotalSelectFullJoin(cfg MetricConfig) metricNewrelicmysqlSlowqueryTotalSelectFullJoin {
	m := metricNewrelicmysqlSlowqueryTotalSelectFullJoin{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicmysqlSlowqueryTotalSelectScan struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicmysql.slowquery.total_select_scan metric with initial data.
func (m *metricNewrelicmysqlSlowqueryTotalSelectScan) init() {
	m.data.SetName("newrelicmysql.slowquery.total_select_scan")
	m.data.SetDescription("Total number of full table scans performed. High value indicates missing indexes.")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicmysqlSlowqueryTotalSelectScan) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("database_name", databaseNameAttributeValue)
	dp.Attributes().PutStr("query_id", queryIDAttributeValue)
	dp.Attributes().PutStr("query_text", queryTextAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicmysqlSlowqueryTotalSelectScan) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicmysqlSlowqueryTotalSelectScan) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicmysqlSlowqueryTotalSelectScan(cfg MetricConfig) metricNewrelicmysqlSlowqueryTotalSelectScan {
	m := metricNewrelicmysqlSlowqueryTotalSelectScan{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicmysqlSlowqueryTotalTmpDiskTables struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicmysql.slowquery.total_tmp_disk_tables metric with initial data.
func (m *metricNewrelicmysqlSlowqueryTotalTmpDiskTables) init() {
	m.data.SetName("newrelicmysql.slowquery.total_tmp_disk_tables")
	m.data.SetDescription("Total number of temporary tables created on disk (RED FLAG - indicates memory pressure).")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicmysqlSlowqueryTotalTmpDiskTables) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("database_name", databaseNameAttributeValue)
	dp.Attributes().PutStr("query_id", queryIDAttributeValue)
	dp.Attributes().PutStr("query_text", queryTextAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicmysqlSlowqueryTotalTmpDiskTables) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicmysqlSlowqueryTotalTmpDiskTables) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicmysqlSlowqueryTotalTmpDiskTables(cfg MetricConfig) metricNewrelicmysqlSlowqueryTotalTmpDiskTables {
	m := metricNewrelicmysqlSlowqueryTotalTmpDiskTables{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicmysqlSlowqueryTotalTmpTables struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicmysql.slowquery.total_tmp_tables metric with initial data.
func (m *metricNewrelicmysqlSlowqueryTotalTmpTables) init() {
	m.data.SetName("newrelicmysql.slowquery.total_tmp_tables")
	m.data.SetDescription("Total number of temporary tables created.")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicmysqlSlowqueryTotalTmpTables) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("database_name", databaseNameAttributeValue)
	dp.Attributes().PutStr("query_id", queryIDAttributeValue)
	dp.Attributes().PutStr("query_text", queryTextAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicmysqlSlowqueryTotalTmpTables) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicmysqlSlowqueryTotalTmpTables) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicmysqlSlowqueryTotalTmpTables(cfg MetricConfig) metricNewrelicmysqlSlowqueryTotalTmpTables {
	m := metricNewrelicmysqlSlowqueryTotalTmpTables{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicmysqlSlowqueryTotalWarnings struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicmysql.slowquery.total_warnings metric with initial data.
func (m *metricNewrelicmysqlSlowqueryTotalWarnings) init() {
	m.data.SetName("newrelicmysql.slowquery.total_warnings")
	m.data.SetDescription("Total number of warnings generated during query execution. Common causes include type mismatches, truncated data, and deprecated syntax.")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicmysqlSlowqueryTotalWarnings) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("database_name", databaseNameAttributeValue)
	dp.Attributes().PutStr("query_id", queryIDAttributeValue)
	dp.Attributes().PutStr("query_text", queryTextAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicmysqlSlowqueryTotalWarnings) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicmysqlSlowqueryTotalWarnings) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicmysqlSlowqueryTotalWarnings(cfg MetricConfig) metricNewrelicmysqlSlowqueryTotalWarnings {
	m := metricNewrelicmysqlSlowqueryTotalWarnings{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicmysqlUptime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicmysql.uptime metric with initial data.
func (m *metricNewrelicmysqlUptime) init() {
	m.data.SetName("newrelicmysql.uptime")
	m.data.SetDescription("The number of seconds that the server has been up.")
	m.data.SetUnit("s")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricNewrelicmysqlUptime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicmysqlUptime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicmysqlUptime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicmysqlUptime(cfg MetricConfig) metricNewrelicmysqlUptime {
	m := metricNewrelicmysqlUptime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

// MetricsBuilder provides an interface for scrapers to report metrics while taking care of all the transformations
// required to produce metric representation defined in metadata and user config.
type MetricsBuilder struct {
	config                                             MetricsBuilderConfig // config of the metrics builder.
	startTime                                          pcommon.Timestamp    // start time that will be applied to all recorded data points.
	metricsCapacity                                    int                  // maximum observed number of metrics per resource.
	metricsBuffer                                      pmetric.Metrics      // accumulates metrics data before emitting.
	buildInfo                                          component.BuildInfo  // contains version information.
	resourceAttributeIncludeFilter                     map[string]filter.Filter
	resourceAttributeExcludeFilter                     map[string]filter.Filter
	metricNewrelicmysqlCommands                        metricNewrelicmysqlCommands
	metricNewrelicmysqlConnectionCount                 metricNewrelicmysqlConnectionCount
	metricNewrelicmysqlQueryCount                      metricNewrelicmysqlQueryCount
	metricNewrelicmysqlSlowqueryAvgCPUTime             metricNewrelicmysqlSlowqueryAvgCPUTime
	metricNewrelicmysqlSlowqueryAvgElapsedTime         metricNewrelicmysqlSlowqueryAvgElapsedTime
	metricNewrelicmysqlSlowqueryAvgLockTime            metricNewrelicmysqlSlowqueryAvgLockTime
	metricNewrelicmysqlSlowqueryAvgRowsAffected        metricNewrelicmysqlSlowqueryAvgRowsAffected
	metricNewrelicmysqlSlowqueryAvgRowsExamined        metricNewrelicmysqlSlowqueryAvgRowsExamined
	metricNewrelicmysqlSlowqueryAvgRowsSent            metricNewrelicmysqlSlowqueryAvgRowsSent
	metricNewrelicmysqlSlowqueryExecutionCount         metricNewrelicmysqlSlowqueryExecutionCount
	metricNewrelicmysqlSlowqueryIntervalAvgElapsedTime metricNewrelicmysqlSlowqueryIntervalAvgElapsedTime
	metricNewrelicmysqlSlowqueryIntervalExecutionCount metricNewrelicmysqlSlowqueryIntervalExecutionCount
	metricNewrelicmysqlSlowqueryMaxElapsedTime         metricNewrelicmysqlSlowqueryMaxElapsedTime
	metricNewrelicmysqlSlowqueryMinElapsedTime         metricNewrelicmysqlSlowqueryMinElapsedTime
	metricNewrelicmysqlSlowqueryTotalErrors            metricNewrelicmysqlSlowqueryTotalErrors
	metricNewrelicmysqlSlowqueryTotalLockTime          metricNewrelicmysqlSlowqueryTotalLockTime
	metricNewrelicmysqlSlowqueryTotalNoGoodIndexUsed   metricNewrelicmysqlSlowqueryTotalNoGoodIndexUsed
	metricNewrelicmysqlSlowqueryTotalNoIndexUsed       metricNewrelicmysqlSlowqueryTotalNoIndexUsed
	metricNewrelicmysqlSlowqueryTotalSelectFullJoin    metricNewrelicmysqlSlowqueryTotalSelectFullJoin
	metricNewrelicmysqlSlowqueryTotalSelectScan        metricNewrelicmysqlSlowqueryTotalSelectScan
	metricNewrelicmysqlSlowqueryTotalTmpDiskTables     metricNewrelicmysqlSlowqueryTotalTmpDiskTables
	metricNewrelicmysqlSlowqueryTotalTmpTables         metricNewrelicmysqlSlowqueryTotalTmpTables
	metricNewrelicmysqlSlowqueryTotalWarnings          metricNewrelicmysqlSlowqueryTotalWarnings
	metricNewrelicmysqlUptime                          metricNewrelicmysqlUptime
}

// MetricBuilderOption applies changes to default metrics builder.
type MetricBuilderOption interface {
	apply(*MetricsBuilder)
}

type metricBuilderOptionFunc func(mb *MetricsBuilder)

func (mbof metricBuilderOptionFunc) apply(mb *MetricsBuilder) {
	mbof(mb)
}

// WithStartTime sets startTime on the metrics builder.
func WithStartTime(startTime pcommon.Timestamp) MetricBuilderOption {
	return metricBuilderOptionFunc(func(mb *MetricsBuilder) {
		mb.startTime = startTime
	})
}
func NewMetricsBuilder(mbc MetricsBuilderConfig, settings receiver.Settings, options ...MetricBuilderOption) *MetricsBuilder {
	mb := &MetricsBuilder{
		config:                                             mbc,
		startTime:                                          pcommon.NewTimestampFromTime(time.Now()),
		metricsBuffer:                                      pmetric.NewMetrics(),
		buildInfo:                                          settings.BuildInfo,
		metricNewrelicmysqlCommands:                        newMetricNewrelicmysqlCommands(mbc.Metrics.NewrelicmysqlCommands),
		metricNewrelicmysqlConnectionCount:                 newMetricNewrelicmysqlConnectionCount(mbc.Metrics.NewrelicmysqlConnectionCount),
		metricNewrelicmysqlQueryCount:                      newMetricNewrelicmysqlQueryCount(mbc.Metrics.NewrelicmysqlQueryCount),
		metricNewrelicmysqlSlowqueryAvgCPUTime:             newMetricNewrelicmysqlSlowqueryAvgCPUTime(mbc.Metrics.NewrelicmysqlSlowqueryAvgCPUTime),
		metricNewrelicmysqlSlowqueryAvgElapsedTime:         newMetricNewrelicmysqlSlowqueryAvgElapsedTime(mbc.Metrics.NewrelicmysqlSlowqueryAvgElapsedTime),
		metricNewrelicmysqlSlowqueryAvgLockTime:            newMetricNewrelicmysqlSlowqueryAvgLockTime(mbc.Metrics.NewrelicmysqlSlowqueryAvgLockTime),
		metricNewrelicmysqlSlowqueryAvgRowsAffected:        newMetricNewrelicmysqlSlowqueryAvgRowsAffected(mbc.Metrics.NewrelicmysqlSlowqueryAvgRowsAffected),
		metricNewrelicmysqlSlowqueryAvgRowsExamined:        newMetricNewrelicmysqlSlowqueryAvgRowsExamined(mbc.Metrics.NewrelicmysqlSlowqueryAvgRowsExamined),
		metricNewrelicmysqlSlowqueryAvgRowsSent:            newMetricNewrelicmysqlSlowqueryAvgRowsSent(mbc.Metrics.NewrelicmysqlSlowqueryAvgRowsSent),
		metricNewrelicmysqlSlowqueryExecutionCount:         newMetricNewrelicmysqlSlowqueryExecutionCount(mbc.Metrics.NewrelicmysqlSlowqueryExecutionCount),
		metricNewrelicmysqlSlowqueryIntervalAvgElapsedTime: newMetricNewrelicmysqlSlowqueryIntervalAvgElapsedTime(mbc.Metrics.NewrelicmysqlSlowqueryIntervalAvgElapsedTime),
		metricNewrelicmysqlSlowqueryIntervalExecutionCount: newMetricNewrelicmysqlSlowqueryIntervalExecutionCount(mbc.Metrics.NewrelicmysqlSlowqueryIntervalExecutionCount),
		metricNewrelicmysqlSlowqueryMaxElapsedTime:         newMetricNewrelicmysqlSlowqueryMaxElapsedTime(mbc.Metrics.NewrelicmysqlSlowqueryMaxElapsedTime),
		metricNewrelicmysqlSlowqueryMinElapsedTime:         newMetricNewrelicmysqlSlowqueryMinElapsedTime(mbc.Metrics.NewrelicmysqlSlowqueryMinElapsedTime),
		metricNewrelicmysqlSlowqueryTotalErrors:            newMetricNewrelicmysqlSlowqueryTotalErrors(mbc.Metrics.NewrelicmysqlSlowqueryTotalErrors),
		metricNewrelicmysqlSlowqueryTotalLockTime:          newMetricNewrelicmysqlSlowqueryTotalLockTime(mbc.Metrics.NewrelicmysqlSlowqueryTotalLockTime),
		metricNewrelicmysqlSlowqueryTotalNoGoodIndexUsed:   newMetricNewrelicmysqlSlowqueryTotalNoGoodIndexUsed(mbc.Metrics.NewrelicmysqlSlowqueryTotalNoGoodIndexUsed),
		metricNewrelicmysqlSlowqueryTotalNoIndexUsed:       newMetricNewrelicmysqlSlowqueryTotalNoIndexUsed(mbc.Metrics.NewrelicmysqlSlowqueryTotalNoIndexUsed),
		metricNewrelicmysqlSlowqueryTotalSelectFullJoin:    newMetricNewrelicmysqlSlowqueryTotalSelectFullJoin(mbc.Metrics.NewrelicmysqlSlowqueryTotalSelectFullJoin),
		metricNewrelicmysqlSlowqueryTotalSelectScan:        newMetricNewrelicmysqlSlowqueryTotalSelectScan(mbc.Metrics.NewrelicmysqlSlowqueryTotalSelectScan),
		metricNewrelicmysqlSlowqueryTotalTmpDiskTables:     newMetricNewrelicmysqlSlowqueryTotalTmpDiskTables(mbc.Metrics.NewrelicmysqlSlowqueryTotalTmpDiskTables),
		metricNewrelicmysqlSlowqueryTotalTmpTables:         newMetricNewrelicmysqlSlowqueryTotalTmpTables(mbc.Metrics.NewrelicmysqlSlowqueryTotalTmpTables),
		metricNewrelicmysqlSlowqueryTotalWarnings:          newMetricNewrelicmysqlSlowqueryTotalWarnings(mbc.Metrics.NewrelicmysqlSlowqueryTotalWarnings),
		metricNewrelicmysqlUptime:                          newMetricNewrelicmysqlUptime(mbc.Metrics.NewrelicmysqlUptime),
		resourceAttributeIncludeFilter:                     make(map[string]filter.Filter),
		resourceAttributeExcludeFilter:                     make(map[string]filter.Filter),
	}
	if mbc.ResourceAttributes.MysqlInstanceEndpoint.MetricsInclude != nil {
		mb.resourceAttributeIncludeFilter["mysql.instance.endpoint"] = filter.CreateFilter(mbc.ResourceAttributes.MysqlInstanceEndpoint.MetricsInclude)
	}
	if mbc.ResourceAttributes.MysqlInstanceEndpoint.MetricsExclude != nil {
		mb.resourceAttributeExcludeFilter["mysql.instance.endpoint"] = filter.CreateFilter(mbc.ResourceAttributes.MysqlInstanceEndpoint.MetricsExclude)
	}

	for _, op := range options {
		op.apply(mb)
	}
	return mb
}

// NewResourceBuilder returns a new resource builder that should be used to build a resource associated with for the emitted metrics.
func (mb *MetricsBuilder) NewResourceBuilder() *ResourceBuilder {
	return NewResourceBuilder(mb.config.ResourceAttributes)
}

// updateCapacity updates max length of metrics and resource attributes that will be used for the slice capacity.
func (mb *MetricsBuilder) updateCapacity(rm pmetric.ResourceMetrics) {
	if mb.metricsCapacity < rm.ScopeMetrics().At(0).Metrics().Len() {
		mb.metricsCapacity = rm.ScopeMetrics().At(0).Metrics().Len()
	}
}

// ResourceMetricsOption applies changes to provided resource metrics.
type ResourceMetricsOption interface {
	apply(pmetric.ResourceMetrics)
}

type resourceMetricsOptionFunc func(pmetric.ResourceMetrics)

func (rmof resourceMetricsOptionFunc) apply(rm pmetric.ResourceMetrics) {
	rmof(rm)
}

// WithResource sets the provided resource on the emitted ResourceMetrics.
// It's recommended to use ResourceBuilder to create the resource.
func WithResource(res pcommon.Resource) ResourceMetricsOption {
	return resourceMetricsOptionFunc(func(rm pmetric.ResourceMetrics) {
		res.CopyTo(rm.Resource())
	})
}

// WithStartTimeOverride overrides start time for all the resource metrics data points.
// This option should be only used if different start time has to be set on metrics coming from different resources.
func WithStartTimeOverride(start pcommon.Timestamp) ResourceMetricsOption {
	return resourceMetricsOptionFunc(func(rm pmetric.ResourceMetrics) {
		var dps pmetric.NumberDataPointSlice
		metrics := rm.ScopeMetrics().At(0).Metrics()
		for i := 0; i < metrics.Len(); i++ {
			switch metrics.At(i).Type() {
			case pmetric.MetricTypeGauge:
				dps = metrics.At(i).Gauge().DataPoints()
			case pmetric.MetricTypeSum:
				dps = metrics.At(i).Sum().DataPoints()
			}
			for j := 0; j < dps.Len(); j++ {
				dps.At(j).SetStartTimestamp(start)
			}
		}
	})
}

// EmitForResource saves all the generated metrics under a new resource and updates the internal state to be ready for
// recording another set of data points as part of another resource. This function can be helpful when one scraper
// needs to emit metrics from several resources. Otherwise calling this function is not required,
// just `Emit` function can be called instead.
// Resource attributes should be provided as ResourceMetricsOption arguments.
func (mb *MetricsBuilder) EmitForResource(options ...ResourceMetricsOption) {
	rm := pmetric.NewResourceMetrics()
	ils := rm.ScopeMetrics().AppendEmpty()
	ils.Scope().SetName(ScopeName)
	ils.Scope().SetVersion(mb.buildInfo.Version)
	ils.Metrics().EnsureCapacity(mb.metricsCapacity)
	mb.metricNewrelicmysqlCommands.emit(ils.Metrics())
	mb.metricNewrelicmysqlConnectionCount.emit(ils.Metrics())
	mb.metricNewrelicmysqlQueryCount.emit(ils.Metrics())
	mb.metricNewrelicmysqlSlowqueryAvgCPUTime.emit(ils.Metrics())
	mb.metricNewrelicmysqlSlowqueryAvgElapsedTime.emit(ils.Metrics())
	mb.metricNewrelicmysqlSlowqueryAvgLockTime.emit(ils.Metrics())
	mb.metricNewrelicmysqlSlowqueryAvgRowsAffected.emit(ils.Metrics())
	mb.metricNewrelicmysqlSlowqueryAvgRowsExamined.emit(ils.Metrics())
	mb.metricNewrelicmysqlSlowqueryAvgRowsSent.emit(ils.Metrics())
	mb.metricNewrelicmysqlSlowqueryExecutionCount.emit(ils.Metrics())
	mb.metricNewrelicmysqlSlowqueryIntervalAvgElapsedTime.emit(ils.Metrics())
	mb.metricNewrelicmysqlSlowqueryIntervalExecutionCount.emit(ils.Metrics())
	mb.metricNewrelicmysqlSlowqueryMaxElapsedTime.emit(ils.Metrics())
	mb.metricNewrelicmysqlSlowqueryMinElapsedTime.emit(ils.Metrics())
	mb.metricNewrelicmysqlSlowqueryTotalErrors.emit(ils.Metrics())
	mb.metricNewrelicmysqlSlowqueryTotalLockTime.emit(ils.Metrics())
	mb.metricNewrelicmysqlSlowqueryTotalNoGoodIndexUsed.emit(ils.Metrics())
	mb.metricNewrelicmysqlSlowqueryTotalNoIndexUsed.emit(ils.Metrics())
	mb.metricNewrelicmysqlSlowqueryTotalSelectFullJoin.emit(ils.Metrics())
	mb.metricNewrelicmysqlSlowqueryTotalSelectScan.emit(ils.Metrics())
	mb.metricNewrelicmysqlSlowqueryTotalTmpDiskTables.emit(ils.Metrics())
	mb.metricNewrelicmysqlSlowqueryTotalTmpTables.emit(ils.Metrics())
	mb.metricNewrelicmysqlSlowqueryTotalWarnings.emit(ils.Metrics())
	mb.metricNewrelicmysqlUptime.emit(ils.Metrics())

	for _, op := range options {
		op.apply(rm)
	}
	for attr, filter := range mb.resourceAttributeIncludeFilter {
		if val, ok := rm.Resource().Attributes().Get(attr); ok && !filter.Matches(val.AsString()) {
			return
		}
	}
	for attr, filter := range mb.resourceAttributeExcludeFilter {
		if val, ok := rm.Resource().Attributes().Get(attr); ok && filter.Matches(val.AsString()) {
			return
		}
	}

	if ils.Metrics().Len() > 0 {
		mb.updateCapacity(rm)
		rm.MoveTo(mb.metricsBuffer.ResourceMetrics().AppendEmpty())
	}
}

// Emit returns all the metrics accumulated by the metrics builder and updates the internal state to be ready for
// recording another set of metrics. This function will be responsible for applying all the transformations required to
// produce metric representation defined in metadata and user config, e.g. delta or cumulative.
func (mb *MetricsBuilder) Emit(options ...ResourceMetricsOption) pmetric.Metrics {
	mb.EmitForResource(options...)
	metrics := mb.metricsBuffer
	mb.metricsBuffer = pmetric.NewMetrics()
	return metrics
}

// RecordNewrelicmysqlCommandsDataPoint adds a data point to newrelicmysql.commands metric.
func (mb *MetricsBuilder) RecordNewrelicmysqlCommandsDataPoint(ts pcommon.Timestamp, inputVal string, commandAttributeValue AttributeCommand) error {
	val, err := strconv.ParseInt(inputVal, 10, 64)
	if err != nil {
		return fmt.Errorf("failed to parse int64 for NewrelicmysqlCommands, value was %s: %w", inputVal, err)
	}
	mb.metricNewrelicmysqlCommands.recordDataPoint(mb.startTime, ts, val, commandAttributeValue.String())
	return nil
}

// RecordNewrelicmysqlConnectionCountDataPoint adds a data point to newrelicmysql.connection.count metric.
func (mb *MetricsBuilder) RecordNewrelicmysqlConnectionCountDataPoint(ts pcommon.Timestamp, inputVal string) error {
	val, err := strconv.ParseInt(inputVal, 10, 64)
	if err != nil {
		return fmt.Errorf("failed to parse int64 for NewrelicmysqlConnectionCount, value was %s: %w", inputVal, err)
	}
	mb.metricNewrelicmysqlConnectionCount.recordDataPoint(mb.startTime, ts, val)
	return nil
}

// RecordNewrelicmysqlQueryCountDataPoint adds a data point to newrelicmysql.query.count metric.
func (mb *MetricsBuilder) RecordNewrelicmysqlQueryCountDataPoint(ts pcommon.Timestamp, inputVal string) error {
	val, err := strconv.ParseInt(inputVal, 10, 64)
	if err != nil {
		return fmt.Errorf("failed to parse int64 for NewrelicmysqlQueryCount, value was %s: %w", inputVal, err)
	}
	mb.metricNewrelicmysqlQueryCount.recordDataPoint(mb.startTime, ts, val)
	return nil
}

// RecordNewrelicmysqlSlowqueryAvgCPUTimeDataPoint adds a data point to newrelicmysql.slowquery.avg_cpu_time metric.
func (mb *MetricsBuilder) RecordNewrelicmysqlSlowqueryAvgCPUTimeDataPoint(ts pcommon.Timestamp, val float64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	mb.metricNewrelicmysqlSlowqueryAvgCPUTime.recordDataPoint(mb.startTime, ts, val, databaseNameAttributeValue, queryIDAttributeValue, queryTextAttributeValue)
}

// RecordNewrelicmysqlSlowqueryAvgElapsedTimeDataPoint adds a data point to newrelicmysql.slowquery.avg_elapsed_time metric.
func (mb *MetricsBuilder) RecordNewrelicmysqlSlowqueryAvgElapsedTimeDataPoint(ts pcommon.Timestamp, val float64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	mb.metricNewrelicmysqlSlowqueryAvgElapsedTime.recordDataPoint(mb.startTime, ts, val, databaseNameAttributeValue, queryIDAttributeValue, queryTextAttributeValue)
}

// RecordNewrelicmysqlSlowqueryAvgLockTimeDataPoint adds a data point to newrelicmysql.slowquery.avg_lock_time metric.
func (mb *MetricsBuilder) RecordNewrelicmysqlSlowqueryAvgLockTimeDataPoint(ts pcommon.Timestamp, val float64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	mb.metricNewrelicmysqlSlowqueryAvgLockTime.recordDataPoint(mb.startTime, ts, val, databaseNameAttributeValue, queryIDAttributeValue, queryTextAttributeValue)
}

// RecordNewrelicmysqlSlowqueryAvgRowsAffectedDataPoint adds a data point to newrelicmysql.slowquery.avg_rows_affected metric.
func (mb *MetricsBuilder) RecordNewrelicmysqlSlowqueryAvgRowsAffectedDataPoint(ts pcommon.Timestamp, val float64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	mb.metricNewrelicmysqlSlowqueryAvgRowsAffected.recordDataPoint(mb.startTime, ts, val, databaseNameAttributeValue, queryIDAttributeValue, queryTextAttributeValue)
}

// RecordNewrelicmysqlSlowqueryAvgRowsExaminedDataPoint adds a data point to newrelicmysql.slowquery.avg_rows_examined metric.
func (mb *MetricsBuilder) RecordNewrelicmysqlSlowqueryAvgRowsExaminedDataPoint(ts pcommon.Timestamp, val float64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	mb.metricNewrelicmysqlSlowqueryAvgRowsExamined.recordDataPoint(mb.startTime, ts, val, databaseNameAttributeValue, queryIDAttributeValue, queryTextAttributeValue)
}

// RecordNewrelicmysqlSlowqueryAvgRowsSentDataPoint adds a data point to newrelicmysql.slowquery.avg_rows_sent metric.
func (mb *MetricsBuilder) RecordNewrelicmysqlSlowqueryAvgRowsSentDataPoint(ts pcommon.Timestamp, val float64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	mb.metricNewrelicmysqlSlowqueryAvgRowsSent.recordDataPoint(mb.startTime, ts, val, databaseNameAttributeValue, queryIDAttributeValue, queryTextAttributeValue)
}

// RecordNewrelicmysqlSlowqueryExecutionCountDataPoint adds a data point to newrelicmysql.slowquery.execution_count metric.
func (mb *MetricsBuilder) RecordNewrelicmysqlSlowqueryExecutionCountDataPoint(ts pcommon.Timestamp, val int64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	mb.metricNewrelicmysqlSlowqueryExecutionCount.recordDataPoint(mb.startTime, ts, val, databaseNameAttributeValue, queryIDAttributeValue, queryTextAttributeValue)
}

// RecordNewrelicmysqlSlowqueryIntervalAvgElapsedTimeDataPoint adds a data point to newrelicmysql.slowquery.interval_avg_elapsed_time metric.
func (mb *MetricsBuilder) RecordNewrelicmysqlSlowqueryIntervalAvgElapsedTimeDataPoint(ts pcommon.Timestamp, val float64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	mb.metricNewrelicmysqlSlowqueryIntervalAvgElapsedTime.recordDataPoint(mb.startTime, ts, val, databaseNameAttributeValue, queryIDAttributeValue, queryTextAttributeValue)
}

// RecordNewrelicmysqlSlowqueryIntervalExecutionCountDataPoint adds a data point to newrelicmysql.slowquery.interval_execution_count metric.
func (mb *MetricsBuilder) RecordNewrelicmysqlSlowqueryIntervalExecutionCountDataPoint(ts pcommon.Timestamp, val int64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	mb.metricNewrelicmysqlSlowqueryIntervalExecutionCount.recordDataPoint(mb.startTime, ts, val, databaseNameAttributeValue, queryIDAttributeValue, queryTextAttributeValue)
}

// RecordNewrelicmysqlSlowqueryMaxElapsedTimeDataPoint adds a data point to newrelicmysql.slowquery.max_elapsed_time metric.
func (mb *MetricsBuilder) RecordNewrelicmysqlSlowqueryMaxElapsedTimeDataPoint(ts pcommon.Timestamp, val float64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	mb.metricNewrelicmysqlSlowqueryMaxElapsedTime.recordDataPoint(mb.startTime, ts, val, databaseNameAttributeValue, queryIDAttributeValue, queryTextAttributeValue)
}

// RecordNewrelicmysqlSlowqueryMinElapsedTimeDataPoint adds a data point to newrelicmysql.slowquery.min_elapsed_time metric.
func (mb *MetricsBuilder) RecordNewrelicmysqlSlowqueryMinElapsedTimeDataPoint(ts pcommon.Timestamp, val float64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	mb.metricNewrelicmysqlSlowqueryMinElapsedTime.recordDataPoint(mb.startTime, ts, val, databaseNameAttributeValue, queryIDAttributeValue, queryTextAttributeValue)
}

// RecordNewrelicmysqlSlowqueryTotalErrorsDataPoint adds a data point to newrelicmysql.slowquery.total_errors metric.
func (mb *MetricsBuilder) RecordNewrelicmysqlSlowqueryTotalErrorsDataPoint(ts pcommon.Timestamp, val int64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	mb.metricNewrelicmysqlSlowqueryTotalErrors.recordDataPoint(mb.startTime, ts, val, databaseNameAttributeValue, queryIDAttributeValue, queryTextAttributeValue)
}

// RecordNewrelicmysqlSlowqueryTotalLockTimeDataPoint adds a data point to newrelicmysql.slowquery.total_lock_time metric.
func (mb *MetricsBuilder) RecordNewrelicmysqlSlowqueryTotalLockTimeDataPoint(ts pcommon.Timestamp, val float64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	mb.metricNewrelicmysqlSlowqueryTotalLockTime.recordDataPoint(mb.startTime, ts, val, databaseNameAttributeValue, queryIDAttributeValue, queryTextAttributeValue)
}

// RecordNewrelicmysqlSlowqueryTotalNoGoodIndexUsedDataPoint adds a data point to newrelicmysql.slowquery.total_no_good_index_used metric.
func (mb *MetricsBuilder) RecordNewrelicmysqlSlowqueryTotalNoGoodIndexUsedDataPoint(ts pcommon.Timestamp, val int64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	mb.metricNewrelicmysqlSlowqueryTotalNoGoodIndexUsed.recordDataPoint(mb.startTime, ts, val, databaseNameAttributeValue, queryIDAttributeValue, queryTextAttributeValue)
}

// RecordNewrelicmysqlSlowqueryTotalNoIndexUsedDataPoint adds a data point to newrelicmysql.slowquery.total_no_index_used metric.
func (mb *MetricsBuilder) RecordNewrelicmysqlSlowqueryTotalNoIndexUsedDataPoint(ts pcommon.Timestamp, val int64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	mb.metricNewrelicmysqlSlowqueryTotalNoIndexUsed.recordDataPoint(mb.startTime, ts, val, databaseNameAttributeValue, queryIDAttributeValue, queryTextAttributeValue)
}

// RecordNewrelicmysqlSlowqueryTotalSelectFullJoinDataPoint adds a data point to newrelicmysql.slowquery.total_select_full_join metric.
func (mb *MetricsBuilder) RecordNewrelicmysqlSlowqueryTotalSelectFullJoinDataPoint(ts pcommon.Timestamp, val int64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	mb.metricNewrelicmysqlSlowqueryTotalSelectFullJoin.recordDataPoint(mb.startTime, ts, val, databaseNameAttributeValue, queryIDAttributeValue, queryTextAttributeValue)
}

// RecordNewrelicmysqlSlowqueryTotalSelectScanDataPoint adds a data point to newrelicmysql.slowquery.total_select_scan metric.
func (mb *MetricsBuilder) RecordNewrelicmysqlSlowqueryTotalSelectScanDataPoint(ts pcommon.Timestamp, val int64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	mb.metricNewrelicmysqlSlowqueryTotalSelectScan.recordDataPoint(mb.startTime, ts, val, databaseNameAttributeValue, queryIDAttributeValue, queryTextAttributeValue)
}

// RecordNewrelicmysqlSlowqueryTotalTmpDiskTablesDataPoint adds a data point to newrelicmysql.slowquery.total_tmp_disk_tables metric.
func (mb *MetricsBuilder) RecordNewrelicmysqlSlowqueryTotalTmpDiskTablesDataPoint(ts pcommon.Timestamp, val int64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	mb.metricNewrelicmysqlSlowqueryTotalTmpDiskTables.recordDataPoint(mb.startTime, ts, val, databaseNameAttributeValue, queryIDAttributeValue, queryTextAttributeValue)
}

// RecordNewrelicmysqlSlowqueryTotalTmpTablesDataPoint adds a data point to newrelicmysql.slowquery.total_tmp_tables metric.
func (mb *MetricsBuilder) RecordNewrelicmysqlSlowqueryTotalTmpTablesDataPoint(ts pcommon.Timestamp, val int64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	mb.metricNewrelicmysqlSlowqueryTotalTmpTables.recordDataPoint(mb.startTime, ts, val, databaseNameAttributeValue, queryIDAttributeValue, queryTextAttributeValue)
}

// RecordNewrelicmysqlSlowqueryTotalWarningsDataPoint adds a data point to newrelicmysql.slowquery.total_warnings metric.
func (mb *MetricsBuilder) RecordNewrelicmysqlSlowqueryTotalWarningsDataPoint(ts pcommon.Timestamp, val int64, databaseNameAttributeValue string, queryIDAttributeValue string, queryTextAttributeValue string) {
	mb.metricNewrelicmysqlSlowqueryTotalWarnings.recordDataPoint(mb.startTime, ts, val, databaseNameAttributeValue, queryIDAttributeValue, queryTextAttributeValue)
}

// RecordNewrelicmysqlUptimeDataPoint adds a data point to newrelicmysql.uptime metric.
func (mb *MetricsBuilder) RecordNewrelicmysqlUptimeDataPoint(ts pcommon.Timestamp, inputVal string) error {
	val, err := strconv.ParseInt(inputVal, 10, 64)
	if err != nil {
		return fmt.Errorf("failed to parse int64 for NewrelicmysqlUptime, value was %s: %w", inputVal, err)
	}
	mb.metricNewrelicmysqlUptime.recordDataPoint(mb.startTime, ts, val)
	return nil
}

// Reset resets metrics builder to its initial state. It should be used when external metrics source is restarted,
// and metrics builder should update its startTime and reset it's internal state accordingly.
func (mb *MetricsBuilder) Reset(options ...MetricBuilderOption) {
	mb.startTime = pcommon.NewTimestampFromTime(time.Now())
	for _, op := range options {
		op.apply(mb)
	}
}
