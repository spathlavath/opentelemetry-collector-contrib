// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"time"

	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/filter"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
	"go.opentelemetry.io/collector/receiver"
)

// AttributeBufferPoolData specifies the value buffer_pool_data attribute.
type AttributeBufferPoolData int

const (
	_ AttributeBufferPoolData = iota
	AttributeBufferPoolDataDirty
	AttributeBufferPoolDataClean
)

// String returns the string representation of the AttributeBufferPoolData.
func (av AttributeBufferPoolData) String() string {
	switch av {
	case AttributeBufferPoolDataDirty:
		return "dirty"
	case AttributeBufferPoolDataClean:
		return "clean"
	}
	return ""
}

// MapAttributeBufferPoolData is a helper map of string to AttributeBufferPoolData attribute value.
var MapAttributeBufferPoolData = map[string]AttributeBufferPoolData{
	"dirty": AttributeBufferPoolDataDirty,
	"clean": AttributeBufferPoolDataClean,
}

// AttributeBufferPoolOperations specifies the value buffer_pool_operations attribute.
type AttributeBufferPoolOperations int

const (
	_ AttributeBufferPoolOperations = iota
	AttributeBufferPoolOperationsReadAheadRnd
	AttributeBufferPoolOperationsReadAhead
	AttributeBufferPoolOperationsReadAheadEvicted
	AttributeBufferPoolOperationsReadRequests
	AttributeBufferPoolOperationsReads
	AttributeBufferPoolOperationsWaitFree
	AttributeBufferPoolOperationsWriteRequests
)

// String returns the string representation of the AttributeBufferPoolOperations.
func (av AttributeBufferPoolOperations) String() string {
	switch av {
	case AttributeBufferPoolOperationsReadAheadRnd:
		return "read_ahead_rnd"
	case AttributeBufferPoolOperationsReadAhead:
		return "read_ahead"
	case AttributeBufferPoolOperationsReadAheadEvicted:
		return "read_ahead_evicted"
	case AttributeBufferPoolOperationsReadRequests:
		return "read_requests"
	case AttributeBufferPoolOperationsReads:
		return "reads"
	case AttributeBufferPoolOperationsWaitFree:
		return "wait_free"
	case AttributeBufferPoolOperationsWriteRequests:
		return "write_requests"
	}
	return ""
}

// MapAttributeBufferPoolOperations is a helper map of string to AttributeBufferPoolOperations attribute value.
var MapAttributeBufferPoolOperations = map[string]AttributeBufferPoolOperations{
	"read_ahead_rnd":     AttributeBufferPoolOperationsReadAheadRnd,
	"read_ahead":         AttributeBufferPoolOperationsReadAhead,
	"read_ahead_evicted": AttributeBufferPoolOperationsReadAheadEvicted,
	"read_requests":      AttributeBufferPoolOperationsReadRequests,
	"reads":              AttributeBufferPoolOperationsReads,
	"wait_free":          AttributeBufferPoolOperationsWaitFree,
	"write_requests":     AttributeBufferPoolOperationsWriteRequests,
}

// AttributeBufferPoolPages specifies the value buffer_pool_pages attribute.
type AttributeBufferPoolPages int

const (
	_ AttributeBufferPoolPages = iota
	AttributeBufferPoolPagesData
	AttributeBufferPoolPagesFree
	AttributeBufferPoolPagesMisc
)

// String returns the string representation of the AttributeBufferPoolPages.
func (av AttributeBufferPoolPages) String() string {
	switch av {
	case AttributeBufferPoolPagesData:
		return "data"
	case AttributeBufferPoolPagesFree:
		return "free"
	case AttributeBufferPoolPagesMisc:
		return "misc"
	}
	return ""
}

// MapAttributeBufferPoolPages is a helper map of string to AttributeBufferPoolPages attribute value.
var MapAttributeBufferPoolPages = map[string]AttributeBufferPoolPages{
	"data": AttributeBufferPoolPagesData,
	"free": AttributeBufferPoolPagesFree,
	"misc": AttributeBufferPoolPagesMisc,
}

// AttributeCommand specifies the value command attribute.
type AttributeCommand int

const (
	_ AttributeCommand = iota
	AttributeCommandDelete
	AttributeCommandDeleteMulti
	AttributeCommandInsert
	AttributeCommandSelect
	AttributeCommandUpdate
	AttributeCommandUpdateMulti
)

// String returns the string representation of the AttributeCommand.
func (av AttributeCommand) String() string {
	switch av {
	case AttributeCommandDelete:
		return "delete"
	case AttributeCommandDeleteMulti:
		return "delete_multi"
	case AttributeCommandInsert:
		return "insert"
	case AttributeCommandSelect:
		return "select"
	case AttributeCommandUpdate:
		return "update"
	case AttributeCommandUpdateMulti:
		return "update_multi"
	}
	return ""
}

// MapAttributeCommand is a helper map of string to AttributeCommand attribute value.
var MapAttributeCommand = map[string]AttributeCommand{
	"delete":       AttributeCommandDelete,
	"delete_multi": AttributeCommandDeleteMulti,
	"insert":       AttributeCommandInsert,
	"select":       AttributeCommandSelect,
	"update":       AttributeCommandUpdate,
	"update_multi": AttributeCommandUpdateMulti,
}

// AttributeConnectionError specifies the value connection_error attribute.
type AttributeConnectionError int

const (
	_ AttributeConnectionError = iota
	AttributeConnectionErrorAccept
	AttributeConnectionErrorInternal
	AttributeConnectionErrorMaxConnections
	AttributeConnectionErrorPeerAddress
	AttributeConnectionErrorSelect
	AttributeConnectionErrorTcpwrap
	AttributeConnectionErrorAborted
	AttributeConnectionErrorAbortedClients
	AttributeConnectionErrorLocked
)

// String returns the string representation of the AttributeConnectionError.
func (av AttributeConnectionError) String() string {
	switch av {
	case AttributeConnectionErrorAccept:
		return "accept"
	case AttributeConnectionErrorInternal:
		return "internal"
	case AttributeConnectionErrorMaxConnections:
		return "max_connections"
	case AttributeConnectionErrorPeerAddress:
		return "peer_address"
	case AttributeConnectionErrorSelect:
		return "select"
	case AttributeConnectionErrorTcpwrap:
		return "tcpwrap"
	case AttributeConnectionErrorAborted:
		return "aborted"
	case AttributeConnectionErrorAbortedClients:
		return "aborted_clients"
	case AttributeConnectionErrorLocked:
		return "locked"
	}
	return ""
}

// MapAttributeConnectionError is a helper map of string to AttributeConnectionError attribute value.
var MapAttributeConnectionError = map[string]AttributeConnectionError{
	"accept":          AttributeConnectionErrorAccept,
	"internal":        AttributeConnectionErrorInternal,
	"max_connections": AttributeConnectionErrorMaxConnections,
	"peer_address":    AttributeConnectionErrorPeerAddress,
	"select":          AttributeConnectionErrorSelect,
	"tcpwrap":         AttributeConnectionErrorTcpwrap,
	"aborted":         AttributeConnectionErrorAborted,
	"aborted_clients": AttributeConnectionErrorAbortedClients,
	"locked":          AttributeConnectionErrorLocked,
}

// AttributeHandler specifies the value handler attribute.
type AttributeHandler int

const (
	_ AttributeHandler = iota
	AttributeHandlerCommit
	AttributeHandlerDelete
	AttributeHandlerDiscover
	AttributeHandlerExternalLock
	AttributeHandlerMrrInit
	AttributeHandlerPrepare
	AttributeHandlerReadFirst
	AttributeHandlerReadKey
	AttributeHandlerReadLast
	AttributeHandlerReadNext
	AttributeHandlerReadPrev
	AttributeHandlerReadRnd
	AttributeHandlerReadRndNext
	AttributeHandlerRollback
	AttributeHandlerSavepoint
	AttributeHandlerSavepointRollback
	AttributeHandlerUpdate
	AttributeHandlerWrite
)

// String returns the string representation of the AttributeHandler.
func (av AttributeHandler) String() string {
	switch av {
	case AttributeHandlerCommit:
		return "commit"
	case AttributeHandlerDelete:
		return "delete"
	case AttributeHandlerDiscover:
		return "discover"
	case AttributeHandlerExternalLock:
		return "external_lock"
	case AttributeHandlerMrrInit:
		return "mrr_init"
	case AttributeHandlerPrepare:
		return "prepare"
	case AttributeHandlerReadFirst:
		return "read_first"
	case AttributeHandlerReadKey:
		return "read_key"
	case AttributeHandlerReadLast:
		return "read_last"
	case AttributeHandlerReadNext:
		return "read_next"
	case AttributeHandlerReadPrev:
		return "read_prev"
	case AttributeHandlerReadRnd:
		return "read_rnd"
	case AttributeHandlerReadRndNext:
		return "read_rnd_next"
	case AttributeHandlerRollback:
		return "rollback"
	case AttributeHandlerSavepoint:
		return "savepoint"
	case AttributeHandlerSavepointRollback:
		return "savepoint_rollback"
	case AttributeHandlerUpdate:
		return "update"
	case AttributeHandlerWrite:
		return "write"
	}
	return ""
}

// MapAttributeHandler is a helper map of string to AttributeHandler attribute value.
var MapAttributeHandler = map[string]AttributeHandler{
	"commit":             AttributeHandlerCommit,
	"delete":             AttributeHandlerDelete,
	"discover":           AttributeHandlerDiscover,
	"external_lock":      AttributeHandlerExternalLock,
	"mrr_init":           AttributeHandlerMrrInit,
	"prepare":            AttributeHandlerPrepare,
	"read_first":         AttributeHandlerReadFirst,
	"read_key":           AttributeHandlerReadKey,
	"read_last":          AttributeHandlerReadLast,
	"read_next":          AttributeHandlerReadNext,
	"read_prev":          AttributeHandlerReadPrev,
	"read_rnd":           AttributeHandlerReadRnd,
	"read_rnd_next":      AttributeHandlerReadRndNext,
	"rollback":           AttributeHandlerRollback,
	"savepoint":          AttributeHandlerSavepoint,
	"savepoint_rollback": AttributeHandlerSavepointRollback,
	"update":             AttributeHandlerUpdate,
	"write":              AttributeHandlerWrite,
}

// AttributeQueryType specifies the value query_type attribute.
type AttributeQueryType int

const (
	_ AttributeQueryType = iota
	AttributeQueryTypeSelect
	AttributeQueryTypeInsert
	AttributeQueryTypeUpdate
	AttributeQueryTypeDelete
	AttributeQueryTypeCreate
	AttributeQueryTypeDrop
	AttributeQueryTypeAlter
	AttributeQueryTypeShow
	AttributeQueryTypeSet
	AttributeQueryTypeBegin
	AttributeQueryTypeCommit
	AttributeQueryTypeRollback
)

// String returns the string representation of the AttributeQueryType.
func (av AttributeQueryType) String() string {
	switch av {
	case AttributeQueryTypeSelect:
		return "select"
	case AttributeQueryTypeInsert:
		return "insert"
	case AttributeQueryTypeUpdate:
		return "update"
	case AttributeQueryTypeDelete:
		return "delete"
	case AttributeQueryTypeCreate:
		return "create"
	case AttributeQueryTypeDrop:
		return "drop"
	case AttributeQueryTypeAlter:
		return "alter"
	case AttributeQueryTypeShow:
		return "show"
	case AttributeQueryTypeSet:
		return "set"
	case AttributeQueryTypeBegin:
		return "begin"
	case AttributeQueryTypeCommit:
		return "commit"
	case AttributeQueryTypeRollback:
		return "rollback"
	}
	return ""
}

// MapAttributeQueryType is a helper map of string to AttributeQueryType attribute value.
var MapAttributeQueryType = map[string]AttributeQueryType{
	"select":   AttributeQueryTypeSelect,
	"insert":   AttributeQueryTypeInsert,
	"update":   AttributeQueryTypeUpdate,
	"delete":   AttributeQueryTypeDelete,
	"create":   AttributeQueryTypeCreate,
	"drop":     AttributeQueryTypeDrop,
	"alter":    AttributeQueryTypeAlter,
	"show":     AttributeQueryTypeShow,
	"set":      AttributeQueryTypeSet,
	"begin":    AttributeQueryTypeBegin,
	"commit":   AttributeQueryTypeCommit,
	"rollback": AttributeQueryTypeRollback,
}

// AttributeWaitEventType specifies the value wait_event_type attribute.
type AttributeWaitEventType int

const (
	_ AttributeWaitEventType = iota
	AttributeWaitEventTypeIo
	AttributeWaitEventTypeLock
	AttributeWaitEventTypeCpu
	AttributeWaitEventTypeNetwork
	AttributeWaitEventTypeMemory
	AttributeWaitEventTypeOther
)

// String returns the string representation of the AttributeWaitEventType.
func (av AttributeWaitEventType) String() string {
	switch av {
	case AttributeWaitEventTypeIo:
		return "io"
	case AttributeWaitEventTypeLock:
		return "lock"
	case AttributeWaitEventTypeCpu:
		return "cpu"
	case AttributeWaitEventTypeNetwork:
		return "network"
	case AttributeWaitEventTypeMemory:
		return "memory"
	case AttributeWaitEventTypeOther:
		return "other"
	}
	return ""
}

// MapAttributeWaitEventType is a helper map of string to AttributeWaitEventType attribute value.
var MapAttributeWaitEventType = map[string]AttributeWaitEventType{
	"io":      AttributeWaitEventTypeIo,
	"lock":    AttributeWaitEventTypeLock,
	"cpu":     AttributeWaitEventTypeCpu,
	"network": AttributeWaitEventTypeNetwork,
	"memory":  AttributeWaitEventTypeMemory,
	"other":   AttributeWaitEventTypeOther,
}

var MetricsInfo = metricsInfo{
	MysqlBlockedSessionsCount: metricInfo{
		Name: "mysql.blocked_sessions.count",
	},
	MysqlBlockedSessionsWaitTime: metricInfo{
		Name: "mysql.blocked_sessions.wait_time",
	},
	MysqlBlockingSessionsCount: metricInfo{
		Name: "mysql.blocking_sessions.count",
	},
	MysqlBufferPoolDataPages: metricInfo{
		Name: "mysql.buffer_pool.data_pages",
	},
	MysqlBufferPoolLimit: metricInfo{
		Name: "mysql.buffer_pool.limit",
	},
	MysqlBufferPoolOperations: metricInfo{
		Name: "mysql.buffer_pool.operations",
	},
	MysqlBufferPoolPages: metricInfo{
		Name: "mysql.buffer_pool.pages",
	},
	MysqlBufferPoolUsage: metricInfo{
		Name: "mysql.buffer_pool.usage",
	},
	MysqlCommands: metricInfo{
		Name: "mysql.commands",
	},
	MysqlConnectionCount: metricInfo{
		Name: "mysql.connection.count",
	},
	MysqlConnectionErrors: metricInfo{
		Name: "mysql.connection.errors",
	},
	MysqlHandlers: metricInfo{
		Name: "mysql.handlers",
	},
	MysqlIndexIoOperations: metricInfo{
		Name: "mysql.index_io.operations",
	},
	MysqlIndexIoWaitTime: metricInfo{
		Name: "mysql.index_io.wait_time",
	},
	MysqlInnodbBufferPoolReadRequests: metricInfo{
		Name: "mysql.innodb.buffer_pool_read_requests",
	},
	MysqlInnodbBufferPoolReads: metricInfo{
		Name: "mysql.innodb.buffer_pool_reads",
	},
	MysqlInnodbBufferPoolWriteRequests: metricInfo{
		Name: "mysql.innodb.buffer_pool_write_requests",
	},
	MysqlInnodbDataRead: metricInfo{
		Name: "mysql.innodb.data_read",
	},
	MysqlInnodbDataReads: metricInfo{
		Name: "mysql.innodb.data_reads",
	},
	MysqlInnodbDataWrites: metricInfo{
		Name: "mysql.innodb.data_writes",
	},
	MysqlInnodbDataWritten: metricInfo{
		Name: "mysql.innodb.data_written",
	},
	MysqlPerformanceSchemaEventsStatementsTime: metricInfo{
		Name: "mysql.performance_schema.events_statements_time",
	},
	MysqlPerformanceSchemaEventsStatementsTotal: metricInfo{
		Name: "mysql.performance_schema.events_statements_total",
	},
	MysqlQueryAvgTime: metricInfo{
		Name: "mysql.query.avg_time",
	},
	MysqlQueryExecutionCount: metricInfo{
		Name: "mysql.query.execution_count",
	},
	MysqlQueryLockTime: metricInfo{
		Name: "mysql.query.lock_time",
	},
	MysqlQueryMaxTime: metricInfo{
		Name: "mysql.query.max_time",
	},
	MysqlQueryMinTime: metricInfo{
		Name: "mysql.query.min_time",
	},
	MysqlQueryRowsExamined: metricInfo{
		Name: "mysql.query.rows_examined",
	},
	MysqlQueryRowsSent: metricInfo{
		Name: "mysql.query.rows_sent",
	},
	MysqlQueryTotalTime: metricInfo{
		Name: "mysql.query.total_time",
	},
	MysqlSlaveIoRunning: metricInfo{
		Name: "mysql.slave_io_running",
	},
	MysqlSlaveLag: metricInfo{
		Name: "mysql.slave_lag",
	},
	MysqlSlaveSQLRunning: metricInfo{
		Name: "mysql.slave_sql_running",
	},
	MysqlSlowQueriesCount: metricInfo{
		Name: "mysql.slow_queries.count",
	},
	MysqlSlowQueriesTotalTime: metricInfo{
		Name: "mysql.slow_queries.total_time",
	},
	MysqlTableIoOperations: metricInfo{
		Name: "mysql.table_io.operations",
	},
	MysqlTableIoWaitTime: metricInfo{
		Name: "mysql.table_io.wait_time",
	},
	MysqlWaitEventsCount: metricInfo{
		Name: "mysql.wait_events.count",
	},
	MysqlWaitEventsTotalTime: metricInfo{
		Name: "mysql.wait_events.total_time",
	},
}

type metricsInfo struct {
	MysqlBlockedSessionsCount                   metricInfo
	MysqlBlockedSessionsWaitTime                metricInfo
	MysqlBlockingSessionsCount                  metricInfo
	MysqlBufferPoolDataPages                    metricInfo
	MysqlBufferPoolLimit                        metricInfo
	MysqlBufferPoolOperations                   metricInfo
	MysqlBufferPoolPages                        metricInfo
	MysqlBufferPoolUsage                        metricInfo
	MysqlCommands                               metricInfo
	MysqlConnectionCount                        metricInfo
	MysqlConnectionErrors                       metricInfo
	MysqlHandlers                               metricInfo
	MysqlIndexIoOperations                      metricInfo
	MysqlIndexIoWaitTime                        metricInfo
	MysqlInnodbBufferPoolReadRequests           metricInfo
	MysqlInnodbBufferPoolReads                  metricInfo
	MysqlInnodbBufferPoolWriteRequests          metricInfo
	MysqlInnodbDataRead                         metricInfo
	MysqlInnodbDataReads                        metricInfo
	MysqlInnodbDataWrites                       metricInfo
	MysqlInnodbDataWritten                      metricInfo
	MysqlPerformanceSchemaEventsStatementsTime  metricInfo
	MysqlPerformanceSchemaEventsStatementsTotal metricInfo
	MysqlQueryAvgTime                           metricInfo
	MysqlQueryExecutionCount                    metricInfo
	MysqlQueryLockTime                          metricInfo
	MysqlQueryMaxTime                           metricInfo
	MysqlQueryMinTime                           metricInfo
	MysqlQueryRowsExamined                      metricInfo
	MysqlQueryRowsSent                          metricInfo
	MysqlQueryTotalTime                         metricInfo
	MysqlSlaveIoRunning                         metricInfo
	MysqlSlaveLag                               metricInfo
	MysqlSlaveSQLRunning                        metricInfo
	MysqlSlowQueriesCount                       metricInfo
	MysqlSlowQueriesTotalTime                   metricInfo
	MysqlTableIoOperations                      metricInfo
	MysqlTableIoWaitTime                        metricInfo
	MysqlWaitEventsCount                        metricInfo
	MysqlWaitEventsTotalTime                    metricInfo
}

type metricInfo struct {
	Name string
}

type metricMysqlBlockedSessionsCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.blocked_sessions.count metric with initial data.
func (m *metricMysqlBlockedSessionsCount) init() {
	m.data.SetName("mysql.blocked_sessions.count")
	m.data.SetDescription("Number of blocked sessions.")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlBlockedSessionsCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, blockedSessionIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("blocked_session_id", blockedSessionIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlBlockedSessionsCount) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlBlockedSessionsCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlBlockedSessionsCount(cfg MetricConfig) metricMysqlBlockedSessionsCount {
	m := metricMysqlBlockedSessionsCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlBlockedSessionsWaitTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.blocked_sessions.wait_time metric with initial data.
func (m *metricMysqlBlockedSessionsWaitTime) init() {
	m.data.SetName("mysql.blocked_sessions.wait_time")
	m.data.SetDescription("Time blocked sessions have been waiting.")
	m.data.SetUnit("s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlBlockedSessionsWaitTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, blockedSessionIDAttributeValue string, blockingSessionIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("blocked_session_id", blockedSessionIDAttributeValue)
	dp.Attributes().PutStr("blocking_session_id", blockingSessionIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlBlockedSessionsWaitTime) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlBlockedSessionsWaitTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlBlockedSessionsWaitTime(cfg MetricConfig) metricMysqlBlockedSessionsWaitTime {
	m := metricMysqlBlockedSessionsWaitTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlBlockingSessionsCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.blocking_sessions.count metric with initial data.
func (m *metricMysqlBlockingSessionsCount) init() {
	m.data.SetName("mysql.blocking_sessions.count")
	m.data.SetDescription("Number of blocking sessions.")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlBlockingSessionsCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, blockingSessionIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("blocking_session_id", blockingSessionIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlBlockingSessionsCount) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlBlockingSessionsCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlBlockingSessionsCount(cfg MetricConfig) metricMysqlBlockingSessionsCount {
	m := metricMysqlBlockingSessionsCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlBufferPoolDataPages struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.buffer_pool.data_pages metric with initial data.
func (m *metricMysqlBufferPoolDataPages) init() {
	m.data.SetName("mysql.buffer_pool.data_pages")
	m.data.SetDescription("The number of data pages in the InnoDB buffer pool.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlBufferPoolDataPages) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, bufferPoolDataAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("status", bufferPoolDataAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlBufferPoolDataPages) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlBufferPoolDataPages) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlBufferPoolDataPages(cfg MetricConfig) metricMysqlBufferPoolDataPages {
	m := metricMysqlBufferPoolDataPages{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlBufferPoolLimit struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.buffer_pool.limit metric with initial data.
func (m *metricMysqlBufferPoolLimit) init() {
	m.data.SetName("mysql.buffer_pool.limit")
	m.data.SetDescription("The configured size of the InnoDB buffer pool.")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
}

func (m *metricMysqlBufferPoolLimit) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlBufferPoolLimit) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlBufferPoolLimit) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlBufferPoolLimit(cfg MetricConfig) metricMysqlBufferPoolLimit {
	m := metricMysqlBufferPoolLimit{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlBufferPoolOperations struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.buffer_pool.operations metric with initial data.
func (m *metricMysqlBufferPoolOperations) init() {
	m.data.SetName("mysql.buffer_pool.operations")
	m.data.SetDescription("The number of operations on the InnoDB buffer pool.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlBufferPoolOperations) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, bufferPoolOperationsAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("operation", bufferPoolOperationsAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlBufferPoolOperations) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlBufferPoolOperations) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlBufferPoolOperations(cfg MetricConfig) metricMysqlBufferPoolOperations {
	m := metricMysqlBufferPoolOperations{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlBufferPoolPages struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.buffer_pool.pages metric with initial data.
func (m *metricMysqlBufferPoolPages) init() {
	m.data.SetName("mysql.buffer_pool.pages")
	m.data.SetDescription("The number of pages in the InnoDB buffer pool.")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlBufferPoolPages) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, bufferPoolPagesAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("kind", bufferPoolPagesAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlBufferPoolPages) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlBufferPoolPages) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlBufferPoolPages(cfg MetricConfig) metricMysqlBufferPoolPages {
	m := metricMysqlBufferPoolPages{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlBufferPoolUsage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.buffer_pool.usage metric with initial data.
func (m *metricMysqlBufferPoolUsage) init() {
	m.data.SetName("mysql.buffer_pool.usage")
	m.data.SetDescription("The number of bytes in the InnoDB buffer pool.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlBufferPoolUsage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, bufferPoolDataAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("status", bufferPoolDataAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlBufferPoolUsage) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlBufferPoolUsage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlBufferPoolUsage(cfg MetricConfig) metricMysqlBufferPoolUsage {
	m := metricMysqlBufferPoolUsage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlCommands struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.commands metric with initial data.
func (m *metricMysqlCommands) init() {
	m.data.SetName("mysql.commands")
	m.data.SetDescription("The number of times each type of command has been executed.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlCommands) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, commandAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("command", commandAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlCommands) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlCommands) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlCommands(cfg MetricConfig) metricMysqlCommands {
	m := metricMysqlCommands{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlConnectionCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.connection.count metric with initial data.
func (m *metricMysqlConnectionCount) init() {
	m.data.SetName("mysql.connection.count")
	m.data.SetDescription("The number of connection attempts to the MySQL server.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricMysqlConnectionCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlConnectionCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlConnectionCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlConnectionCount(cfg MetricConfig) metricMysqlConnectionCount {
	m := metricMysqlConnectionCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlConnectionErrors struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.connection.errors metric with initial data.
func (m *metricMysqlConnectionErrors) init() {
	m.data.SetName("mysql.connection.errors")
	m.data.SetDescription("The number of failed connections to the MySQL server.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlConnectionErrors) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, connectionErrorAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("error", connectionErrorAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlConnectionErrors) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlConnectionErrors) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlConnectionErrors(cfg MetricConfig) metricMysqlConnectionErrors {
	m := metricMysqlConnectionErrors{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlHandlers struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.handlers metric with initial data.
func (m *metricMysqlHandlers) init() {
	m.data.SetName("mysql.handlers")
	m.data.SetDescription("The number of requests to various MySQL handlers.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlHandlers) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, handlerAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("kind", handlerAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlHandlers) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlHandlers) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlHandlers(cfg MetricConfig) metricMysqlHandlers {
	m := metricMysqlHandlers{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlIndexIoOperations struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.index_io.operations metric with initial data.
func (m *metricMysqlIndexIoOperations) init() {
	m.data.SetName("mysql.index_io.operations")
	m.data.SetDescription("Number of index I/O operations.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlIndexIoOperations) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, schemaNameAttributeValue string, tableNameAttributeValue string, indexNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("schema_name", schemaNameAttributeValue)
	dp.Attributes().PutStr("table_name", tableNameAttributeValue)
	dp.Attributes().PutStr("index_name", indexNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlIndexIoOperations) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlIndexIoOperations) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlIndexIoOperations(cfg MetricConfig) metricMysqlIndexIoOperations {
	m := metricMysqlIndexIoOperations{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlIndexIoWaitTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.index_io.wait_time metric with initial data.
func (m *metricMysqlIndexIoWaitTime) init() {
	m.data.SetName("mysql.index_io.wait_time")
	m.data.SetDescription("Total time spent waiting for index I/O operations.")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlIndexIoWaitTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, schemaNameAttributeValue string, tableNameAttributeValue string, indexNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("schema_name", schemaNameAttributeValue)
	dp.Attributes().PutStr("table_name", tableNameAttributeValue)
	dp.Attributes().PutStr("index_name", indexNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlIndexIoWaitTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlIndexIoWaitTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlIndexIoWaitTime(cfg MetricConfig) metricMysqlIndexIoWaitTime {
	m := metricMysqlIndexIoWaitTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlInnodbBufferPoolReadRequests struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.innodb.buffer_pool_read_requests metric with initial data.
func (m *metricMysqlInnodbBufferPoolReadRequests) init() {
	m.data.SetName("mysql.innodb.buffer_pool_read_requests")
	m.data.SetDescription("Number of logical read requests to the InnoDB buffer pool.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricMysqlInnodbBufferPoolReadRequests) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlInnodbBufferPoolReadRequests) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlInnodbBufferPoolReadRequests) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlInnodbBufferPoolReadRequests(cfg MetricConfig) metricMysqlInnodbBufferPoolReadRequests {
	m := metricMysqlInnodbBufferPoolReadRequests{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlInnodbBufferPoolReads struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.innodb.buffer_pool_reads metric with initial data.
func (m *metricMysqlInnodbBufferPoolReads) init() {
	m.data.SetName("mysql.innodb.buffer_pool_reads")
	m.data.SetDescription("Number of reads that InnoDB could not satisfy from the buffer pool.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricMysqlInnodbBufferPoolReads) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlInnodbBufferPoolReads) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlInnodbBufferPoolReads) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlInnodbBufferPoolReads(cfg MetricConfig) metricMysqlInnodbBufferPoolReads {
	m := metricMysqlInnodbBufferPoolReads{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlInnodbBufferPoolWriteRequests struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.innodb.buffer_pool_write_requests metric with initial data.
func (m *metricMysqlInnodbBufferPoolWriteRequests) init() {
	m.data.SetName("mysql.innodb.buffer_pool_write_requests")
	m.data.SetDescription("Number of writes done to the InnoDB buffer pool.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricMysqlInnodbBufferPoolWriteRequests) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlInnodbBufferPoolWriteRequests) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlInnodbBufferPoolWriteRequests) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlInnodbBufferPoolWriteRequests(cfg MetricConfig) metricMysqlInnodbBufferPoolWriteRequests {
	m := metricMysqlInnodbBufferPoolWriteRequests{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlInnodbDataRead struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.innodb.data_read metric with initial data.
func (m *metricMysqlInnodbDataRead) init() {
	m.data.SetName("mysql.innodb.data_read")
	m.data.SetDescription("Amount of data read by InnoDB.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricMysqlInnodbDataRead) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlInnodbDataRead) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlInnodbDataRead) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlInnodbDataRead(cfg MetricConfig) metricMysqlInnodbDataRead {
	m := metricMysqlInnodbDataRead{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlInnodbDataReads struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.innodb.data_reads metric with initial data.
func (m *metricMysqlInnodbDataReads) init() {
	m.data.SetName("mysql.innodb.data_reads")
	m.data.SetDescription("Number of data reads by InnoDB.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricMysqlInnodbDataReads) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlInnodbDataReads) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlInnodbDataReads) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlInnodbDataReads(cfg MetricConfig) metricMysqlInnodbDataReads {
	m := metricMysqlInnodbDataReads{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlInnodbDataWrites struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.innodb.data_writes metric with initial data.
func (m *metricMysqlInnodbDataWrites) init() {
	m.data.SetName("mysql.innodb.data_writes")
	m.data.SetDescription("Number of data writes by InnoDB.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricMysqlInnodbDataWrites) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlInnodbDataWrites) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlInnodbDataWrites) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlInnodbDataWrites(cfg MetricConfig) metricMysqlInnodbDataWrites {
	m := metricMysqlInnodbDataWrites{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlInnodbDataWritten struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.innodb.data_written metric with initial data.
func (m *metricMysqlInnodbDataWritten) init() {
	m.data.SetName("mysql.innodb.data_written")
	m.data.SetDescription("Amount of data written by InnoDB.")
	m.data.SetUnit("By")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricMysqlInnodbDataWritten) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlInnodbDataWritten) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlInnodbDataWritten) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlInnodbDataWritten(cfg MetricConfig) metricMysqlInnodbDataWritten {
	m := metricMysqlInnodbDataWritten{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlPerformanceSchemaEventsStatementsTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.performance_schema.events_statements_time metric with initial data.
func (m *metricMysqlPerformanceSchemaEventsStatementsTime) init() {
	m.data.SetName("mysql.performance_schema.events_statements_time")
	m.data.SetDescription("Total time of statement events.")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlPerformanceSchemaEventsStatementsTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, queryDigestAttributeValue string, queryTypeAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("query_digest", queryDigestAttributeValue)
	dp.Attributes().PutStr("query_type", queryTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlPerformanceSchemaEventsStatementsTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlPerformanceSchemaEventsStatementsTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlPerformanceSchemaEventsStatementsTime(cfg MetricConfig) metricMysqlPerformanceSchemaEventsStatementsTime {
	m := metricMysqlPerformanceSchemaEventsStatementsTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlPerformanceSchemaEventsStatementsTotal struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.performance_schema.events_statements_total metric with initial data.
func (m *metricMysqlPerformanceSchemaEventsStatementsTotal) init() {
	m.data.SetName("mysql.performance_schema.events_statements_total")
	m.data.SetDescription("Total number of statement events.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlPerformanceSchemaEventsStatementsTotal) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, queryDigestAttributeValue string, queryTypeAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("query_digest", queryDigestAttributeValue)
	dp.Attributes().PutStr("query_type", queryTypeAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlPerformanceSchemaEventsStatementsTotal) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlPerformanceSchemaEventsStatementsTotal) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlPerformanceSchemaEventsStatementsTotal(cfg MetricConfig) metricMysqlPerformanceSchemaEventsStatementsTotal {
	m := metricMysqlPerformanceSchemaEventsStatementsTotal{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlQueryAvgTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.query.avg_time metric with initial data.
func (m *metricMysqlQueryAvgTime) init() {
	m.data.SetName("mysql.query.avg_time")
	m.data.SetDescription("Average execution time for this query type.")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlQueryAvgTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, queryDigestAttributeValue string, queryTypeAttributeValue string, schemaNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("query_digest", queryDigestAttributeValue)
	dp.Attributes().PutStr("query_type", queryTypeAttributeValue)
	dp.Attributes().PutStr("schema_name", schemaNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlQueryAvgTime) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlQueryAvgTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlQueryAvgTime(cfg MetricConfig) metricMysqlQueryAvgTime {
	m := metricMysqlQueryAvgTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlQueryExecutionCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.query.execution_count metric with initial data.
func (m *metricMysqlQueryExecutionCount) init() {
	m.data.SetName("mysql.query.execution_count")
	m.data.SetDescription("Number of times a query has been executed.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlQueryExecutionCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, queryDigestAttributeValue string, queryTypeAttributeValue string, schemaNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("query_digest", queryDigestAttributeValue)
	dp.Attributes().PutStr("query_type", queryTypeAttributeValue)
	dp.Attributes().PutStr("schema_name", schemaNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlQueryExecutionCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlQueryExecutionCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlQueryExecutionCount(cfg MetricConfig) metricMysqlQueryExecutionCount {
	m := metricMysqlQueryExecutionCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlQueryLockTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.query.lock_time metric with initial data.
func (m *metricMysqlQueryLockTime) init() {
	m.data.SetName("mysql.query.lock_time")
	m.data.SetDescription("Total time spent waiting for locks for this query type.")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlQueryLockTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, queryDigestAttributeValue string, queryTypeAttributeValue string, schemaNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("query_digest", queryDigestAttributeValue)
	dp.Attributes().PutStr("query_type", queryTypeAttributeValue)
	dp.Attributes().PutStr("schema_name", schemaNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlQueryLockTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlQueryLockTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlQueryLockTime(cfg MetricConfig) metricMysqlQueryLockTime {
	m := metricMysqlQueryLockTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlQueryMaxTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.query.max_time metric with initial data.
func (m *metricMysqlQueryMaxTime) init() {
	m.data.SetName("mysql.query.max_time")
	m.data.SetDescription("Maximum execution time for this query type.")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlQueryMaxTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, queryDigestAttributeValue string, queryTypeAttributeValue string, schemaNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("query_digest", queryDigestAttributeValue)
	dp.Attributes().PutStr("query_type", queryTypeAttributeValue)
	dp.Attributes().PutStr("schema_name", schemaNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlQueryMaxTime) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlQueryMaxTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlQueryMaxTime(cfg MetricConfig) metricMysqlQueryMaxTime {
	m := metricMysqlQueryMaxTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlQueryMinTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.query.min_time metric with initial data.
func (m *metricMysqlQueryMinTime) init() {
	m.data.SetName("mysql.query.min_time")
	m.data.SetDescription("Minimum execution time for this query type.")
	m.data.SetUnit("ms")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlQueryMinTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, queryDigestAttributeValue string, queryTypeAttributeValue string, schemaNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("query_digest", queryDigestAttributeValue)
	dp.Attributes().PutStr("query_type", queryTypeAttributeValue)
	dp.Attributes().PutStr("schema_name", schemaNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlQueryMinTime) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlQueryMinTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlQueryMinTime(cfg MetricConfig) metricMysqlQueryMinTime {
	m := metricMysqlQueryMinTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlQueryRowsExamined struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.query.rows_examined metric with initial data.
func (m *metricMysqlQueryRowsExamined) init() {
	m.data.SetName("mysql.query.rows_examined")
	m.data.SetDescription("Total number of rows examined by this query type.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlQueryRowsExamined) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, queryDigestAttributeValue string, queryTypeAttributeValue string, schemaNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("query_digest", queryDigestAttributeValue)
	dp.Attributes().PutStr("query_type", queryTypeAttributeValue)
	dp.Attributes().PutStr("schema_name", schemaNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlQueryRowsExamined) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlQueryRowsExamined) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlQueryRowsExamined(cfg MetricConfig) metricMysqlQueryRowsExamined {
	m := metricMysqlQueryRowsExamined{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlQueryRowsSent struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.query.rows_sent metric with initial data.
func (m *metricMysqlQueryRowsSent) init() {
	m.data.SetName("mysql.query.rows_sent")
	m.data.SetDescription("Total number of rows sent by this query type.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlQueryRowsSent) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, queryDigestAttributeValue string, queryTypeAttributeValue string, schemaNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("query_digest", queryDigestAttributeValue)
	dp.Attributes().PutStr("query_type", queryTypeAttributeValue)
	dp.Attributes().PutStr("schema_name", schemaNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlQueryRowsSent) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlQueryRowsSent) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlQueryRowsSent(cfg MetricConfig) metricMysqlQueryRowsSent {
	m := metricMysqlQueryRowsSent{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlQueryTotalTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.query.total_time metric with initial data.
func (m *metricMysqlQueryTotalTime) init() {
	m.data.SetName("mysql.query.total_time")
	m.data.SetDescription("Total time spent executing queries of this type.")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlQueryTotalTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, queryDigestAttributeValue string, queryTypeAttributeValue string, schemaNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("query_digest", queryDigestAttributeValue)
	dp.Attributes().PutStr("query_type", queryTypeAttributeValue)
	dp.Attributes().PutStr("schema_name", schemaNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlQueryTotalTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlQueryTotalTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlQueryTotalTime(cfg MetricConfig) metricMysqlQueryTotalTime {
	m := metricMysqlQueryTotalTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlSlaveIoRunning struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.slave_io_running metric with initial data.
func (m *metricMysqlSlaveIoRunning) init() {
	m.data.SetName("mysql.slave_io_running")
	m.data.SetDescription("Whether the I/O thread is running on the replica.")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
}

func (m *metricMysqlSlaveIoRunning) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlSlaveIoRunning) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlSlaveIoRunning) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlSlaveIoRunning(cfg MetricConfig) metricMysqlSlaveIoRunning {
	m := metricMysqlSlaveIoRunning{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlSlaveLag struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.slave_lag metric with initial data.
func (m *metricMysqlSlaveLag) init() {
	m.data.SetName("mysql.slave_lag")
	m.data.SetDescription("Number of seconds that the replica must lag the source.")
	m.data.SetUnit("s")
	m.data.SetEmptyGauge()
}

func (m *metricMysqlSlaveLag) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlSlaveLag) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlSlaveLag) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlSlaveLag(cfg MetricConfig) metricMysqlSlaveLag {
	m := metricMysqlSlaveLag{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlSlaveSQLRunning struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.slave_sql_running metric with initial data.
func (m *metricMysqlSlaveSQLRunning) init() {
	m.data.SetName("mysql.slave_sql_running")
	m.data.SetDescription("Whether the SQL thread is running on the replica.")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
}

func (m *metricMysqlSlaveSQLRunning) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlSlaveSQLRunning) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlSlaveSQLRunning) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlSlaveSQLRunning(cfg MetricConfig) metricMysqlSlaveSQLRunning {
	m := metricMysqlSlaveSQLRunning{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlSlowQueriesCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.slow_queries.count metric with initial data.
func (m *metricMysqlSlowQueriesCount) init() {
	m.data.SetName("mysql.slow_queries.count")
	m.data.SetDescription("Number of slow queries.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricMysqlSlowQueriesCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlSlowQueriesCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlSlowQueriesCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlSlowQueriesCount(cfg MetricConfig) metricMysqlSlowQueriesCount {
	m := metricMysqlSlowQueriesCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlSlowQueriesTotalTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.slow_queries.total_time metric with initial data.
func (m *metricMysqlSlowQueriesTotalTime) init() {
	m.data.SetName("mysql.slow_queries.total_time")
	m.data.SetDescription("Total time spent on slow queries.")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricMysqlSlowQueriesTotalTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlSlowQueriesTotalTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlSlowQueriesTotalTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlSlowQueriesTotalTime(cfg MetricConfig) metricMysqlSlowQueriesTotalTime {
	m := metricMysqlSlowQueriesTotalTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlTableIoOperations struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.table_io.operations metric with initial data.
func (m *metricMysqlTableIoOperations) init() {
	m.data.SetName("mysql.table_io.operations")
	m.data.SetDescription("Number of table I/O operations.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlTableIoOperations) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, schemaNameAttributeValue string, tableNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("schema_name", schemaNameAttributeValue)
	dp.Attributes().PutStr("table_name", tableNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlTableIoOperations) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlTableIoOperations) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlTableIoOperations(cfg MetricConfig) metricMysqlTableIoOperations {
	m := metricMysqlTableIoOperations{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlTableIoWaitTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.table_io.wait_time metric with initial data.
func (m *metricMysqlTableIoWaitTime) init() {
	m.data.SetName("mysql.table_io.wait_time")
	m.data.SetDescription("Total time spent waiting for table I/O operations.")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlTableIoWaitTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, schemaNameAttributeValue string, tableNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("schema_name", schemaNameAttributeValue)
	dp.Attributes().PutStr("table_name", tableNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlTableIoWaitTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlTableIoWaitTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlTableIoWaitTime(cfg MetricConfig) metricMysqlTableIoWaitTime {
	m := metricMysqlTableIoWaitTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlWaitEventsCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.wait_events.count metric with initial data.
func (m *metricMysqlWaitEventsCount) init() {
	m.data.SetName("mysql.wait_events.count")
	m.data.SetDescription("Number of wait events.")
	m.data.SetUnit("1")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlWaitEventsCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, waitEventTypeAttributeValue string, waitEventAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("wait_event_type", waitEventTypeAttributeValue)
	dp.Attributes().PutStr("wait_event", waitEventAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlWaitEventsCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlWaitEventsCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlWaitEventsCount(cfg MetricConfig) metricMysqlWaitEventsCount {
	m := metricMysqlWaitEventsCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricMysqlWaitEventsTotalTime struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills mysql.wait_events.total_time metric with initial data.
func (m *metricMysqlWaitEventsTotalTime) init() {
	m.data.SetName("mysql.wait_events.total_time")
	m.data.SetDescription("Total time spent waiting for events.")
	m.data.SetUnit("ms")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(true)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
	m.data.Sum().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricMysqlWaitEventsTotalTime) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, waitEventTypeAttributeValue string, waitEventAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("wait_event_type", waitEventTypeAttributeValue)
	dp.Attributes().PutStr("wait_event", waitEventAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricMysqlWaitEventsTotalTime) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricMysqlWaitEventsTotalTime) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricMysqlWaitEventsTotalTime(cfg MetricConfig) metricMysqlWaitEventsTotalTime {
	m := metricMysqlWaitEventsTotalTime{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

// MetricsBuilder provides an interface for scrapers to report metrics while taking care of all the transformations
// required to produce metric representation defined in metadata and user config.
type MetricsBuilder struct {
	config                                            MetricsBuilderConfig // config of the metrics builder.
	startTime                                         pcommon.Timestamp    // start time that will be applied to all recorded data points.
	metricsCapacity                                   int                  // maximum observed number of metrics per resource.
	metricsBuffer                                     pmetric.Metrics      // accumulates metrics data before emitting.
	buildInfo                                         component.BuildInfo  // contains version information.
	resourceAttributeIncludeFilter                    map[string]filter.Filter
	resourceAttributeExcludeFilter                    map[string]filter.Filter
	metricMysqlBlockedSessionsCount                   metricMysqlBlockedSessionsCount
	metricMysqlBlockedSessionsWaitTime                metricMysqlBlockedSessionsWaitTime
	metricMysqlBlockingSessionsCount                  metricMysqlBlockingSessionsCount
	metricMysqlBufferPoolDataPages                    metricMysqlBufferPoolDataPages
	metricMysqlBufferPoolLimit                        metricMysqlBufferPoolLimit
	metricMysqlBufferPoolOperations                   metricMysqlBufferPoolOperations
	metricMysqlBufferPoolPages                        metricMysqlBufferPoolPages
	metricMysqlBufferPoolUsage                        metricMysqlBufferPoolUsage
	metricMysqlCommands                               metricMysqlCommands
	metricMysqlConnectionCount                        metricMysqlConnectionCount
	metricMysqlConnectionErrors                       metricMysqlConnectionErrors
	metricMysqlHandlers                               metricMysqlHandlers
	metricMysqlIndexIoOperations                      metricMysqlIndexIoOperations
	metricMysqlIndexIoWaitTime                        metricMysqlIndexIoWaitTime
	metricMysqlInnodbBufferPoolReadRequests           metricMysqlInnodbBufferPoolReadRequests
	metricMysqlInnodbBufferPoolReads                  metricMysqlInnodbBufferPoolReads
	metricMysqlInnodbBufferPoolWriteRequests          metricMysqlInnodbBufferPoolWriteRequests
	metricMysqlInnodbDataRead                         metricMysqlInnodbDataRead
	metricMysqlInnodbDataReads                        metricMysqlInnodbDataReads
	metricMysqlInnodbDataWrites                       metricMysqlInnodbDataWrites
	metricMysqlInnodbDataWritten                      metricMysqlInnodbDataWritten
	metricMysqlPerformanceSchemaEventsStatementsTime  metricMysqlPerformanceSchemaEventsStatementsTime
	metricMysqlPerformanceSchemaEventsStatementsTotal metricMysqlPerformanceSchemaEventsStatementsTotal
	metricMysqlQueryAvgTime                           metricMysqlQueryAvgTime
	metricMysqlQueryExecutionCount                    metricMysqlQueryExecutionCount
	metricMysqlQueryLockTime                          metricMysqlQueryLockTime
	metricMysqlQueryMaxTime                           metricMysqlQueryMaxTime
	metricMysqlQueryMinTime                           metricMysqlQueryMinTime
	metricMysqlQueryRowsExamined                      metricMysqlQueryRowsExamined
	metricMysqlQueryRowsSent                          metricMysqlQueryRowsSent
	metricMysqlQueryTotalTime                         metricMysqlQueryTotalTime
	metricMysqlSlaveIoRunning                         metricMysqlSlaveIoRunning
	metricMysqlSlaveLag                               metricMysqlSlaveLag
	metricMysqlSlaveSQLRunning                        metricMysqlSlaveSQLRunning
	metricMysqlSlowQueriesCount                       metricMysqlSlowQueriesCount
	metricMysqlSlowQueriesTotalTime                   metricMysqlSlowQueriesTotalTime
	metricMysqlTableIoOperations                      metricMysqlTableIoOperations
	metricMysqlTableIoWaitTime                        metricMysqlTableIoWaitTime
	metricMysqlWaitEventsCount                        metricMysqlWaitEventsCount
	metricMysqlWaitEventsTotalTime                    metricMysqlWaitEventsTotalTime
}

// MetricBuilderOption applies changes to default metrics builder.
type MetricBuilderOption interface {
	apply(*MetricsBuilder)
}

type metricBuilderOptionFunc func(mb *MetricsBuilder)

func (mbof metricBuilderOptionFunc) apply(mb *MetricsBuilder) {
	mbof(mb)
}

// WithStartTime sets startTime on the metrics builder.
func WithStartTime(startTime pcommon.Timestamp) MetricBuilderOption {
	return metricBuilderOptionFunc(func(mb *MetricsBuilder) {
		mb.startTime = startTime
	})
}
func NewMetricsBuilder(mbc MetricsBuilderConfig, settings receiver.Settings, options ...MetricBuilderOption) *MetricsBuilder {
	mb := &MetricsBuilder{
		config:                                            mbc,
		startTime:                                         pcommon.NewTimestampFromTime(time.Now()),
		metricsBuffer:                                     pmetric.NewMetrics(),
		buildInfo:                                         settings.BuildInfo,
		metricMysqlBlockedSessionsCount:                   newMetricMysqlBlockedSessionsCount(mbc.Metrics.MysqlBlockedSessionsCount),
		metricMysqlBlockedSessionsWaitTime:                newMetricMysqlBlockedSessionsWaitTime(mbc.Metrics.MysqlBlockedSessionsWaitTime),
		metricMysqlBlockingSessionsCount:                  newMetricMysqlBlockingSessionsCount(mbc.Metrics.MysqlBlockingSessionsCount),
		metricMysqlBufferPoolDataPages:                    newMetricMysqlBufferPoolDataPages(mbc.Metrics.MysqlBufferPoolDataPages),
		metricMysqlBufferPoolLimit:                        newMetricMysqlBufferPoolLimit(mbc.Metrics.MysqlBufferPoolLimit),
		metricMysqlBufferPoolOperations:                   newMetricMysqlBufferPoolOperations(mbc.Metrics.MysqlBufferPoolOperations),
		metricMysqlBufferPoolPages:                        newMetricMysqlBufferPoolPages(mbc.Metrics.MysqlBufferPoolPages),
		metricMysqlBufferPoolUsage:                        newMetricMysqlBufferPoolUsage(mbc.Metrics.MysqlBufferPoolUsage),
		metricMysqlCommands:                               newMetricMysqlCommands(mbc.Metrics.MysqlCommands),
		metricMysqlConnectionCount:                        newMetricMysqlConnectionCount(mbc.Metrics.MysqlConnectionCount),
		metricMysqlConnectionErrors:                       newMetricMysqlConnectionErrors(mbc.Metrics.MysqlConnectionErrors),
		metricMysqlHandlers:                               newMetricMysqlHandlers(mbc.Metrics.MysqlHandlers),
		metricMysqlIndexIoOperations:                      newMetricMysqlIndexIoOperations(mbc.Metrics.MysqlIndexIoOperations),
		metricMysqlIndexIoWaitTime:                        newMetricMysqlIndexIoWaitTime(mbc.Metrics.MysqlIndexIoWaitTime),
		metricMysqlInnodbBufferPoolReadRequests:           newMetricMysqlInnodbBufferPoolReadRequests(mbc.Metrics.MysqlInnodbBufferPoolReadRequests),
		metricMysqlInnodbBufferPoolReads:                  newMetricMysqlInnodbBufferPoolReads(mbc.Metrics.MysqlInnodbBufferPoolReads),
		metricMysqlInnodbBufferPoolWriteRequests:          newMetricMysqlInnodbBufferPoolWriteRequests(mbc.Metrics.MysqlInnodbBufferPoolWriteRequests),
		metricMysqlInnodbDataRead:                         newMetricMysqlInnodbDataRead(mbc.Metrics.MysqlInnodbDataRead),
		metricMysqlInnodbDataReads:                        newMetricMysqlInnodbDataReads(mbc.Metrics.MysqlInnodbDataReads),
		metricMysqlInnodbDataWrites:                       newMetricMysqlInnodbDataWrites(mbc.Metrics.MysqlInnodbDataWrites),
		metricMysqlInnodbDataWritten:                      newMetricMysqlInnodbDataWritten(mbc.Metrics.MysqlInnodbDataWritten),
		metricMysqlPerformanceSchemaEventsStatementsTime:  newMetricMysqlPerformanceSchemaEventsStatementsTime(mbc.Metrics.MysqlPerformanceSchemaEventsStatementsTime),
		metricMysqlPerformanceSchemaEventsStatementsTotal: newMetricMysqlPerformanceSchemaEventsStatementsTotal(mbc.Metrics.MysqlPerformanceSchemaEventsStatementsTotal),
		metricMysqlQueryAvgTime:                           newMetricMysqlQueryAvgTime(mbc.Metrics.MysqlQueryAvgTime),
		metricMysqlQueryExecutionCount:                    newMetricMysqlQueryExecutionCount(mbc.Metrics.MysqlQueryExecutionCount),
		metricMysqlQueryLockTime:                          newMetricMysqlQueryLockTime(mbc.Metrics.MysqlQueryLockTime),
		metricMysqlQueryMaxTime:                           newMetricMysqlQueryMaxTime(mbc.Metrics.MysqlQueryMaxTime),
		metricMysqlQueryMinTime:                           newMetricMysqlQueryMinTime(mbc.Metrics.MysqlQueryMinTime),
		metricMysqlQueryRowsExamined:                      newMetricMysqlQueryRowsExamined(mbc.Metrics.MysqlQueryRowsExamined),
		metricMysqlQueryRowsSent:                          newMetricMysqlQueryRowsSent(mbc.Metrics.MysqlQueryRowsSent),
		metricMysqlQueryTotalTime:                         newMetricMysqlQueryTotalTime(mbc.Metrics.MysqlQueryTotalTime),
		metricMysqlSlaveIoRunning:                         newMetricMysqlSlaveIoRunning(mbc.Metrics.MysqlSlaveIoRunning),
		metricMysqlSlaveLag:                               newMetricMysqlSlaveLag(mbc.Metrics.MysqlSlaveLag),
		metricMysqlSlaveSQLRunning:                        newMetricMysqlSlaveSQLRunning(mbc.Metrics.MysqlSlaveSQLRunning),
		metricMysqlSlowQueriesCount:                       newMetricMysqlSlowQueriesCount(mbc.Metrics.MysqlSlowQueriesCount),
		metricMysqlSlowQueriesTotalTime:                   newMetricMysqlSlowQueriesTotalTime(mbc.Metrics.MysqlSlowQueriesTotalTime),
		metricMysqlTableIoOperations:                      newMetricMysqlTableIoOperations(mbc.Metrics.MysqlTableIoOperations),
		metricMysqlTableIoWaitTime:                        newMetricMysqlTableIoWaitTime(mbc.Metrics.MysqlTableIoWaitTime),
		metricMysqlWaitEventsCount:                        newMetricMysqlWaitEventsCount(mbc.Metrics.MysqlWaitEventsCount),
		metricMysqlWaitEventsTotalTime:                    newMetricMysqlWaitEventsTotalTime(mbc.Metrics.MysqlWaitEventsTotalTime),
		resourceAttributeIncludeFilter:                    make(map[string]filter.Filter),
		resourceAttributeExcludeFilter:                    make(map[string]filter.Filter),
	}
	if mbc.ResourceAttributes.MysqlInstanceEndpoint.MetricsInclude != nil {
		mb.resourceAttributeIncludeFilter["mysql.instance.endpoint"] = filter.CreateFilter(mbc.ResourceAttributes.MysqlInstanceEndpoint.MetricsInclude)
	}
	if mbc.ResourceAttributes.MysqlInstanceEndpoint.MetricsExclude != nil {
		mb.resourceAttributeExcludeFilter["mysql.instance.endpoint"] = filter.CreateFilter(mbc.ResourceAttributes.MysqlInstanceEndpoint.MetricsExclude)
	}
	if mbc.ResourceAttributes.MysqlInstanceVersion.MetricsInclude != nil {
		mb.resourceAttributeIncludeFilter["mysql.instance.version"] = filter.CreateFilter(mbc.ResourceAttributes.MysqlInstanceVersion.MetricsInclude)
	}
	if mbc.ResourceAttributes.MysqlInstanceVersion.MetricsExclude != nil {
		mb.resourceAttributeExcludeFilter["mysql.instance.version"] = filter.CreateFilter(mbc.ResourceAttributes.MysqlInstanceVersion.MetricsExclude)
	}

	for _, op := range options {
		op.apply(mb)
	}
	return mb
}

// NewResourceBuilder returns a new resource builder that should be used to build a resource associated with for the emitted metrics.
func (mb *MetricsBuilder) NewResourceBuilder() *ResourceBuilder {
	return NewResourceBuilder(mb.config.ResourceAttributes)
}

// updateCapacity updates max length of metrics and resource attributes that will be used for the slice capacity.
func (mb *MetricsBuilder) updateCapacity(rm pmetric.ResourceMetrics) {
	if mb.metricsCapacity < rm.ScopeMetrics().At(0).Metrics().Len() {
		mb.metricsCapacity = rm.ScopeMetrics().At(0).Metrics().Len()
	}
}

// ResourceMetricsOption applies changes to provided resource metrics.
type ResourceMetricsOption interface {
	apply(pmetric.ResourceMetrics)
}

type resourceMetricsOptionFunc func(pmetric.ResourceMetrics)

func (rmof resourceMetricsOptionFunc) apply(rm pmetric.ResourceMetrics) {
	rmof(rm)
}

// WithResource sets the provided resource on the emitted ResourceMetrics.
// It's recommended to use ResourceBuilder to create the resource.
func WithResource(res pcommon.Resource) ResourceMetricsOption {
	return resourceMetricsOptionFunc(func(rm pmetric.ResourceMetrics) {
		res.CopyTo(rm.Resource())
	})
}

// WithStartTimeOverride overrides start time for all the resource metrics data points.
// This option should be only used if different start time has to be set on metrics coming from different resources.
func WithStartTimeOverride(start pcommon.Timestamp) ResourceMetricsOption {
	return resourceMetricsOptionFunc(func(rm pmetric.ResourceMetrics) {
		var dps pmetric.NumberDataPointSlice
		metrics := rm.ScopeMetrics().At(0).Metrics()
		for i := 0; i < metrics.Len(); i++ {
			switch metrics.At(i).Type() {
			case pmetric.MetricTypeGauge:
				dps = metrics.At(i).Gauge().DataPoints()
			case pmetric.MetricTypeSum:
				dps = metrics.At(i).Sum().DataPoints()
			}
			for j := 0; j < dps.Len(); j++ {
				dps.At(j).SetStartTimestamp(start)
			}
		}
	})
}

// EmitForResource saves all the generated metrics under a new resource and updates the internal state to be ready for
// recording another set of data points as part of another resource. This function can be helpful when one scraper
// needs to emit metrics from several resources. Otherwise calling this function is not required,
// just `Emit` function can be called instead.
// Resource attributes should be provided as ResourceMetricsOption arguments.
func (mb *MetricsBuilder) EmitForResource(options ...ResourceMetricsOption) {
	rm := pmetric.NewResourceMetrics()
	ils := rm.ScopeMetrics().AppendEmpty()
	ils.Scope().SetName(ScopeName)
	ils.Scope().SetVersion(mb.buildInfo.Version)
	ils.Metrics().EnsureCapacity(mb.metricsCapacity)
	mb.metricMysqlBlockedSessionsCount.emit(ils.Metrics())
	mb.metricMysqlBlockedSessionsWaitTime.emit(ils.Metrics())
	mb.metricMysqlBlockingSessionsCount.emit(ils.Metrics())
	mb.metricMysqlBufferPoolDataPages.emit(ils.Metrics())
	mb.metricMysqlBufferPoolLimit.emit(ils.Metrics())
	mb.metricMysqlBufferPoolOperations.emit(ils.Metrics())
	mb.metricMysqlBufferPoolPages.emit(ils.Metrics())
	mb.metricMysqlBufferPoolUsage.emit(ils.Metrics())
	mb.metricMysqlCommands.emit(ils.Metrics())
	mb.metricMysqlConnectionCount.emit(ils.Metrics())
	mb.metricMysqlConnectionErrors.emit(ils.Metrics())
	mb.metricMysqlHandlers.emit(ils.Metrics())
	mb.metricMysqlIndexIoOperations.emit(ils.Metrics())
	mb.metricMysqlIndexIoWaitTime.emit(ils.Metrics())
	mb.metricMysqlInnodbBufferPoolReadRequests.emit(ils.Metrics())
	mb.metricMysqlInnodbBufferPoolReads.emit(ils.Metrics())
	mb.metricMysqlInnodbBufferPoolWriteRequests.emit(ils.Metrics())
	mb.metricMysqlInnodbDataRead.emit(ils.Metrics())
	mb.metricMysqlInnodbDataReads.emit(ils.Metrics())
	mb.metricMysqlInnodbDataWrites.emit(ils.Metrics())
	mb.metricMysqlInnodbDataWritten.emit(ils.Metrics())
	mb.metricMysqlPerformanceSchemaEventsStatementsTime.emit(ils.Metrics())
	mb.metricMysqlPerformanceSchemaEventsStatementsTotal.emit(ils.Metrics())
	mb.metricMysqlQueryAvgTime.emit(ils.Metrics())
	mb.metricMysqlQueryExecutionCount.emit(ils.Metrics())
	mb.metricMysqlQueryLockTime.emit(ils.Metrics())
	mb.metricMysqlQueryMaxTime.emit(ils.Metrics())
	mb.metricMysqlQueryMinTime.emit(ils.Metrics())
	mb.metricMysqlQueryRowsExamined.emit(ils.Metrics())
	mb.metricMysqlQueryRowsSent.emit(ils.Metrics())
	mb.metricMysqlQueryTotalTime.emit(ils.Metrics())
	mb.metricMysqlSlaveIoRunning.emit(ils.Metrics())
	mb.metricMysqlSlaveLag.emit(ils.Metrics())
	mb.metricMysqlSlaveSQLRunning.emit(ils.Metrics())
	mb.metricMysqlSlowQueriesCount.emit(ils.Metrics())
	mb.metricMysqlSlowQueriesTotalTime.emit(ils.Metrics())
	mb.metricMysqlTableIoOperations.emit(ils.Metrics())
	mb.metricMysqlTableIoWaitTime.emit(ils.Metrics())
	mb.metricMysqlWaitEventsCount.emit(ils.Metrics())
	mb.metricMysqlWaitEventsTotalTime.emit(ils.Metrics())

	for _, op := range options {
		op.apply(rm)
	}
	for attr, filter := range mb.resourceAttributeIncludeFilter {
		if val, ok := rm.Resource().Attributes().Get(attr); ok && !filter.Matches(val.AsString()) {
			return
		}
	}
	for attr, filter := range mb.resourceAttributeExcludeFilter {
		if val, ok := rm.Resource().Attributes().Get(attr); ok && filter.Matches(val.AsString()) {
			return
		}
	}

	if ils.Metrics().Len() > 0 {
		mb.updateCapacity(rm)
		rm.MoveTo(mb.metricsBuffer.ResourceMetrics().AppendEmpty())
	}
}

// Emit returns all the metrics accumulated by the metrics builder and updates the internal state to be ready for
// recording another set of metrics. This function will be responsible for applying all the transformations required to
// produce metric representation defined in metadata and user config, e.g. delta or cumulative.
func (mb *MetricsBuilder) Emit(options ...ResourceMetricsOption) pmetric.Metrics {
	mb.EmitForResource(options...)
	metrics := mb.metricsBuffer
	mb.metricsBuffer = pmetric.NewMetrics()
	return metrics
}

// RecordMysqlBlockedSessionsCountDataPoint adds a data point to mysql.blocked_sessions.count metric.
func (mb *MetricsBuilder) RecordMysqlBlockedSessionsCountDataPoint(ts pcommon.Timestamp, val int64, blockedSessionIDAttributeValue string) {
	mb.metricMysqlBlockedSessionsCount.recordDataPoint(mb.startTime, ts, val, blockedSessionIDAttributeValue)
}

// RecordMysqlBlockedSessionsWaitTimeDataPoint adds a data point to mysql.blocked_sessions.wait_time metric.
func (mb *MetricsBuilder) RecordMysqlBlockedSessionsWaitTimeDataPoint(ts pcommon.Timestamp, val float64, blockedSessionIDAttributeValue string, blockingSessionIDAttributeValue string) {
	mb.metricMysqlBlockedSessionsWaitTime.recordDataPoint(mb.startTime, ts, val, blockedSessionIDAttributeValue, blockingSessionIDAttributeValue)
}

// RecordMysqlBlockingSessionsCountDataPoint adds a data point to mysql.blocking_sessions.count metric.
func (mb *MetricsBuilder) RecordMysqlBlockingSessionsCountDataPoint(ts pcommon.Timestamp, val int64, blockingSessionIDAttributeValue string) {
	mb.metricMysqlBlockingSessionsCount.recordDataPoint(mb.startTime, ts, val, blockingSessionIDAttributeValue)
}

// RecordMysqlBufferPoolDataPagesDataPoint adds a data point to mysql.buffer_pool.data_pages metric.
func (mb *MetricsBuilder) RecordMysqlBufferPoolDataPagesDataPoint(ts pcommon.Timestamp, val int64, bufferPoolDataAttributeValue AttributeBufferPoolData) {
	mb.metricMysqlBufferPoolDataPages.recordDataPoint(mb.startTime, ts, val, bufferPoolDataAttributeValue.String())
}

// RecordMysqlBufferPoolLimitDataPoint adds a data point to mysql.buffer_pool.limit metric.
func (mb *MetricsBuilder) RecordMysqlBufferPoolLimitDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricMysqlBufferPoolLimit.recordDataPoint(mb.startTime, ts, val)
}

// RecordMysqlBufferPoolOperationsDataPoint adds a data point to mysql.buffer_pool.operations metric.
func (mb *MetricsBuilder) RecordMysqlBufferPoolOperationsDataPoint(ts pcommon.Timestamp, val int64, bufferPoolOperationsAttributeValue AttributeBufferPoolOperations) {
	mb.metricMysqlBufferPoolOperations.recordDataPoint(mb.startTime, ts, val, bufferPoolOperationsAttributeValue.String())
}

// RecordMysqlBufferPoolPagesDataPoint adds a data point to mysql.buffer_pool.pages metric.
func (mb *MetricsBuilder) RecordMysqlBufferPoolPagesDataPoint(ts pcommon.Timestamp, val int64, bufferPoolPagesAttributeValue AttributeBufferPoolPages) {
	mb.metricMysqlBufferPoolPages.recordDataPoint(mb.startTime, ts, val, bufferPoolPagesAttributeValue.String())
}

// RecordMysqlBufferPoolUsageDataPoint adds a data point to mysql.buffer_pool.usage metric.
func (mb *MetricsBuilder) RecordMysqlBufferPoolUsageDataPoint(ts pcommon.Timestamp, val int64, bufferPoolDataAttributeValue AttributeBufferPoolData) {
	mb.metricMysqlBufferPoolUsage.recordDataPoint(mb.startTime, ts, val, bufferPoolDataAttributeValue.String())
}

// RecordMysqlCommandsDataPoint adds a data point to mysql.commands metric.
func (mb *MetricsBuilder) RecordMysqlCommandsDataPoint(ts pcommon.Timestamp, val int64, commandAttributeValue AttributeCommand) {
	mb.metricMysqlCommands.recordDataPoint(mb.startTime, ts, val, commandAttributeValue.String())
}

// RecordMysqlConnectionCountDataPoint adds a data point to mysql.connection.count metric.
func (mb *MetricsBuilder) RecordMysqlConnectionCountDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricMysqlConnectionCount.recordDataPoint(mb.startTime, ts, val)
}

// RecordMysqlConnectionErrorsDataPoint adds a data point to mysql.connection.errors metric.
func (mb *MetricsBuilder) RecordMysqlConnectionErrorsDataPoint(ts pcommon.Timestamp, val int64, connectionErrorAttributeValue AttributeConnectionError) {
	mb.metricMysqlConnectionErrors.recordDataPoint(mb.startTime, ts, val, connectionErrorAttributeValue.String())
}

// RecordMysqlHandlersDataPoint adds a data point to mysql.handlers metric.
func (mb *MetricsBuilder) RecordMysqlHandlersDataPoint(ts pcommon.Timestamp, val int64, handlerAttributeValue AttributeHandler) {
	mb.metricMysqlHandlers.recordDataPoint(mb.startTime, ts, val, handlerAttributeValue.String())
}

// RecordMysqlIndexIoOperationsDataPoint adds a data point to mysql.index_io.operations metric.
func (mb *MetricsBuilder) RecordMysqlIndexIoOperationsDataPoint(ts pcommon.Timestamp, val int64, schemaNameAttributeValue string, tableNameAttributeValue string, indexNameAttributeValue string) {
	mb.metricMysqlIndexIoOperations.recordDataPoint(mb.startTime, ts, val, schemaNameAttributeValue, tableNameAttributeValue, indexNameAttributeValue)
}

// RecordMysqlIndexIoWaitTimeDataPoint adds a data point to mysql.index_io.wait_time metric.
func (mb *MetricsBuilder) RecordMysqlIndexIoWaitTimeDataPoint(ts pcommon.Timestamp, val float64, schemaNameAttributeValue string, tableNameAttributeValue string, indexNameAttributeValue string) {
	mb.metricMysqlIndexIoWaitTime.recordDataPoint(mb.startTime, ts, val, schemaNameAttributeValue, tableNameAttributeValue, indexNameAttributeValue)
}

// RecordMysqlInnodbBufferPoolReadRequestsDataPoint adds a data point to mysql.innodb.buffer_pool_read_requests metric.
func (mb *MetricsBuilder) RecordMysqlInnodbBufferPoolReadRequestsDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricMysqlInnodbBufferPoolReadRequests.recordDataPoint(mb.startTime, ts, val)
}

// RecordMysqlInnodbBufferPoolReadsDataPoint adds a data point to mysql.innodb.buffer_pool_reads metric.
func (mb *MetricsBuilder) RecordMysqlInnodbBufferPoolReadsDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricMysqlInnodbBufferPoolReads.recordDataPoint(mb.startTime, ts, val)
}

// RecordMysqlInnodbBufferPoolWriteRequestsDataPoint adds a data point to mysql.innodb.buffer_pool_write_requests metric.
func (mb *MetricsBuilder) RecordMysqlInnodbBufferPoolWriteRequestsDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricMysqlInnodbBufferPoolWriteRequests.recordDataPoint(mb.startTime, ts, val)
}

// RecordMysqlInnodbDataReadDataPoint adds a data point to mysql.innodb.data_read metric.
func (mb *MetricsBuilder) RecordMysqlInnodbDataReadDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricMysqlInnodbDataRead.recordDataPoint(mb.startTime, ts, val)
}

// RecordMysqlInnodbDataReadsDataPoint adds a data point to mysql.innodb.data_reads metric.
func (mb *MetricsBuilder) RecordMysqlInnodbDataReadsDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricMysqlInnodbDataReads.recordDataPoint(mb.startTime, ts, val)
}

// RecordMysqlInnodbDataWritesDataPoint adds a data point to mysql.innodb.data_writes metric.
func (mb *MetricsBuilder) RecordMysqlInnodbDataWritesDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricMysqlInnodbDataWrites.recordDataPoint(mb.startTime, ts, val)
}

// RecordMysqlInnodbDataWrittenDataPoint adds a data point to mysql.innodb.data_written metric.
func (mb *MetricsBuilder) RecordMysqlInnodbDataWrittenDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricMysqlInnodbDataWritten.recordDataPoint(mb.startTime, ts, val)
}

// RecordMysqlPerformanceSchemaEventsStatementsTimeDataPoint adds a data point to mysql.performance_schema.events_statements_time metric.
func (mb *MetricsBuilder) RecordMysqlPerformanceSchemaEventsStatementsTimeDataPoint(ts pcommon.Timestamp, val float64, queryDigestAttributeValue string, queryTypeAttributeValue AttributeQueryType) {
	mb.metricMysqlPerformanceSchemaEventsStatementsTime.recordDataPoint(mb.startTime, ts, val, queryDigestAttributeValue, queryTypeAttributeValue.String())
}

// RecordMysqlPerformanceSchemaEventsStatementsTotalDataPoint adds a data point to mysql.performance_schema.events_statements_total metric.
func (mb *MetricsBuilder) RecordMysqlPerformanceSchemaEventsStatementsTotalDataPoint(ts pcommon.Timestamp, val int64, queryDigestAttributeValue string, queryTypeAttributeValue AttributeQueryType) {
	mb.metricMysqlPerformanceSchemaEventsStatementsTotal.recordDataPoint(mb.startTime, ts, val, queryDigestAttributeValue, queryTypeAttributeValue.String())
}

// RecordMysqlQueryAvgTimeDataPoint adds a data point to mysql.query.avg_time metric.
func (mb *MetricsBuilder) RecordMysqlQueryAvgTimeDataPoint(ts pcommon.Timestamp, val float64, queryDigestAttributeValue string, queryTypeAttributeValue AttributeQueryType, schemaNameAttributeValue string) {
	mb.metricMysqlQueryAvgTime.recordDataPoint(mb.startTime, ts, val, queryDigestAttributeValue, queryTypeAttributeValue.String(), schemaNameAttributeValue)
}

// RecordMysqlQueryExecutionCountDataPoint adds a data point to mysql.query.execution_count metric.
func (mb *MetricsBuilder) RecordMysqlQueryExecutionCountDataPoint(ts pcommon.Timestamp, val int64, queryDigestAttributeValue string, queryTypeAttributeValue AttributeQueryType, schemaNameAttributeValue string) {
	mb.metricMysqlQueryExecutionCount.recordDataPoint(mb.startTime, ts, val, queryDigestAttributeValue, queryTypeAttributeValue.String(), schemaNameAttributeValue)
}

// RecordMysqlQueryLockTimeDataPoint adds a data point to mysql.query.lock_time metric.
func (mb *MetricsBuilder) RecordMysqlQueryLockTimeDataPoint(ts pcommon.Timestamp, val float64, queryDigestAttributeValue string, queryTypeAttributeValue AttributeQueryType, schemaNameAttributeValue string) {
	mb.metricMysqlQueryLockTime.recordDataPoint(mb.startTime, ts, val, queryDigestAttributeValue, queryTypeAttributeValue.String(), schemaNameAttributeValue)
}

// RecordMysqlQueryMaxTimeDataPoint adds a data point to mysql.query.max_time metric.
func (mb *MetricsBuilder) RecordMysqlQueryMaxTimeDataPoint(ts pcommon.Timestamp, val float64, queryDigestAttributeValue string, queryTypeAttributeValue AttributeQueryType, schemaNameAttributeValue string) {
	mb.metricMysqlQueryMaxTime.recordDataPoint(mb.startTime, ts, val, queryDigestAttributeValue, queryTypeAttributeValue.String(), schemaNameAttributeValue)
}

// RecordMysqlQueryMinTimeDataPoint adds a data point to mysql.query.min_time metric.
func (mb *MetricsBuilder) RecordMysqlQueryMinTimeDataPoint(ts pcommon.Timestamp, val float64, queryDigestAttributeValue string, queryTypeAttributeValue AttributeQueryType, schemaNameAttributeValue string) {
	mb.metricMysqlQueryMinTime.recordDataPoint(mb.startTime, ts, val, queryDigestAttributeValue, queryTypeAttributeValue.String(), schemaNameAttributeValue)
}

// RecordMysqlQueryRowsExaminedDataPoint adds a data point to mysql.query.rows_examined metric.
func (mb *MetricsBuilder) RecordMysqlQueryRowsExaminedDataPoint(ts pcommon.Timestamp, val int64, queryDigestAttributeValue string, queryTypeAttributeValue AttributeQueryType, schemaNameAttributeValue string) {
	mb.metricMysqlQueryRowsExamined.recordDataPoint(mb.startTime, ts, val, queryDigestAttributeValue, queryTypeAttributeValue.String(), schemaNameAttributeValue)
}

// RecordMysqlQueryRowsSentDataPoint adds a data point to mysql.query.rows_sent metric.
func (mb *MetricsBuilder) RecordMysqlQueryRowsSentDataPoint(ts pcommon.Timestamp, val int64, queryDigestAttributeValue string, queryTypeAttributeValue AttributeQueryType, schemaNameAttributeValue string) {
	mb.metricMysqlQueryRowsSent.recordDataPoint(mb.startTime, ts, val, queryDigestAttributeValue, queryTypeAttributeValue.String(), schemaNameAttributeValue)
}

// RecordMysqlQueryTotalTimeDataPoint adds a data point to mysql.query.total_time metric.
func (mb *MetricsBuilder) RecordMysqlQueryTotalTimeDataPoint(ts pcommon.Timestamp, val float64, queryDigestAttributeValue string, queryTypeAttributeValue AttributeQueryType, schemaNameAttributeValue string) {
	mb.metricMysqlQueryTotalTime.recordDataPoint(mb.startTime, ts, val, queryDigestAttributeValue, queryTypeAttributeValue.String(), schemaNameAttributeValue)
}

// RecordMysqlSlaveIoRunningDataPoint adds a data point to mysql.slave_io_running metric.
func (mb *MetricsBuilder) RecordMysqlSlaveIoRunningDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricMysqlSlaveIoRunning.recordDataPoint(mb.startTime, ts, val)
}

// RecordMysqlSlaveLagDataPoint adds a data point to mysql.slave_lag metric.
func (mb *MetricsBuilder) RecordMysqlSlaveLagDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricMysqlSlaveLag.recordDataPoint(mb.startTime, ts, val)
}

// RecordMysqlSlaveSQLRunningDataPoint adds a data point to mysql.slave_sql_running metric.
func (mb *MetricsBuilder) RecordMysqlSlaveSQLRunningDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricMysqlSlaveSQLRunning.recordDataPoint(mb.startTime, ts, val)
}

// RecordMysqlSlowQueriesCountDataPoint adds a data point to mysql.slow_queries.count metric.
func (mb *MetricsBuilder) RecordMysqlSlowQueriesCountDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricMysqlSlowQueriesCount.recordDataPoint(mb.startTime, ts, val)
}

// RecordMysqlSlowQueriesTotalTimeDataPoint adds a data point to mysql.slow_queries.total_time metric.
func (mb *MetricsBuilder) RecordMysqlSlowQueriesTotalTimeDataPoint(ts pcommon.Timestamp, val float64) {
	mb.metricMysqlSlowQueriesTotalTime.recordDataPoint(mb.startTime, ts, val)
}

// RecordMysqlTableIoOperationsDataPoint adds a data point to mysql.table_io.operations metric.
func (mb *MetricsBuilder) RecordMysqlTableIoOperationsDataPoint(ts pcommon.Timestamp, val int64, schemaNameAttributeValue string, tableNameAttributeValue string) {
	mb.metricMysqlTableIoOperations.recordDataPoint(mb.startTime, ts, val, schemaNameAttributeValue, tableNameAttributeValue)
}

// RecordMysqlTableIoWaitTimeDataPoint adds a data point to mysql.table_io.wait_time metric.
func (mb *MetricsBuilder) RecordMysqlTableIoWaitTimeDataPoint(ts pcommon.Timestamp, val float64, schemaNameAttributeValue string, tableNameAttributeValue string) {
	mb.metricMysqlTableIoWaitTime.recordDataPoint(mb.startTime, ts, val, schemaNameAttributeValue, tableNameAttributeValue)
}

// RecordMysqlWaitEventsCountDataPoint adds a data point to mysql.wait_events.count metric.
func (mb *MetricsBuilder) RecordMysqlWaitEventsCountDataPoint(ts pcommon.Timestamp, val int64, waitEventTypeAttributeValue AttributeWaitEventType, waitEventAttributeValue string) {
	mb.metricMysqlWaitEventsCount.recordDataPoint(mb.startTime, ts, val, waitEventTypeAttributeValue.String(), waitEventAttributeValue)
}

// RecordMysqlWaitEventsTotalTimeDataPoint adds a data point to mysql.wait_events.total_time metric.
func (mb *MetricsBuilder) RecordMysqlWaitEventsTotalTimeDataPoint(ts pcommon.Timestamp, val float64, waitEventTypeAttributeValue AttributeWaitEventType, waitEventAttributeValue string) {
	mb.metricMysqlWaitEventsTotalTime.recordDataPoint(mb.startTime, ts, val, waitEventTypeAttributeValue.String(), waitEventAttributeValue)
}

// Reset resets metrics builder to its initial state. It should be used when external metrics source is restarted,
// and metrics builder should update its startTime and reset it's internal state accordingly.
func (mb *MetricsBuilder) Reset(options ...MetricBuilderOption) {
	mb.startTime = pcommon.NewTimestampFromTime(time.Now())
	for _, op := range options {
		op.apply(mb)
	}
}
