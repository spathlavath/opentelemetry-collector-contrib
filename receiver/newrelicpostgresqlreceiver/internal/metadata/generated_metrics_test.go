// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"testing"

	"github.com/stretchr/testify/assert"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
	"go.opentelemetry.io/collector/receiver/receivertest"
	"go.uber.org/zap"
	"go.uber.org/zap/zaptest/observer"
)

type testDataSet int

const (
	testDataSetDefault testDataSet = iota
	testDataSetAll
	testDataSetNone
)

func TestMetricsBuilder(t *testing.T) {
	tests := []struct {
		name        string
		metricsSet  testDataSet
		resAttrsSet testDataSet
		expectEmpty bool
	}{
		{
			name: "default",
		},
		{
			name:        "all_set",
			metricsSet:  testDataSetAll,
			resAttrsSet: testDataSetAll,
		},
		{
			name:        "none_set",
			metricsSet:  testDataSetNone,
			resAttrsSet: testDataSetNone,
			expectEmpty: true,
		},
		{
			name:        "filter_set_include",
			resAttrsSet: testDataSetAll,
		},
		{
			name:        "filter_set_exclude",
			resAttrsSet: testDataSetAll,
			expectEmpty: true,
		},
	}
	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			start := pcommon.Timestamp(1_000_000_000)
			ts := pcommon.Timestamp(1_000_001_000)
			observedZapCore, observedLogs := observer.New(zap.WarnLevel)
			settings := receivertest.NewNopSettings(receivertest.NopType)
			settings.Logger = zap.New(observedZapCore)
			mb := NewMetricsBuilder(loadMetricsBuilderConfig(t, tt.name), settings, WithStartTime(start))

			expectedWarnings := 0

			assert.Equal(t, expectedWarnings, observedLogs.Len())

			defaultMetricsCount := 0
			allMetricsCount := 0

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBeforeXidWraparoundDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBlkReadTimeDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBlkWriteTimeDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBufferHitDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlChecksumsEnabledDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlChecksumsFailuresDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlCommitsDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlConflictsDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlConflictsBufferpinDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlConflictsDeadlockDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlConflictsLockDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlConflictsSnapshotDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlConflictsTablespaceDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlConnectionsDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlDatabaseSizeDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlDeadlocksDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlDiskReadDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationBackendXminAgeDataPoint(ts, 1, "application_name-val", "client_address-val", "replication_state-val", "sync_state-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationFlushLsnDelayDataPoint(ts, 1, "application_name-val", "client_address-val", "replication_state-val", "sync_state-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationReplayLsnDelayDataPoint(ts, 1, "application_name-val", "client_address-val", "replication_state-val", "sync_state-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationSentLsnDelayDataPoint(ts, 1, "application_name-val", "client_address-val", "replication_state-val", "sync_state-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationWalFlushLagDataPoint(ts, 1, "application_name-val", "client_address-val", "replication_state-val", "sync_state-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationWalReplayLagDataPoint(ts, 1, "application_name-val", "client_address-val", "replication_state-val", "sync_state-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationWalWriteLagDataPoint(ts, 1, "application_name-val", "client_address-val", "replication_state-val", "sync_state-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationWriteLsnDelayDataPoint(ts, 1, "application_name-val", "client_address-val", "replication_state-val", "sync_state-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationDelayDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationDelayBytesDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationSlotCatalogXminAgeDataPoint(ts, 1, "slot_name-val", "slot_type-val", "plugin-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationSlotConfirmedFlushDelayBytesDataPoint(ts, 1, "slot_name-val", "slot_type-val", "plugin-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationSlotRestartDelayBytesDataPoint(ts, 1, "slot_name-val", "slot_type-val", "plugin-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationSlotSpillBytesDataPoint(ts, 1, "slot_name-val", "slot_type-val", "state-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationSlotSpillCountDataPoint(ts, 1, "slot_name-val", "slot_type-val", "state-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationSlotSpillTxnsDataPoint(ts, 1, "slot_name-val", "slot_type-val", "state-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationSlotStreamBytesDataPoint(ts, 1, "slot_name-val", "slot_type-val", "state-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationSlotStreamCountDataPoint(ts, 1, "slot_name-val", "slot_type-val", "state-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationSlotStreamTxnsDataPoint(ts, 1, "slot_name-val", "slot_type-val", "state-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationSlotTotalBytesDataPoint(ts, 1, "slot_name-val", "slot_type-val", "state-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationSlotTotalTxnsDataPoint(ts, 1, "slot_name-val", "slot_type-val", "state-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationSlotXminAgeDataPoint(ts, 1, "slot_name-val", "slot_type-val", "plugin-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlRollbacksDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlRowsDeletedDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlRowsFetchedDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlRowsInsertedDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlRowsReturnedDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlRowsUpdatedDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSessionsAbandonedDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSessionsActiveTimeDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSessionsCountDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSessionsFatalDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSessionsIdleInTransactionTimeDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSessionsKilledDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSessionsSessionTimeDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSubscriptionApplyErrorDataPoint(ts, 1, "subscription_name-val", "state-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSubscriptionLastMsgReceiptAgeDataPoint(ts, 1, "subscription_name-val", "state-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSubscriptionLastMsgSendAgeDataPoint(ts, 1, "subscription_name-val", "state-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSubscriptionLatestEndAgeDataPoint(ts, 1, "subscription_name-val", "state-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSubscriptionSyncErrorDataPoint(ts, 1, "subscription_name-val", "state-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlTempBytesDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlTempFilesDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalBuffersFullDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalBytesDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalFpiDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalRecordsDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalSyncDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalSyncTimeDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalWriteDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalWriteTimeDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalFilesAgeDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalFilesCountDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalFilesSizeDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalReceiverConnectedDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalReceiverLastMsgReceiptAgeDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalReceiverLastMsgSendAgeDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalReceiverLatestEndAgeDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalReceiverReceivedTimelineDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			rb := mb.NewResourceBuilder()
			rb.SetDatabaseName("database_name-val")
			rb.SetDbSystem("db.system-val")
			rb.SetNewrelicpostgresqlInstanceName("newrelicpostgresql.instance_name-val")
			rb.SetPostgresqlVersion("postgresql.version-val")
			rb.SetServerAddress("server.address-val")
			rb.SetServerPort("server.port-val")
			res := rb.Emit()
			metrics := mb.Emit(WithResource(res))

			if tt.expectEmpty {
				assert.Equal(t, 0, metrics.ResourceMetrics().Len())
				return
			}

			assert.Equal(t, 1, metrics.ResourceMetrics().Len())
			rm := metrics.ResourceMetrics().At(0)
			assert.Equal(t, res, rm.Resource())
			assert.Equal(t, 1, rm.ScopeMetrics().Len())
			ms := rm.ScopeMetrics().At(0).Metrics()
			if tt.metricsSet == testDataSetDefault {
				assert.Equal(t, defaultMetricsCount, ms.Len())
			}
			if tt.metricsSet == testDataSetAll {
				assert.Equal(t, allMetricsCount, ms.Len())
			}
			validatedMetrics := make(map[string]bool)
			for i := 0; i < ms.Len(); i++ {
				switch ms.At(i).Name() {
				case "postgresql.before_xid_wraparound":
					assert.False(t, validatedMetrics["postgresql.before_xid_wraparound"], "Found a duplicate in the metrics slice: postgresql.before_xid_wraparound")
					validatedMetrics["postgresql.before_xid_wraparound"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of transactions before XID wraparound occurs", ms.At(i).Description())
					assert.Equal(t, "{transactions}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.blk_read_time":
					assert.False(t, validatedMetrics["postgresql.blk_read_time"], "Found a duplicate in the metrics slice: postgresql.blk_read_time")
					validatedMetrics["postgresql.blk_read_time"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time spent reading data file blocks (milliseconds)", ms.At(i).Description())
					assert.Equal(t, "ms", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.blk_write_time":
					assert.False(t, validatedMetrics["postgresql.blk_write_time"], "Found a duplicate in the metrics slice: postgresql.blk_write_time")
					validatedMetrics["postgresql.blk_write_time"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time spent writing data file blocks (milliseconds)", ms.At(i).Description())
					assert.Equal(t, "ms", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.buffer_hit":
					assert.False(t, validatedMetrics["postgresql.buffer_hit"], "Found a duplicate in the metrics slice: postgresql.buffer_hit")
					validatedMetrics["postgresql.buffer_hit"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of times disk blocks were found in the buffer cache", ms.At(i).Description())
					assert.Equal(t, "{blocks}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.checksums.enabled":
					assert.False(t, validatedMetrics["postgresql.checksums.enabled"], "Found a duplicate in the metrics slice: postgresql.checksums.enabled")
					validatedMetrics["postgresql.checksums.enabled"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Whether data checksums are enabled for this PostgreSQL cluster (PostgreSQL 12+)", ms.At(i).Description())
					assert.Equal(t, "{status}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.checksums.failures":
					assert.False(t, validatedMetrics["postgresql.checksums.failures"], "Found a duplicate in the metrics slice: postgresql.checksums.failures")
					validatedMetrics["postgresql.checksums.failures"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of data page checksum failures detected (PostgreSQL 12+)", ms.At(i).Description())
					assert.Equal(t, "{failures}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.commits":
					assert.False(t, validatedMetrics["postgresql.commits"], "Found a duplicate in the metrics slice: postgresql.commits")
					validatedMetrics["postgresql.commits"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of transactions that have been committed", ms.At(i).Description())
					assert.Equal(t, "{transactions}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.conflicts":
					assert.False(t, validatedMetrics["postgresql.conflicts"], "Found a duplicate in the metrics slice: postgresql.conflicts")
					validatedMetrics["postgresql.conflicts"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of queries canceled due to conflicts with recovery", ms.At(i).Description())
					assert.Equal(t, "{queries}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.conflicts.bufferpin":
					assert.False(t, validatedMetrics["postgresql.conflicts.bufferpin"], "Found a duplicate in the metrics slice: postgresql.conflicts.bufferpin")
					validatedMetrics["postgresql.conflicts.bufferpin"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Queries canceled due to pinned buffers during recovery", ms.At(i).Description())
					assert.Equal(t, "{queries}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.conflicts.deadlock":
					assert.False(t, validatedMetrics["postgresql.conflicts.deadlock"], "Found a duplicate in the metrics slice: postgresql.conflicts.deadlock")
					validatedMetrics["postgresql.conflicts.deadlock"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Queries canceled due to deadlocks during recovery", ms.At(i).Description())
					assert.Equal(t, "{queries}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.conflicts.lock":
					assert.False(t, validatedMetrics["postgresql.conflicts.lock"], "Found a duplicate in the metrics slice: postgresql.conflicts.lock")
					validatedMetrics["postgresql.conflicts.lock"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Queries canceled due to lock timeouts during recovery", ms.At(i).Description())
					assert.Equal(t, "{queries}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.conflicts.snapshot":
					assert.False(t, validatedMetrics["postgresql.conflicts.snapshot"], "Found a duplicate in the metrics slice: postgresql.conflicts.snapshot")
					validatedMetrics["postgresql.conflicts.snapshot"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Queries canceled due to old snapshots during recovery", ms.At(i).Description())
					assert.Equal(t, "{queries}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.conflicts.tablespace":
					assert.False(t, validatedMetrics["postgresql.conflicts.tablespace"], "Found a duplicate in the metrics slice: postgresql.conflicts.tablespace")
					validatedMetrics["postgresql.conflicts.tablespace"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Queries canceled due to dropped tablespaces during recovery", ms.At(i).Description())
					assert.Equal(t, "{queries}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.connections":
					assert.False(t, validatedMetrics["postgresql.connections"], "Found a duplicate in the metrics slice: postgresql.connections")
					validatedMetrics["postgresql.connections"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of active connections (backends) to the database", ms.At(i).Description())
					assert.Equal(t, "{connections}", ms.At(i).Unit())
					assert.False(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.database_size":
					assert.False(t, validatedMetrics["postgresql.database_size"], "Found a duplicate in the metrics slice: postgresql.database_size")
					validatedMetrics["postgresql.database_size"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Size of the database in bytes", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.deadlocks":
					assert.False(t, validatedMetrics["postgresql.deadlocks"], "Found a duplicate in the metrics slice: postgresql.deadlocks")
					validatedMetrics["postgresql.deadlocks"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of deadlocks detected", ms.At(i).Description())
					assert.Equal(t, "{deadlocks}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.disk_read":
					assert.False(t, validatedMetrics["postgresql.disk_read"], "Found a duplicate in the metrics slice: postgresql.disk_read")
					validatedMetrics["postgresql.disk_read"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of disk blocks read", ms.At(i).Description())
					assert.Equal(t, "{blocks}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.replication.backend_xmin_age":
					assert.False(t, validatedMetrics["postgresql.replication.backend_xmin_age"], "Found a duplicate in the metrics slice: postgresql.replication.backend_xmin_age")
					validatedMetrics["postgresql.replication.backend_xmin_age"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Age of the oldest transaction on the standby server that is holding back vacuum", ms.At(i).Description())
					assert.Equal(t, "{transactions}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("application_name")
					assert.True(t, ok)
					assert.Equal(t, "application_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("client_address")
					assert.True(t, ok)
					assert.Equal(t, "client_address-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("replication_state")
					assert.True(t, ok)
					assert.Equal(t, "replication_state-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("sync_state")
					assert.True(t, ok)
					assert.Equal(t, "sync_state-val", attrVal.Str())
				case "postgresql.replication.flush_lsn_delay":
					assert.False(t, validatedMetrics["postgresql.replication.flush_lsn_delay"], "Found a duplicate in the metrics slice: postgresql.replication.flush_lsn_delay")
					validatedMetrics["postgresql.replication.flush_lsn_delay"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of bytes of WAL flushed but not yet applied on standby", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("application_name")
					assert.True(t, ok)
					assert.Equal(t, "application_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("client_address")
					assert.True(t, ok)
					assert.Equal(t, "client_address-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("replication_state")
					assert.True(t, ok)
					assert.Equal(t, "replication_state-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("sync_state")
					assert.True(t, ok)
					assert.Equal(t, "sync_state-val", attrVal.Str())
				case "postgresql.replication.replay_lsn_delay":
					assert.False(t, validatedMetrics["postgresql.replication.replay_lsn_delay"], "Found a duplicate in the metrics slice: postgresql.replication.replay_lsn_delay")
					validatedMetrics["postgresql.replication.replay_lsn_delay"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of bytes of WAL not yet replayed on standby (total replication lag in bytes)", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("application_name")
					assert.True(t, ok)
					assert.Equal(t, "application_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("client_address")
					assert.True(t, ok)
					assert.Equal(t, "client_address-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("replication_state")
					assert.True(t, ok)
					assert.Equal(t, "replication_state-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("sync_state")
					assert.True(t, ok)
					assert.Equal(t, "sync_state-val", attrVal.Str())
				case "postgresql.replication.sent_lsn_delay":
					assert.False(t, validatedMetrics["postgresql.replication.sent_lsn_delay"], "Found a duplicate in the metrics slice: postgresql.replication.sent_lsn_delay")
					validatedMetrics["postgresql.replication.sent_lsn_delay"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of bytes of WAL sent but not yet written to disk on standby", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("application_name")
					assert.True(t, ok)
					assert.Equal(t, "application_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("client_address")
					assert.True(t, ok)
					assert.Equal(t, "client_address-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("replication_state")
					assert.True(t, ok)
					assert.Equal(t, "replication_state-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("sync_state")
					assert.True(t, ok)
					assert.Equal(t, "sync_state-val", attrVal.Str())
				case "postgresql.replication.wal_flush_lag":
					assert.False(t, validatedMetrics["postgresql.replication.wal_flush_lag"], "Found a duplicate in the metrics slice: postgresql.replication.wal_flush_lag")
					validatedMetrics["postgresql.replication.wal_flush_lag"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time elapsed between WAL flush on primary and confirmation from standby (PostgreSQL 10+)", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("application_name")
					assert.True(t, ok)
					assert.Equal(t, "application_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("client_address")
					assert.True(t, ok)
					assert.Equal(t, "client_address-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("replication_state")
					assert.True(t, ok)
					assert.Equal(t, "replication_state-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("sync_state")
					assert.True(t, ok)
					assert.Equal(t, "sync_state-val", attrVal.Str())
				case "postgresql.replication.wal_replay_lag":
					assert.False(t, validatedMetrics["postgresql.replication.wal_replay_lag"], "Found a duplicate in the metrics slice: postgresql.replication.wal_replay_lag")
					validatedMetrics["postgresql.replication.wal_replay_lag"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time elapsed between WAL replay on primary and confirmation from standby (PostgreSQL 10+)", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("application_name")
					assert.True(t, ok)
					assert.Equal(t, "application_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("client_address")
					assert.True(t, ok)
					assert.Equal(t, "client_address-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("replication_state")
					assert.True(t, ok)
					assert.Equal(t, "replication_state-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("sync_state")
					assert.True(t, ok)
					assert.Equal(t, "sync_state-val", attrVal.Str())
				case "postgresql.replication.wal_write_lag":
					assert.False(t, validatedMetrics["postgresql.replication.wal_write_lag"], "Found a duplicate in the metrics slice: postgresql.replication.wal_write_lag")
					validatedMetrics["postgresql.replication.wal_write_lag"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time elapsed between WAL write on primary and confirmation from standby (PostgreSQL 10+)", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("application_name")
					assert.True(t, ok)
					assert.Equal(t, "application_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("client_address")
					assert.True(t, ok)
					assert.Equal(t, "client_address-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("replication_state")
					assert.True(t, ok)
					assert.Equal(t, "replication_state-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("sync_state")
					assert.True(t, ok)
					assert.Equal(t, "sync_state-val", attrVal.Str())
				case "postgresql.replication.write_lsn_delay":
					assert.False(t, validatedMetrics["postgresql.replication.write_lsn_delay"], "Found a duplicate in the metrics slice: postgresql.replication.write_lsn_delay")
					validatedMetrics["postgresql.replication.write_lsn_delay"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of bytes of WAL written but not yet flushed on standby", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("application_name")
					assert.True(t, ok)
					assert.Equal(t, "application_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("client_address")
					assert.True(t, ok)
					assert.Equal(t, "client_address-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("replication_state")
					assert.True(t, ok)
					assert.Equal(t, "replication_state-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("sync_state")
					assert.True(t, ok)
					assert.Equal(t, "sync_state-val", attrVal.Str())
				case "postgresql.replication_delay":
					assert.False(t, validatedMetrics["postgresql.replication_delay"], "Found a duplicate in the metrics slice: postgresql.replication_delay")
					validatedMetrics["postgresql.replication_delay"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time lag between primary and standby (standby-side metric, PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.replication_delay_bytes":
					assert.False(t, validatedMetrics["postgresql.replication_delay_bytes"], "Found a duplicate in the metrics slice: postgresql.replication_delay_bytes")
					validatedMetrics["postgresql.replication_delay_bytes"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Byte lag between WAL received and replayed on standby (standby-side metric, PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.replication_slot.catalog_xmin_age":
					assert.False(t, validatedMetrics["postgresql.replication_slot.catalog_xmin_age"], "Found a duplicate in the metrics slice: postgresql.replication_slot.catalog_xmin_age")
					validatedMetrics["postgresql.replication_slot.catalog_xmin_age"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Age of oldest transaction affecting system catalogs that this slot needs to keep (PostgreSQL 9.4+)", ms.At(i).Description())
					assert.Equal(t, "{transactions}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("slot_name")
					assert.True(t, ok)
					assert.Equal(t, "slot_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("slot_type")
					assert.True(t, ok)
					assert.Equal(t, "slot_type-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("plugin")
					assert.True(t, ok)
					assert.Equal(t, "plugin-val", attrVal.Str())
				case "postgresql.replication_slot.confirmed_flush_delay_bytes":
					assert.False(t, validatedMetrics["postgresql.replication_slot.confirmed_flush_delay_bytes"], "Found a duplicate in the metrics slice: postgresql.replication_slot.confirmed_flush_delay_bytes")
					validatedMetrics["postgresql.replication_slot.confirmed_flush_delay_bytes"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of bytes between current WAL position and confirmed_flush_lsn (logical slots only, PostgreSQL 9.4+)", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("slot_name")
					assert.True(t, ok)
					assert.Equal(t, "slot_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("slot_type")
					assert.True(t, ok)
					assert.Equal(t, "slot_type-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("plugin")
					assert.True(t, ok)
					assert.Equal(t, "plugin-val", attrVal.Str())
				case "postgresql.replication_slot.restart_delay_bytes":
					assert.False(t, validatedMetrics["postgresql.replication_slot.restart_delay_bytes"], "Found a duplicate in the metrics slice: postgresql.replication_slot.restart_delay_bytes")
					validatedMetrics["postgresql.replication_slot.restart_delay_bytes"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of bytes of WAL between current position and slot's restart_lsn (PostgreSQL 9.4+)", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("slot_name")
					assert.True(t, ok)
					assert.Equal(t, "slot_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("slot_type")
					assert.True(t, ok)
					assert.Equal(t, "slot_type-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("plugin")
					assert.True(t, ok)
					assert.Equal(t, "plugin-val", attrVal.Str())
				case "postgresql.replication_slot.spill_bytes":
					assert.False(t, validatedMetrics["postgresql.replication_slot.spill_bytes"], "Found a duplicate in the metrics slice: postgresql.replication_slot.spill_bytes")
					validatedMetrics["postgresql.replication_slot.spill_bytes"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Total amount of data spilled to disk for logical decoding (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("slot_name")
					assert.True(t, ok)
					assert.Equal(t, "slot_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("slot_type")
					assert.True(t, ok)
					assert.Equal(t, "slot_type-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("state")
					assert.True(t, ok)
					assert.Equal(t, "state-val", attrVal.Str())
				case "postgresql.replication_slot.spill_count":
					assert.False(t, validatedMetrics["postgresql.replication_slot.spill_count"], "Found a duplicate in the metrics slice: postgresql.replication_slot.spill_count")
					validatedMetrics["postgresql.replication_slot.spill_count"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of times transactions were spilled to disk during logical decoding (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "{spills}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("slot_name")
					assert.True(t, ok)
					assert.Equal(t, "slot_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("slot_type")
					assert.True(t, ok)
					assert.Equal(t, "slot_type-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("state")
					assert.True(t, ok)
					assert.Equal(t, "state-val", attrVal.Str())
				case "postgresql.replication_slot.spill_txns":
					assert.False(t, validatedMetrics["postgresql.replication_slot.spill_txns"], "Found a duplicate in the metrics slice: postgresql.replication_slot.spill_txns")
					validatedMetrics["postgresql.replication_slot.spill_txns"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of transactions spilled to disk during logical decoding (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "{transactions}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("slot_name")
					assert.True(t, ok)
					assert.Equal(t, "slot_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("slot_type")
					assert.True(t, ok)
					assert.Equal(t, "slot_type-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("state")
					assert.True(t, ok)
					assert.Equal(t, "state-val", attrVal.Str())
				case "postgresql.replication_slot.stream_bytes":
					assert.False(t, validatedMetrics["postgresql.replication_slot.stream_bytes"], "Found a duplicate in the metrics slice: postgresql.replication_slot.stream_bytes")
					validatedMetrics["postgresql.replication_slot.stream_bytes"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Total amount of data streamed for in-progress transactions during logical decoding (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("slot_name")
					assert.True(t, ok)
					assert.Equal(t, "slot_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("slot_type")
					assert.True(t, ok)
					assert.Equal(t, "slot_type-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("state")
					assert.True(t, ok)
					assert.Equal(t, "state-val", attrVal.Str())
				case "postgresql.replication_slot.stream_count":
					assert.False(t, validatedMetrics["postgresql.replication_slot.stream_count"], "Found a duplicate in the metrics slice: postgresql.replication_slot.stream_count")
					validatedMetrics["postgresql.replication_slot.stream_count"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of times in-progress transactions were streamed during logical decoding (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "{streams}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("slot_name")
					assert.True(t, ok)
					assert.Equal(t, "slot_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("slot_type")
					assert.True(t, ok)
					assert.Equal(t, "slot_type-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("state")
					assert.True(t, ok)
					assert.Equal(t, "state-val", attrVal.Str())
				case "postgresql.replication_slot.stream_txns":
					assert.False(t, validatedMetrics["postgresql.replication_slot.stream_txns"], "Found a duplicate in the metrics slice: postgresql.replication_slot.stream_txns")
					validatedMetrics["postgresql.replication_slot.stream_txns"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of in-progress transactions streamed during logical decoding (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "{transactions}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("slot_name")
					assert.True(t, ok)
					assert.Equal(t, "slot_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("slot_type")
					assert.True(t, ok)
					assert.Equal(t, "slot_type-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("state")
					assert.True(t, ok)
					assert.Equal(t, "state-val", attrVal.Str())
				case "postgresql.replication_slot.total_bytes":
					assert.False(t, validatedMetrics["postgresql.replication_slot.total_bytes"], "Found a duplicate in the metrics slice: postgresql.replication_slot.total_bytes")
					validatedMetrics["postgresql.replication_slot.total_bytes"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Total amount of data decoded for transactions during logical decoding (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("slot_name")
					assert.True(t, ok)
					assert.Equal(t, "slot_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("slot_type")
					assert.True(t, ok)
					assert.Equal(t, "slot_type-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("state")
					assert.True(t, ok)
					assert.Equal(t, "state-val", attrVal.Str())
				case "postgresql.replication_slot.total_txns":
					assert.False(t, validatedMetrics["postgresql.replication_slot.total_txns"], "Found a duplicate in the metrics slice: postgresql.replication_slot.total_txns")
					validatedMetrics["postgresql.replication_slot.total_txns"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Total number of decoded transactions during logical decoding (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "{transactions}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("slot_name")
					assert.True(t, ok)
					assert.Equal(t, "slot_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("slot_type")
					assert.True(t, ok)
					assert.Equal(t, "slot_type-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("state")
					assert.True(t, ok)
					assert.Equal(t, "state-val", attrVal.Str())
				case "postgresql.replication_slot.xmin_age":
					assert.False(t, validatedMetrics["postgresql.replication_slot.xmin_age"], "Found a duplicate in the metrics slice: postgresql.replication_slot.xmin_age")
					validatedMetrics["postgresql.replication_slot.xmin_age"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Age of oldest transaction that this replication slot needs to keep (PostgreSQL 9.4+)", ms.At(i).Description())
					assert.Equal(t, "{transactions}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("slot_name")
					assert.True(t, ok)
					assert.Equal(t, "slot_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("slot_type")
					assert.True(t, ok)
					assert.Equal(t, "slot_type-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("plugin")
					assert.True(t, ok)
					assert.Equal(t, "plugin-val", attrVal.Str())
				case "postgresql.rollbacks":
					assert.False(t, validatedMetrics["postgresql.rollbacks"], "Found a duplicate in the metrics slice: postgresql.rollbacks")
					validatedMetrics["postgresql.rollbacks"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of transactions that have been rolled back", ms.At(i).Description())
					assert.Equal(t, "{transactions}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.rows_deleted":
					assert.False(t, validatedMetrics["postgresql.rows_deleted"], "Found a duplicate in the metrics slice: postgresql.rows_deleted")
					validatedMetrics["postgresql.rows_deleted"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of rows deleted", ms.At(i).Description())
					assert.Equal(t, "{rows}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.rows_fetched":
					assert.False(t, validatedMetrics["postgresql.rows_fetched"], "Found a duplicate in the metrics slice: postgresql.rows_fetched")
					validatedMetrics["postgresql.rows_fetched"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of rows fetched by queries", ms.At(i).Description())
					assert.Equal(t, "{rows}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.rows_inserted":
					assert.False(t, validatedMetrics["postgresql.rows_inserted"], "Found a duplicate in the metrics slice: postgresql.rows_inserted")
					validatedMetrics["postgresql.rows_inserted"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of rows inserted", ms.At(i).Description())
					assert.Equal(t, "{rows}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.rows_returned":
					assert.False(t, validatedMetrics["postgresql.rows_returned"], "Found a duplicate in the metrics slice: postgresql.rows_returned")
					validatedMetrics["postgresql.rows_returned"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of rows returned by queries", ms.At(i).Description())
					assert.Equal(t, "{rows}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.rows_updated":
					assert.False(t, validatedMetrics["postgresql.rows_updated"], "Found a duplicate in the metrics slice: postgresql.rows_updated")
					validatedMetrics["postgresql.rows_updated"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of rows updated", ms.At(i).Description())
					assert.Equal(t, "{rows}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.sessions.abandoned":
					assert.False(t, validatedMetrics["postgresql.sessions.abandoned"], "Found a duplicate in the metrics slice: postgresql.sessions.abandoned")
					validatedMetrics["postgresql.sessions.abandoned"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of sessions abandoned due to client disconnection (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "{sessions}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.sessions.active_time":
					assert.False(t, validatedMetrics["postgresql.sessions.active_time"], "Found a duplicate in the metrics slice: postgresql.sessions.active_time")
					validatedMetrics["postgresql.sessions.active_time"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time spent executing queries in this database (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "ms", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.sessions.count":
					assert.False(t, validatedMetrics["postgresql.sessions.count"], "Found a duplicate in the metrics slice: postgresql.sessions.count")
					validatedMetrics["postgresql.sessions.count"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of sessions established to this database (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "{sessions}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.sessions.fatal":
					assert.False(t, validatedMetrics["postgresql.sessions.fatal"], "Found a duplicate in the metrics slice: postgresql.sessions.fatal")
					validatedMetrics["postgresql.sessions.fatal"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of sessions terminated by fatal errors (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "{sessions}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.sessions.idle_in_transaction_time":
					assert.False(t, validatedMetrics["postgresql.sessions.idle_in_transaction_time"], "Found a duplicate in the metrics slice: postgresql.sessions.idle_in_transaction_time")
					validatedMetrics["postgresql.sessions.idle_in_transaction_time"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time spent idle in transactions in this database (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "ms", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.sessions.killed":
					assert.False(t, validatedMetrics["postgresql.sessions.killed"], "Found a duplicate in the metrics slice: postgresql.sessions.killed")
					validatedMetrics["postgresql.sessions.killed"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of sessions terminated by operator intervention (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "{sessions}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.sessions.session_time":
					assert.False(t, validatedMetrics["postgresql.sessions.session_time"], "Found a duplicate in the metrics slice: postgresql.sessions.session_time")
					validatedMetrics["postgresql.sessions.session_time"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time spent in sessions for this database (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "ms", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.subscription.apply_error":
					assert.False(t, validatedMetrics["postgresql.subscription.apply_error"], "Found a duplicate in the metrics slice: postgresql.subscription.apply_error")
					validatedMetrics["postgresql.subscription.apply_error"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of errors encountered while applying logical replication changes (PostgreSQL 15+)", ms.At(i).Description())
					assert.Equal(t, "{errors}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("subscription_name")
					assert.True(t, ok)
					assert.Equal(t, "subscription_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("state")
					assert.True(t, ok)
					assert.Equal(t, "state-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.subscription.last_msg_receipt_age":
					assert.False(t, validatedMetrics["postgresql.subscription.last_msg_receipt_age"], "Found a duplicate in the metrics slice: postgresql.subscription.last_msg_receipt_age")
					validatedMetrics["postgresql.subscription.last_msg_receipt_age"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time elapsed since last message received from publisher in logical replication (PostgreSQL 15+)", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("subscription_name")
					assert.True(t, ok)
					assert.Equal(t, "subscription_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("state")
					assert.True(t, ok)
					assert.Equal(t, "state-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.subscription.last_msg_send_age":
					assert.False(t, validatedMetrics["postgresql.subscription.last_msg_send_age"], "Found a duplicate in the metrics slice: postgresql.subscription.last_msg_send_age")
					validatedMetrics["postgresql.subscription.last_msg_send_age"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time elapsed since last message sent from publisher in logical replication (PostgreSQL 15+)", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("subscription_name")
					assert.True(t, ok)
					assert.Equal(t, "subscription_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("state")
					assert.True(t, ok)
					assert.Equal(t, "state-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.subscription.latest_end_age":
					assert.False(t, validatedMetrics["postgresql.subscription.latest_end_age"], "Found a duplicate in the metrics slice: postgresql.subscription.latest_end_age")
					validatedMetrics["postgresql.subscription.latest_end_age"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time elapsed since latest WAL location reported to publisher in logical replication (PostgreSQL 15+)", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("subscription_name")
					assert.True(t, ok)
					assert.Equal(t, "subscription_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("state")
					assert.True(t, ok)
					assert.Equal(t, "state-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.subscription.sync_error":
					assert.False(t, validatedMetrics["postgresql.subscription.sync_error"], "Found a duplicate in the metrics slice: postgresql.subscription.sync_error")
					validatedMetrics["postgresql.subscription.sync_error"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of errors encountered during initial sync in logical replication (PostgreSQL 15+)", ms.At(i).Description())
					assert.Equal(t, "{errors}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("subscription_name")
					assert.True(t, ok)
					assert.Equal(t, "subscription_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("state")
					assert.True(t, ok)
					assert.Equal(t, "state-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.temp_bytes":
					assert.False(t, validatedMetrics["postgresql.temp_bytes"], "Found a duplicate in the metrics slice: postgresql.temp_bytes")
					validatedMetrics["postgresql.temp_bytes"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Total amount of data written to temporary files", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.temp_files":
					assert.False(t, validatedMetrics["postgresql.temp_files"], "Found a duplicate in the metrics slice: postgresql.temp_files")
					validatedMetrics["postgresql.temp_files"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of temporary files created", ms.At(i).Description())
					assert.Equal(t, "{files}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.wal.buffers_full":
					assert.False(t, validatedMetrics["postgresql.wal.buffers_full"], "Found a duplicate in the metrics slice: postgresql.wal.buffers_full")
					validatedMetrics["postgresql.wal.buffers_full"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of times WAL data was written because WAL buffers became full (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "{buffers}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.wal.bytes":
					assert.False(t, validatedMetrics["postgresql.wal.bytes"], "Found a duplicate in the metrics slice: postgresql.wal.bytes")
					validatedMetrics["postgresql.wal.bytes"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Total amount of WAL bytes generated (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.wal.fpi":
					assert.False(t, validatedMetrics["postgresql.wal.fpi"], "Found a duplicate in the metrics slice: postgresql.wal.fpi")
					validatedMetrics["postgresql.wal.fpi"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Total number of WAL full page images generated (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "{images}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.wal.records":
					assert.False(t, validatedMetrics["postgresql.wal.records"], "Found a duplicate in the metrics slice: postgresql.wal.records")
					validatedMetrics["postgresql.wal.records"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Total number of WAL records generated (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "{records}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.wal.sync":
					assert.False(t, validatedMetrics["postgresql.wal.sync"], "Found a duplicate in the metrics slice: postgresql.wal.sync")
					validatedMetrics["postgresql.wal.sync"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of times WAL files were synced to disk (PostgreSQL 14-17)", ms.At(i).Description())
					assert.Equal(t, "{syncs}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.wal.sync_time":
					assert.False(t, validatedMetrics["postgresql.wal.sync_time"], "Found a duplicate in the metrics slice: postgresql.wal.sync_time")
					validatedMetrics["postgresql.wal.sync_time"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Total time spent syncing WAL files to disk (PostgreSQL 14-17)", ms.At(i).Description())
					assert.Equal(t, "ms", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.wal.write":
					assert.False(t, validatedMetrics["postgresql.wal.write"], "Found a duplicate in the metrics slice: postgresql.wal.write")
					validatedMetrics["postgresql.wal.write"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of times WAL buffers were written to disk (PostgreSQL 14-17)", ms.At(i).Description())
					assert.Equal(t, "{writes}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.wal.write_time":
					assert.False(t, validatedMetrics["postgresql.wal.write_time"], "Found a duplicate in the metrics slice: postgresql.wal.write_time")
					validatedMetrics["postgresql.wal.write_time"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Total time spent writing WAL buffers to disk (PostgreSQL 14-17)", ms.At(i).Description())
					assert.Equal(t, "ms", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.wal_files.age":
					assert.False(t, validatedMetrics["postgresql.wal_files.age"], "Found a duplicate in the metrics slice: postgresql.wal_files.age")
					validatedMetrics["postgresql.wal_files.age"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Age of the oldest WAL file in seconds (PostgreSQL 10+)", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.wal_files.count":
					assert.False(t, validatedMetrics["postgresql.wal_files.count"], "Found a duplicate in the metrics slice: postgresql.wal_files.count")
					validatedMetrics["postgresql.wal_files.count"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Total number of WAL files in the pg_wal directory (PostgreSQL 10+)", ms.At(i).Description())
					assert.Equal(t, "{files}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.wal_files.size":
					assert.False(t, validatedMetrics["postgresql.wal_files.size"], "Found a duplicate in the metrics slice: postgresql.wal_files.size")
					validatedMetrics["postgresql.wal_files.size"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Total size of all WAL files in bytes (PostgreSQL 10+)", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.wal_receiver.connected":
					assert.False(t, validatedMetrics["postgresql.wal_receiver.connected"], "Found a duplicate in the metrics slice: postgresql.wal_receiver.connected")
					validatedMetrics["postgresql.wal_receiver.connected"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Whether WAL receiver is connected (1 if streaming, 0 otherwise, PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{status}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.wal_receiver.last_msg_receipt_age":
					assert.False(t, validatedMetrics["postgresql.wal_receiver.last_msg_receipt_age"], "Found a duplicate in the metrics slice: postgresql.wal_receiver.last_msg_receipt_age")
					validatedMetrics["postgresql.wal_receiver.last_msg_receipt_age"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time elapsed since last message received by WAL receiver from primary (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.wal_receiver.last_msg_send_age":
					assert.False(t, validatedMetrics["postgresql.wal_receiver.last_msg_send_age"], "Found a duplicate in the metrics slice: postgresql.wal_receiver.last_msg_send_age")
					validatedMetrics["postgresql.wal_receiver.last_msg_send_age"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time elapsed since last message sent from primary to WAL receiver (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.wal_receiver.latest_end_age":
					assert.False(t, validatedMetrics["postgresql.wal_receiver.latest_end_age"], "Found a duplicate in the metrics slice: postgresql.wal_receiver.latest_end_age")
					validatedMetrics["postgresql.wal_receiver.latest_end_age"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time elapsed since last WAL location reported back to primary by WAL receiver (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.wal_receiver.received_timeline":
					assert.False(t, validatedMetrics["postgresql.wal_receiver.received_timeline"], "Found a duplicate in the metrics slice: postgresql.wal_receiver.received_timeline")
					validatedMetrics["postgresql.wal_receiver.received_timeline"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Timeline number of last WAL file received and synced to disk by WAL receiver (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{timeline}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				}
			}
		})
	}
}
