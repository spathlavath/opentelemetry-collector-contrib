// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"testing"

	"github.com/stretchr/testify/assert"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
	"go.opentelemetry.io/collector/receiver/receivertest"
	"go.uber.org/zap"
	"go.uber.org/zap/zaptest/observer"
)

type testDataSet int

const (
	testDataSetDefault testDataSet = iota
	testDataSetAll
	testDataSetNone
)

func TestMetricsBuilder(t *testing.T) {
	tests := []struct {
		name        string
		metricsSet  testDataSet
		resAttrsSet testDataSet
		expectEmpty bool
	}{
		{
			name: "default",
		},
		{
			name:        "all_set",
			metricsSet:  testDataSetAll,
			resAttrsSet: testDataSetAll,
		},
		{
			name:        "none_set",
			metricsSet:  testDataSetNone,
			resAttrsSet: testDataSetNone,
			expectEmpty: true,
		},
		{
			name:        "filter_set_include",
			resAttrsSet: testDataSetAll,
		},
		{
			name:        "filter_set_exclude",
			resAttrsSet: testDataSetAll,
			expectEmpty: true,
		},
	}
	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			start := pcommon.Timestamp(1_000_000_000)
			ts := pcommon.Timestamp(1_000_001_000)
			observedZapCore, observedLogs := observer.New(zap.WarnLevel)
			settings := receivertest.NewNopSettings(receivertest.NopType)
			settings.Logger = zap.New(observedZapCore)
			mb := NewMetricsBuilder(loadMetricsBuilderConfig(t, tt.name), settings, WithStartTime(start))

			expectedWarnings := 0

			assert.Equal(t, expectedWarnings, observedLogs.Len())

			defaultMetricsCount := 0
			allMetricsCount := 0

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPgbouncerStatsAvgBytesInDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "database_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPgbouncerStatsAvgBytesOutDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "database_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPgbouncerStatsAvgRequestsPerSecondDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "database_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPgbouncerStatsAvgServerAssignmentCountDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "database_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPgbouncerStatsAvgTransactionCountDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "database_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPgbouncerStatsAvgTransactionDurationMillisecondsDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "database_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPgbouncerStatsBytesInPerSecondDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "database_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPgbouncerStatsBytesOutPerSecondDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "database_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPgbouncerStatsQueriesPerSecondDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "database_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPgbouncerStatsRequestsPerSecondDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "database_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPgbouncerStatsTotalServerAssignmentCountDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "database_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPgbouncerStatsTransactionsPerSecondDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "database_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlActiveWaitingQueriesDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "database_name-val", "user_name-val", "application_name-val", "backend_type-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlActivityBackendXidAgeDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "database_name-val", "user_name-val", "application_name-val", "backend_type-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlActivityBackendXminAgeDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "database_name-val", "user_name-val", "application_name-val", "backend_type-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlActivityWaitEventDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "database_name-val", "user_name-val", "application_name-val", "backend_type-val", "wait_event-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlActivityXactStartAgeDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "database_name-val", "user_name-val", "application_name-val", "backend_type-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlAnalyzeChildTablesDoneDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlAnalyzeChildTablesTotalDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlAnalyzeExtStatsComputedDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlAnalyzeExtStatsTotalDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlAnalyzeSampleBlksScannedDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlAnalyzeSampleBlksTotalDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlAnalyzedDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlArchiverArchivedCountDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlArchiverFailedCountDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlAutoanalyzedDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlAutovacuumedDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBeforeXidWraparoundDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBgwriterBuffersAllocDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBgwriterBuffersBackendDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBgwriterBuffersBackendFsyncDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBgwriterBuffersCheckpointDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBgwriterBuffersCleanDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBgwriterCheckpointsRequestedDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBgwriterCheckpointsTimedDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBgwriterMaxwrittenCleanDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBgwriterSyncTimeDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBgwriterWriteTimeDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBlkReadTimeDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBlkWriteTimeDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBufferHitDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBuffercacheDirtyBuffersDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "database_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBuffercachePinningBackendsDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "database_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBuffercacheUnusedBuffersDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "database_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBuffercacheUsageCountDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "database_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlBuffercacheUsedBuffersDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "database_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlChecksumsEnabledDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlChecksumsFailuresDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlClusterVacuumHeapBlksScannedDataPoint(ts, 1, "command-val", "database_name-val", "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlClusterVacuumHeapBlksTotalDataPoint(ts, 1, "command-val", "database_name-val", "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlClusterVacuumHeapTuplesScannedDataPoint(ts, 1, "command-val", "database_name-val", "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlClusterVacuumHeapTuplesWrittenDataPoint(ts, 1, "command-val", "database_name-val", "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlCommitsDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlConflictsDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlConflictsBufferpinDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlConflictsDeadlockDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlConflictsLockDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlConflictsSnapshotDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlConflictsTablespaceDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlConnectionsDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlControlCheckpointDelayDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlControlCheckpointDelayBytesDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlControlRedoDelayBytesDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlControlTimelineIDDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlCreateIndexBlocksDoneDataPoint(ts, 1, "database_name-val", "index_name-val", "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlCreateIndexBlocksTotalDataPoint(ts, 1, "database_name-val", "index_name-val", "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlCreateIndexLockersDoneDataPoint(ts, 1, "database_name-val", "index_name-val", "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlCreateIndexLockersTotalDataPoint(ts, 1, "database_name-val", "index_name-val", "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlCreateIndexPartitionsDoneDataPoint(ts, 1, "database_name-val", "index_name-val", "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlCreateIndexPartitionsTotalDataPoint(ts, 1, "database_name-val", "index_name-val", "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlCreateIndexTuplesDoneDataPoint(ts, 1, "database_name-val", "index_name-val", "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlCreateIndexTuplesTotalDataPoint(ts, 1, "database_name-val", "index_name-val", "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlDatabaseSizeDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlDbCountDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlDeadlocksDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlDiskReadDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlHeapBlocksHitDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlHeapBlocksReadDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlIndexBlocksHitDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlIndexBlocksReadDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlIndexScansDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val", "index_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlIndexSizeDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val", "index_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlIndexTuplesFetchedDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val", "index_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlIndexTuplesReadDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val", "index_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlLastAnalyzeAgeDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlLastAutoanalyzeAgeDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlLastAutovacuumAgeDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlLastVacuumAgeDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlMaxConnectionsDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlPercentUsageConnectionsDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlPgStatStatementsDeallocDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlRecoveryPrefetchBlockDistanceDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlRecoveryPrefetchHitDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlRecoveryPrefetchIoDepthDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlRecoveryPrefetchPrefetchDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlRecoveryPrefetchSkipFpwDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlRecoveryPrefetchSkipInitDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlRecoveryPrefetchSkipNewDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlRecoveryPrefetchSkipRepDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlRecoveryPrefetchWalDistanceDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlRelationAllVisibleDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlRelationPagesDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlRelationTuplesDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlRelationXminDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlRelationSizeDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationBackendXminAgeDataPoint(ts, 1, "application_name-val", "client_address-val", "replication_state-val", "sync_state-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationFlushLsnDelayDataPoint(ts, 1, "application_name-val", "client_address-val", "replication_state-val", "sync_state-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationReplayLsnDelayDataPoint(ts, 1, "application_name-val", "client_address-val", "replication_state-val", "sync_state-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationSentLsnDelayDataPoint(ts, 1, "application_name-val", "client_address-val", "replication_state-val", "sync_state-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationWalFlushLagDataPoint(ts, 1, "application_name-val", "client_address-val", "replication_state-val", "sync_state-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationWalReplayLagDataPoint(ts, 1, "application_name-val", "client_address-val", "replication_state-val", "sync_state-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationWalWriteLagDataPoint(ts, 1, "application_name-val", "client_address-val", "replication_state-val", "sync_state-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationWriteLsnDelayDataPoint(ts, 1, "application_name-val", "client_address-val", "replication_state-val", "sync_state-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationDelayDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationDelayBytesDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationSlotCatalogXminAgeDataPoint(ts, 1, "slot_name-val", "slot_type-val", "plugin-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationSlotConfirmedFlushDelayBytesDataPoint(ts, 1, "slot_name-val", "slot_type-val", "plugin-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationSlotRestartDelayBytesDataPoint(ts, 1, "slot_name-val", "slot_type-val", "plugin-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationSlotSpillBytesDataPoint(ts, 1, "slot_name-val", "slot_type-val", "state-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationSlotSpillCountDataPoint(ts, 1, "slot_name-val", "slot_type-val", "state-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationSlotSpillTxnsDataPoint(ts, 1, "slot_name-val", "slot_type-val", "state-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationSlotStreamBytesDataPoint(ts, 1, "slot_name-val", "slot_type-val", "state-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationSlotStreamCountDataPoint(ts, 1, "slot_name-val", "slot_type-val", "state-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationSlotStreamTxnsDataPoint(ts, 1, "slot_name-val", "slot_type-val", "state-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationSlotTotalBytesDataPoint(ts, 1, "slot_name-val", "slot_type-val", "state-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationSlotTotalTxnsDataPoint(ts, 1, "slot_name-val", "slot_type-val", "state-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlReplicationSlotXminAgeDataPoint(ts, 1, "slot_name-val", "slot_type-val", "plugin-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlRollbacksDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlRowsDeletedDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlRowsFetchedDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlRowsInsertedDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlRowsReturnedDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlRowsUpdatedDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlRunningDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSessionsAbandonedDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSessionsActiveTimeDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSessionsCountDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSessionsFatalDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSessionsIdleInTransactionTimeDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSessionsKilledDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSessionsSessionTimeDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSlruBlksExistsDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "slru_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSlruBlksHitDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "slru_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSlruBlksReadDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "slru_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSlruBlksWrittenDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "slru_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSlruBlksZeroedDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "slru_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSlruFlushesDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "slru_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSlruTruncatesDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "slru_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSnapshotXipCountDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSnapshotXmaxDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSnapshotXminDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSubscriptionApplyErrorDataPoint(ts, 1, "subscription_name-val", "state-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSubscriptionLastMsgReceiptAgeDataPoint(ts, 1, "subscription_name-val", "state-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSubscriptionLastMsgSendAgeDataPoint(ts, 1, "subscription_name-val", "state-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSubscriptionLatestEndAgeDataPoint(ts, 1, "subscription_name-val", "state-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlSubscriptionSyncErrorDataPoint(ts, 1, "subscription_name-val", "state-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlTempBytesDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlTempFilesDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlToastAutovacuumedDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlToastLastAutovacuumAgeDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlToastLastVacuumAgeDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlToastVacuumedDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlToastBlocksHitDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlToastBlocksReadDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlToastIndexBlocksHitDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlToastIndexBlocksReadDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlToastSizeDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlTransactionsDurationMaxDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "database_name-val", "user_name-val", "application_name-val", "backend_type-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlTransactionsDurationSumDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "database_name-val", "user_name-val", "application_name-val", "backend_type-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlUptimeDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlVacuumHeapBlksScannedDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlVacuumHeapBlksTotalDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlVacuumHeapBlksVacuumedDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlVacuumIndexVacuumCountDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlVacuumMaxDeadTuplesDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlVacuumNumDeadTuplesDataPoint(ts, 1, "database_name-val", "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlVacuumedDataPoint(ts, 1, "newrelicpostgresql.instance_name-val", "schema_name-val", "table_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalBuffersFullDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalBytesDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalFpiDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalRecordsDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalSyncDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalSyncTimeDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalWriteDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalWriteTimeDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalFilesAgeDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalFilesCountDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalFilesSizeDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalReceiverConnectedDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalReceiverLastMsgReceiptAgeDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalReceiverLastMsgSendAgeDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalReceiverLatestEndAgeDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordPostgresqlWalReceiverReceivedTimelineDataPoint(ts, 1, "newrelicpostgresql.instance_name-val")

			rb := mb.NewResourceBuilder()
			rb.SetDatabaseName("database_name-val")
			rb.SetDbSystem("db.system-val")
			rb.SetNewrelicpostgresqlInstanceName("newrelicpostgresql.instance_name-val")
			rb.SetPostgresqlVersion("postgresql.version-val")
			rb.SetServerAddress("server.address-val")
			rb.SetServerPort("server.port-val")
			res := rb.Emit()
			metrics := mb.Emit(WithResource(res))

			if tt.expectEmpty {
				assert.Equal(t, 0, metrics.ResourceMetrics().Len())
				return
			}

			assert.Equal(t, 1, metrics.ResourceMetrics().Len())
			rm := metrics.ResourceMetrics().At(0)
			assert.Equal(t, res, rm.Resource())
			assert.Equal(t, 1, rm.ScopeMetrics().Len())
			ms := rm.ScopeMetrics().At(0).Metrics()
			if tt.metricsSet == testDataSetDefault {
				assert.Equal(t, defaultMetricsCount, ms.Len())
			}
			if tt.metricsSet == testDataSetAll {
				assert.Equal(t, allMetricsCount, ms.Len())
			}
			validatedMetrics := make(map[string]bool)
			for i := 0; i < ms.Len(); i++ {
				switch ms.At(i).Name() {
				case "pgbouncer.stats.avg_bytes_in":
					assert.False(t, validatedMetrics["pgbouncer.stats.avg_bytes_in"], "Found a duplicate in the metrics slice: pgbouncer.stats.avg_bytes_in")
					validatedMetrics["pgbouncer.stats.avg_bytes_in"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Average bytes received per request (PgBouncer 1.8+)", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
				case "pgbouncer.stats.avg_bytes_out":
					assert.False(t, validatedMetrics["pgbouncer.stats.avg_bytes_out"], "Found a duplicate in the metrics slice: pgbouncer.stats.avg_bytes_out")
					validatedMetrics["pgbouncer.stats.avg_bytes_out"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Average bytes sent per request (PgBouncer 1.8+)", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
				case "pgbouncer.stats.avg_requests_per_second":
					assert.False(t, validatedMetrics["pgbouncer.stats.avg_requests_per_second"], "Found a duplicate in the metrics slice: pgbouncer.stats.avg_requests_per_second")
					validatedMetrics["pgbouncer.stats.avg_requests_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Average requests per second (PgBouncer 1.8+)", ms.At(i).Description())
					assert.Equal(t, "{requests}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
				case "pgbouncer.stats.avg_server_assignment_count":
					assert.False(t, validatedMetrics["pgbouncer.stats.avg_server_assignment_count"], "Found a duplicate in the metrics slice: pgbouncer.stats.avg_server_assignment_count")
					validatedMetrics["pgbouncer.stats.avg_server_assignment_count"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Average number of server assignments per transaction (PgBouncer 1.8+)", ms.At(i).Description())
					assert.Equal(t, "{assignments}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
				case "pgbouncer.stats.avg_transaction_count":
					assert.False(t, validatedMetrics["pgbouncer.stats.avg_transaction_count"], "Found a duplicate in the metrics slice: pgbouncer.stats.avg_transaction_count")
					validatedMetrics["pgbouncer.stats.avg_transaction_count"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Average transaction count (PgBouncer 1.8+)", ms.At(i).Description())
					assert.Equal(t, "{transactions}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
				case "pgbouncer.stats.avg_transaction_duration_milliseconds":
					assert.False(t, validatedMetrics["pgbouncer.stats.avg_transaction_duration_milliseconds"], "Found a duplicate in the metrics slice: pgbouncer.stats.avg_transaction_duration_milliseconds")
					validatedMetrics["pgbouncer.stats.avg_transaction_duration_milliseconds"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Average transaction duration in milliseconds (PgBouncer 1.8+)", ms.At(i).Description())
					assert.Equal(t, "ms", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
				case "pgbouncer.stats.bytes_in_per_second":
					assert.False(t, validatedMetrics["pgbouncer.stats.bytes_in_per_second"], "Found a duplicate in the metrics slice: pgbouncer.stats.bytes_in_per_second")
					validatedMetrics["pgbouncer.stats.bytes_in_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Average bytes received per second from clients (PgBouncer 1.8+)", ms.At(i).Description())
					assert.Equal(t, "By/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
				case "pgbouncer.stats.bytes_out_per_second":
					assert.False(t, validatedMetrics["pgbouncer.stats.bytes_out_per_second"], "Found a duplicate in the metrics slice: pgbouncer.stats.bytes_out_per_second")
					validatedMetrics["pgbouncer.stats.bytes_out_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Average bytes sent per second to clients (PgBouncer 1.8+)", ms.At(i).Description())
					assert.Equal(t, "By/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
				case "pgbouncer.stats.queries_per_second":
					assert.False(t, validatedMetrics["pgbouncer.stats.queries_per_second"], "Found a duplicate in the metrics slice: pgbouncer.stats.queries_per_second")
					validatedMetrics["pgbouncer.stats.queries_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Average SQL queries per second (PgBouncer 1.8+)", ms.At(i).Description())
					assert.Equal(t, "{queries}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
				case "pgbouncer.stats.requests_per_second":
					assert.False(t, validatedMetrics["pgbouncer.stats.requests_per_second"], "Found a duplicate in the metrics slice: pgbouncer.stats.requests_per_second")
					validatedMetrics["pgbouncer.stats.requests_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Average client requests per second (PgBouncer 1.8+)", ms.At(i).Description())
					assert.Equal(t, "{requests}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
				case "pgbouncer.stats.total_server_assignment_count":
					assert.False(t, validatedMetrics["pgbouncer.stats.total_server_assignment_count"], "Found a duplicate in the metrics slice: pgbouncer.stats.total_server_assignment_count")
					validatedMetrics["pgbouncer.stats.total_server_assignment_count"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Total number of server assignments since PgBouncer start (PgBouncer 1.8+)", ms.At(i).Description())
					assert.Equal(t, "{assignments}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
				case "pgbouncer.stats.transactions_per_second":
					assert.False(t, validatedMetrics["pgbouncer.stats.transactions_per_second"], "Found a duplicate in the metrics slice: pgbouncer.stats.transactions_per_second")
					validatedMetrics["pgbouncer.stats.transactions_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Average transactions per second (PgBouncer 1.8+)", ms.At(i).Description())
					assert.Equal(t, "{transactions}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
				case "postgresql.active_waiting_queries":
					assert.False(t, validatedMetrics["postgresql.active_waiting_queries"], "Found a duplicate in the metrics slice: postgresql.active_waiting_queries")
					validatedMetrics["postgresql.active_waiting_queries"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of active queries currently waiting on locks or other resources (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{queries}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("user_name")
					assert.True(t, ok)
					assert.Equal(t, "user_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("application_name")
					assert.True(t, ok)
					assert.Equal(t, "application_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("backend_type")
					assert.True(t, ok)
					assert.Equal(t, "backend_type-val", attrVal.Str())
				case "postgresql.activity.backend_xid_age":
					assert.False(t, validatedMetrics["postgresql.activity.backend_xid_age"], "Found a duplicate in the metrics slice: postgresql.activity.backend_xid_age")
					validatedMetrics["postgresql.activity.backend_xid_age"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Maximum age of backend transaction IDs currently in use (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{transactions}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("user_name")
					assert.True(t, ok)
					assert.Equal(t, "user_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("application_name")
					assert.True(t, ok)
					assert.Equal(t, "application_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("backend_type")
					assert.True(t, ok)
					assert.Equal(t, "backend_type-val", attrVal.Str())
				case "postgresql.activity.backend_xmin_age":
					assert.False(t, validatedMetrics["postgresql.activity.backend_xmin_age"], "Found a duplicate in the metrics slice: postgresql.activity.backend_xmin_age")
					validatedMetrics["postgresql.activity.backend_xmin_age"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Maximum age of backend xmin values (oldest transaction visible to any backend) (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{transactions}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("user_name")
					assert.True(t, ok)
					assert.Equal(t, "user_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("application_name")
					assert.True(t, ok)
					assert.Equal(t, "application_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("backend_type")
					assert.True(t, ok)
					assert.Equal(t, "backend_type-val", attrVal.Str())
				case "postgresql.activity.wait_event":
					assert.False(t, validatedMetrics["postgresql.activity.wait_event"], "Found a duplicate in the metrics slice: postgresql.activity.wait_event")
					validatedMetrics["postgresql.activity.wait_event"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Count of backends grouped by wait event type for performance analysis (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{backends}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("user_name")
					assert.True(t, ok)
					assert.Equal(t, "user_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("application_name")
					assert.True(t, ok)
					assert.Equal(t, "application_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("backend_type")
					assert.True(t, ok)
					assert.Equal(t, "backend_type-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("wait_event")
					assert.True(t, ok)
					assert.Equal(t, "wait_event-val", attrVal.Str())
				case "postgresql.activity.xact_start_age":
					assert.False(t, validatedMetrics["postgresql.activity.xact_start_age"], "Found a duplicate in the metrics slice: postgresql.activity.xact_start_age")
					validatedMetrics["postgresql.activity.xact_start_age"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Maximum age in seconds of the oldest transaction start time across all backends (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("user_name")
					assert.True(t, ok)
					assert.Equal(t, "user_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("application_name")
					assert.True(t, ok)
					assert.Equal(t, "application_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("backend_type")
					assert.True(t, ok)
					assert.Equal(t, "backend_type-val", attrVal.Str())
				case "postgresql.analyze.child_tables_done":
					assert.False(t, validatedMetrics["postgresql.analyze.child_tables_done"], "Found a duplicate in the metrics slice: postgresql.analyze.child_tables_done")
					validatedMetrics["postgresql.analyze.child_tables_done"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of child tables processed during ANALYZE operation (PostgreSQL 13+)", ms.At(i).Description())
					assert.Equal(t, "{tables}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.analyze.child_tables_total":
					assert.False(t, validatedMetrics["postgresql.analyze.child_tables_total"], "Found a duplicate in the metrics slice: postgresql.analyze.child_tables_total")
					validatedMetrics["postgresql.analyze.child_tables_total"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Total number of child tables to be analyzed (PostgreSQL 13+)", ms.At(i).Description())
					assert.Equal(t, "{tables}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.analyze.ext_stats_computed":
					assert.False(t, validatedMetrics["postgresql.analyze.ext_stats_computed"], "Found a duplicate in the metrics slice: postgresql.analyze.ext_stats_computed")
					validatedMetrics["postgresql.analyze.ext_stats_computed"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of extended statistics computed during ANALYZE operation (PostgreSQL 13+)", ms.At(i).Description())
					assert.Equal(t, "{statistics}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.analyze.ext_stats_total":
					assert.False(t, validatedMetrics["postgresql.analyze.ext_stats_total"], "Found a duplicate in the metrics slice: postgresql.analyze.ext_stats_total")
					validatedMetrics["postgresql.analyze.ext_stats_total"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Total number of extended statistics to be computed (PostgreSQL 13+)", ms.At(i).Description())
					assert.Equal(t, "{statistics}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.analyze.sample_blks_scanned":
					assert.False(t, validatedMetrics["postgresql.analyze.sample_blks_scanned"], "Found a duplicate in the metrics slice: postgresql.analyze.sample_blks_scanned")
					validatedMetrics["postgresql.analyze.sample_blks_scanned"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of sample blocks scanned during ANALYZE operation (PostgreSQL 13+)", ms.At(i).Description())
					assert.Equal(t, "{blocks}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.analyze.sample_blks_total":
					assert.False(t, validatedMetrics["postgresql.analyze.sample_blks_total"], "Found a duplicate in the metrics slice: postgresql.analyze.sample_blks_total")
					validatedMetrics["postgresql.analyze.sample_blks_total"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Total number of sample blocks to be scanned (PostgreSQL 13+)", ms.At(i).Description())
					assert.Equal(t, "{blocks}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.analyzed":
					assert.False(t, validatedMetrics["postgresql.analyzed"], "Found a duplicate in the metrics slice: postgresql.analyzed")
					validatedMetrics["postgresql.analyzed"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of times this table has been manually analyzed (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{operations}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.archiver.archived_count":
					assert.False(t, validatedMetrics["postgresql.archiver.archived_count"], "Found a duplicate in the metrics slice: postgresql.archiver.archived_count")
					validatedMetrics["postgresql.archiver.archived_count"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of WAL files successfully archived (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{files}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.archiver.failed_count":
					assert.False(t, validatedMetrics["postgresql.archiver.failed_count"], "Found a duplicate in the metrics slice: postgresql.archiver.failed_count")
					validatedMetrics["postgresql.archiver.failed_count"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of failed attempts to archive WAL files (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{files}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.autoanalyzed":
					assert.False(t, validatedMetrics["postgresql.autoanalyzed"], "Found a duplicate in the metrics slice: postgresql.autoanalyzed")
					validatedMetrics["postgresql.autoanalyzed"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of times this table has been analyzed by autoanalyze (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{operations}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.autovacuumed":
					assert.False(t, validatedMetrics["postgresql.autovacuumed"], "Found a duplicate in the metrics slice: postgresql.autovacuumed")
					validatedMetrics["postgresql.autovacuumed"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of times this table has been vacuumed by autovacuum (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{operations}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.before_xid_wraparound":
					assert.False(t, validatedMetrics["postgresql.before_xid_wraparound"], "Found a duplicate in the metrics slice: postgresql.before_xid_wraparound")
					validatedMetrics["postgresql.before_xid_wraparound"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of transactions before XID wraparound occurs", ms.At(i).Description())
					assert.Equal(t, "{transactions}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.bgwriter.buffers_alloc":
					assert.False(t, validatedMetrics["postgresql.bgwriter.buffers_alloc"], "Found a duplicate in the metrics slice: postgresql.bgwriter.buffers_alloc")
					validatedMetrics["postgresql.bgwriter.buffers_alloc"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of buffers allocated (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{buffers}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.bgwriter.buffers_backend":
					assert.False(t, validatedMetrics["postgresql.bgwriter.buffers_backend"], "Found a duplicate in the metrics slice: postgresql.bgwriter.buffers_backend")
					validatedMetrics["postgresql.bgwriter.buffers_backend"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of buffers written directly by a backend (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{buffers}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.bgwriter.buffers_backend_fsync":
					assert.False(t, validatedMetrics["postgresql.bgwriter.buffers_backend_fsync"], "Found a duplicate in the metrics slice: postgresql.bgwriter.buffers_backend_fsync")
					validatedMetrics["postgresql.bgwriter.buffers_backend_fsync"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of times a backend had to execute its own fsync call (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{operations}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.bgwriter.buffers_checkpoint":
					assert.False(t, validatedMetrics["postgresql.bgwriter.buffers_checkpoint"], "Found a duplicate in the metrics slice: postgresql.bgwriter.buffers_checkpoint")
					validatedMetrics["postgresql.bgwriter.buffers_checkpoint"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of buffers written during checkpoints (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{buffers}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.bgwriter.buffers_clean":
					assert.False(t, validatedMetrics["postgresql.bgwriter.buffers_clean"], "Found a duplicate in the metrics slice: postgresql.bgwriter.buffers_clean")
					validatedMetrics["postgresql.bgwriter.buffers_clean"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of buffers written by the background writer (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{buffers}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.bgwriter.checkpoints_requested":
					assert.False(t, validatedMetrics["postgresql.bgwriter.checkpoints_requested"], "Found a duplicate in the metrics slice: postgresql.bgwriter.checkpoints_requested")
					validatedMetrics["postgresql.bgwriter.checkpoints_requested"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of requested checkpoints that have been performed (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{checkpoints}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.bgwriter.checkpoints_timed":
					assert.False(t, validatedMetrics["postgresql.bgwriter.checkpoints_timed"], "Found a duplicate in the metrics slice: postgresql.bgwriter.checkpoints_timed")
					validatedMetrics["postgresql.bgwriter.checkpoints_timed"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of scheduled checkpoints that have been performed (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{checkpoints}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.bgwriter.maxwritten_clean":
					assert.False(t, validatedMetrics["postgresql.bgwriter.maxwritten_clean"], "Found a duplicate in the metrics slice: postgresql.bgwriter.maxwritten_clean")
					validatedMetrics["postgresql.bgwriter.maxwritten_clean"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of times the background writer stopped a cleaning scan because it had written too many buffers (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{operations}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.bgwriter.sync_time":
					assert.False(t, validatedMetrics["postgresql.bgwriter.sync_time"], "Found a duplicate in the metrics slice: postgresql.bgwriter.sync_time")
					validatedMetrics["postgresql.bgwriter.sync_time"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Total time spent syncing checkpoint data to disk in milliseconds (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "ms", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.bgwriter.write_time":
					assert.False(t, validatedMetrics["postgresql.bgwriter.write_time"], "Found a duplicate in the metrics slice: postgresql.bgwriter.write_time")
					validatedMetrics["postgresql.bgwriter.write_time"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Total time spent writing checkpoint data to disk in milliseconds (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "ms", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.blk_read_time":
					assert.False(t, validatedMetrics["postgresql.blk_read_time"], "Found a duplicate in the metrics slice: postgresql.blk_read_time")
					validatedMetrics["postgresql.blk_read_time"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time spent reading data file blocks (milliseconds)", ms.At(i).Description())
					assert.Equal(t, "ms", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.blk_write_time":
					assert.False(t, validatedMetrics["postgresql.blk_write_time"], "Found a duplicate in the metrics slice: postgresql.blk_write_time")
					validatedMetrics["postgresql.blk_write_time"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time spent writing data file blocks (milliseconds)", ms.At(i).Description())
					assert.Equal(t, "ms", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.buffer_hit":
					assert.False(t, validatedMetrics["postgresql.buffer_hit"], "Found a duplicate in the metrics slice: postgresql.buffer_hit")
					validatedMetrics["postgresql.buffer_hit"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of times disk blocks were found in the buffer cache", ms.At(i).Description())
					assert.Equal(t, "{blocks}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.buffercache.dirty_buffers":
					assert.False(t, validatedMetrics["postgresql.buffercache.dirty_buffers"], "Found a duplicate in the metrics slice: postgresql.buffercache.dirty_buffers")
					validatedMetrics["postgresql.buffercache.dirty_buffers"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of dirty buffers in the shared buffer cache (requires pg_buffercache extension, PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{buffers}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.buffercache.pinning_backends":
					assert.False(t, validatedMetrics["postgresql.buffercache.pinning_backends"], "Found a duplicate in the metrics slice: postgresql.buffercache.pinning_backends")
					validatedMetrics["postgresql.buffercache.pinning_backends"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of backends pinning buffers in the shared buffer cache (requires pg_buffercache extension, PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{backends}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.buffercache.unused_buffers":
					assert.False(t, validatedMetrics["postgresql.buffercache.unused_buffers"], "Found a duplicate in the metrics slice: postgresql.buffercache.unused_buffers")
					validatedMetrics["postgresql.buffercache.unused_buffers"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of unused buffers in the shared buffer cache (requires pg_buffercache extension, PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{buffers}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.buffercache.usage_count":
					assert.False(t, validatedMetrics["postgresql.buffercache.usage_count"], "Found a duplicate in the metrics slice: postgresql.buffercache.usage_count")
					validatedMetrics["postgresql.buffercache.usage_count"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Sum of usage counts for buffers in the shared buffer cache (requires pg_buffercache extension, PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{count}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.buffercache.used_buffers":
					assert.False(t, validatedMetrics["postgresql.buffercache.used_buffers"], "Found a duplicate in the metrics slice: postgresql.buffercache.used_buffers")
					validatedMetrics["postgresql.buffercache.used_buffers"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of used buffers in the shared buffer cache (requires pg_buffercache extension, PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{buffers}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.checksums.enabled":
					assert.False(t, validatedMetrics["postgresql.checksums.enabled"], "Found a duplicate in the metrics slice: postgresql.checksums.enabled")
					validatedMetrics["postgresql.checksums.enabled"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Whether data checksums are enabled for this PostgreSQL cluster (PostgreSQL 12+)", ms.At(i).Description())
					assert.Equal(t, "{status}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.checksums.failures":
					assert.False(t, validatedMetrics["postgresql.checksums.failures"], "Found a duplicate in the metrics slice: postgresql.checksums.failures")
					validatedMetrics["postgresql.checksums.failures"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of data page checksum failures detected (PostgreSQL 12+)", ms.At(i).Description())
					assert.Equal(t, "{failures}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.cluster_vacuum.heap_blks_scanned":
					assert.False(t, validatedMetrics["postgresql.cluster_vacuum.heap_blks_scanned"], "Found a duplicate in the metrics slice: postgresql.cluster_vacuum.heap_blks_scanned")
					validatedMetrics["postgresql.cluster_vacuum.heap_blks_scanned"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of heap blocks scanned during CLUSTER/VACUUM FULL operation (PostgreSQL 12+)", ms.At(i).Description())
					assert.Equal(t, "{blocks}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("command")
					assert.True(t, ok)
					assert.Equal(t, "command-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.cluster_vacuum.heap_blks_total":
					assert.False(t, validatedMetrics["postgresql.cluster_vacuum.heap_blks_total"], "Found a duplicate in the metrics slice: postgresql.cluster_vacuum.heap_blks_total")
					validatedMetrics["postgresql.cluster_vacuum.heap_blks_total"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Total number of heap blocks to be scanned during CLUSTER/VACUUM FULL (PostgreSQL 12+)", ms.At(i).Description())
					assert.Equal(t, "{blocks}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("command")
					assert.True(t, ok)
					assert.Equal(t, "command-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.cluster_vacuum.heap_tuples_scanned":
					assert.False(t, validatedMetrics["postgresql.cluster_vacuum.heap_tuples_scanned"], "Found a duplicate in the metrics slice: postgresql.cluster_vacuum.heap_tuples_scanned")
					validatedMetrics["postgresql.cluster_vacuum.heap_tuples_scanned"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of heap tuples scanned during CLUSTER/VACUUM FULL operation (PostgreSQL 12+)", ms.At(i).Description())
					assert.Equal(t, "{tuples}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("command")
					assert.True(t, ok)
					assert.Equal(t, "command-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.cluster_vacuum.heap_tuples_written":
					assert.False(t, validatedMetrics["postgresql.cluster_vacuum.heap_tuples_written"], "Found a duplicate in the metrics slice: postgresql.cluster_vacuum.heap_tuples_written")
					validatedMetrics["postgresql.cluster_vacuum.heap_tuples_written"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of heap tuples written during CLUSTER/VACUUM FULL operation (PostgreSQL 12+)", ms.At(i).Description())
					assert.Equal(t, "{tuples}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("command")
					assert.True(t, ok)
					assert.Equal(t, "command-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.commits":
					assert.False(t, validatedMetrics["postgresql.commits"], "Found a duplicate in the metrics slice: postgresql.commits")
					validatedMetrics["postgresql.commits"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of transactions that have been committed", ms.At(i).Description())
					assert.Equal(t, "{transactions}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.conflicts":
					assert.False(t, validatedMetrics["postgresql.conflicts"], "Found a duplicate in the metrics slice: postgresql.conflicts")
					validatedMetrics["postgresql.conflicts"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of queries canceled due to conflicts with recovery", ms.At(i).Description())
					assert.Equal(t, "{queries}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.conflicts.bufferpin":
					assert.False(t, validatedMetrics["postgresql.conflicts.bufferpin"], "Found a duplicate in the metrics slice: postgresql.conflicts.bufferpin")
					validatedMetrics["postgresql.conflicts.bufferpin"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Queries canceled due to pinned buffers during recovery", ms.At(i).Description())
					assert.Equal(t, "{queries}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.conflicts.deadlock":
					assert.False(t, validatedMetrics["postgresql.conflicts.deadlock"], "Found a duplicate in the metrics slice: postgresql.conflicts.deadlock")
					validatedMetrics["postgresql.conflicts.deadlock"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Queries canceled due to deadlocks during recovery", ms.At(i).Description())
					assert.Equal(t, "{queries}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.conflicts.lock":
					assert.False(t, validatedMetrics["postgresql.conflicts.lock"], "Found a duplicate in the metrics slice: postgresql.conflicts.lock")
					validatedMetrics["postgresql.conflicts.lock"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Queries canceled due to lock timeouts during recovery", ms.At(i).Description())
					assert.Equal(t, "{queries}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.conflicts.snapshot":
					assert.False(t, validatedMetrics["postgresql.conflicts.snapshot"], "Found a duplicate in the metrics slice: postgresql.conflicts.snapshot")
					validatedMetrics["postgresql.conflicts.snapshot"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Queries canceled due to old snapshots during recovery", ms.At(i).Description())
					assert.Equal(t, "{queries}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.conflicts.tablespace":
					assert.False(t, validatedMetrics["postgresql.conflicts.tablespace"], "Found a duplicate in the metrics slice: postgresql.conflicts.tablespace")
					validatedMetrics["postgresql.conflicts.tablespace"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Queries canceled due to dropped tablespaces during recovery", ms.At(i).Description())
					assert.Equal(t, "{queries}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.connections":
					assert.False(t, validatedMetrics["postgresql.connections"], "Found a duplicate in the metrics slice: postgresql.connections")
					validatedMetrics["postgresql.connections"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of active connections (backends) to the database", ms.At(i).Description())
					assert.Equal(t, "{connections}", ms.At(i).Unit())
					assert.False(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.control.checkpoint_delay":
					assert.False(t, validatedMetrics["postgresql.control.checkpoint_delay"], "Found a duplicate in the metrics slice: postgresql.control.checkpoint_delay")
					validatedMetrics["postgresql.control.checkpoint_delay"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time elapsed since the last checkpoint in seconds (PostgreSQL 10+)", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.control.checkpoint_delay_bytes":
					assert.False(t, validatedMetrics["postgresql.control.checkpoint_delay_bytes"], "Found a duplicate in the metrics slice: postgresql.control.checkpoint_delay_bytes")
					validatedMetrics["postgresql.control.checkpoint_delay_bytes"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "WAL distance from the last checkpoint in bytes (PostgreSQL 10+)", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.control.redo_delay_bytes":
					assert.False(t, validatedMetrics["postgresql.control.redo_delay_bytes"], "Found a duplicate in the metrics slice: postgresql.control.redo_delay_bytes")
					validatedMetrics["postgresql.control.redo_delay_bytes"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "WAL distance from the redo location in bytes (PostgreSQL 10+)", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.control.timeline_id":
					assert.False(t, validatedMetrics["postgresql.control.timeline_id"], "Found a duplicate in the metrics slice: postgresql.control.timeline_id")
					validatedMetrics["postgresql.control.timeline_id"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Current timeline ID (PostgreSQL 10+)", ms.At(i).Description())
					assert.Equal(t, "{timeline}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.create_index.blocks_done":
					assert.False(t, validatedMetrics["postgresql.create_index.blocks_done"], "Found a duplicate in the metrics slice: postgresql.create_index.blocks_done")
					validatedMetrics["postgresql.create_index.blocks_done"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of blocks processed during CREATE INDEX operation (PostgreSQL 12+)", ms.At(i).Description())
					assert.Equal(t, "{blocks}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("index_name")
					assert.True(t, ok)
					assert.Equal(t, "index_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.create_index.blocks_total":
					assert.False(t, validatedMetrics["postgresql.create_index.blocks_total"], "Found a duplicate in the metrics slice: postgresql.create_index.blocks_total")
					validatedMetrics["postgresql.create_index.blocks_total"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Total number of blocks to be processed during CREATE INDEX (PostgreSQL 12+)", ms.At(i).Description())
					assert.Equal(t, "{blocks}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("index_name")
					assert.True(t, ok)
					assert.Equal(t, "index_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.create_index.lockers_done":
					assert.False(t, validatedMetrics["postgresql.create_index.lockers_done"], "Found a duplicate in the metrics slice: postgresql.create_index.lockers_done")
					validatedMetrics["postgresql.create_index.lockers_done"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of lockers processed during CREATE INDEX operation (PostgreSQL 12+)", ms.At(i).Description())
					assert.Equal(t, "{lockers}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("index_name")
					assert.True(t, ok)
					assert.Equal(t, "index_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.create_index.lockers_total":
					assert.False(t, validatedMetrics["postgresql.create_index.lockers_total"], "Found a duplicate in the metrics slice: postgresql.create_index.lockers_total")
					validatedMetrics["postgresql.create_index.lockers_total"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Total number of lockers to be processed during CREATE INDEX (PostgreSQL 12+)", ms.At(i).Description())
					assert.Equal(t, "{lockers}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("index_name")
					assert.True(t, ok)
					assert.Equal(t, "index_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.create_index.partitions_done":
					assert.False(t, validatedMetrics["postgresql.create_index.partitions_done"], "Found a duplicate in the metrics slice: postgresql.create_index.partitions_done")
					validatedMetrics["postgresql.create_index.partitions_done"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of partitions processed during CREATE INDEX operation (PostgreSQL 12+)", ms.At(i).Description())
					assert.Equal(t, "{partitions}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("index_name")
					assert.True(t, ok)
					assert.Equal(t, "index_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.create_index.partitions_total":
					assert.False(t, validatedMetrics["postgresql.create_index.partitions_total"], "Found a duplicate in the metrics slice: postgresql.create_index.partitions_total")
					validatedMetrics["postgresql.create_index.partitions_total"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Total number of partitions to be processed during CREATE INDEX (PostgreSQL 12+)", ms.At(i).Description())
					assert.Equal(t, "{partitions}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("index_name")
					assert.True(t, ok)
					assert.Equal(t, "index_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.create_index.tuples_done":
					assert.False(t, validatedMetrics["postgresql.create_index.tuples_done"], "Found a duplicate in the metrics slice: postgresql.create_index.tuples_done")
					validatedMetrics["postgresql.create_index.tuples_done"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of tuples indexed during CREATE INDEX operation (PostgreSQL 12+)", ms.At(i).Description())
					assert.Equal(t, "{tuples}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("index_name")
					assert.True(t, ok)
					assert.Equal(t, "index_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.create_index.tuples_total":
					assert.False(t, validatedMetrics["postgresql.create_index.tuples_total"], "Found a duplicate in the metrics slice: postgresql.create_index.tuples_total")
					validatedMetrics["postgresql.create_index.tuples_total"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Total number of tuples to be indexed during CREATE INDEX (PostgreSQL 12+)", ms.At(i).Description())
					assert.Equal(t, "{tuples}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("index_name")
					assert.True(t, ok)
					assert.Equal(t, "index_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.database_size":
					assert.False(t, validatedMetrics["postgresql.database_size"], "Found a duplicate in the metrics slice: postgresql.database_size")
					validatedMetrics["postgresql.database_size"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Size of the database in bytes", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.db.count":
					assert.False(t, validatedMetrics["postgresql.db.count"], "Found a duplicate in the metrics slice: postgresql.db.count")
					validatedMetrics["postgresql.db.count"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of databases that allow connections (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{databases}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.deadlocks":
					assert.False(t, validatedMetrics["postgresql.deadlocks"], "Found a duplicate in the metrics slice: postgresql.deadlocks")
					validatedMetrics["postgresql.deadlocks"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of deadlocks detected", ms.At(i).Description())
					assert.Equal(t, "{deadlocks}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.disk_read":
					assert.False(t, validatedMetrics["postgresql.disk_read"], "Found a duplicate in the metrics slice: postgresql.disk_read")
					validatedMetrics["postgresql.disk_read"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of disk blocks read", ms.At(i).Description())
					assert.Equal(t, "{blocks}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.heap_blocks_hit":
					assert.False(t, validatedMetrics["postgresql.heap_blocks_hit"], "Found a duplicate in the metrics slice: postgresql.heap_blocks_hit")
					validatedMetrics["postgresql.heap_blocks_hit"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of heap blocks read from buffer cache for this table (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{blocks}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.heap_blocks_read":
					assert.False(t, validatedMetrics["postgresql.heap_blocks_read"], "Found a duplicate in the metrics slice: postgresql.heap_blocks_read")
					validatedMetrics["postgresql.heap_blocks_read"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of heap blocks read from disk for this table (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{blocks}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.index_blocks_hit":
					assert.False(t, validatedMetrics["postgresql.index_blocks_hit"], "Found a duplicate in the metrics slice: postgresql.index_blocks_hit")
					validatedMetrics["postgresql.index_blocks_hit"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of index blocks read from buffer cache for this table (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{blocks}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.index_blocks_read":
					assert.False(t, validatedMetrics["postgresql.index_blocks_read"], "Found a duplicate in the metrics slice: postgresql.index_blocks_read")
					validatedMetrics["postgresql.index_blocks_read"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of index blocks read from disk for this table (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{blocks}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.index_scans":
					assert.False(t, validatedMetrics["postgresql.index_scans"], "Found a duplicate in the metrics slice: postgresql.index_scans")
					validatedMetrics["postgresql.index_scans"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of index scans initiated on this index (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{scans}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("index_name")
					assert.True(t, ok)
					assert.Equal(t, "index_name-val", attrVal.Str())
				case "postgresql.index_size":
					assert.False(t, validatedMetrics["postgresql.index_size"], "Found a duplicate in the metrics slice: postgresql.index_size")
					validatedMetrics["postgresql.index_size"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Size of this index in bytes (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("index_name")
					assert.True(t, ok)
					assert.Equal(t, "index_name-val", attrVal.Str())
				case "postgresql.index_tuples_fetched":
					assert.False(t, validatedMetrics["postgresql.index_tuples_fetched"], "Found a duplicate in the metrics slice: postgresql.index_tuples_fetched")
					validatedMetrics["postgresql.index_tuples_fetched"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of live table rows fetched by simple index scans using this index (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{tuples}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("index_name")
					assert.True(t, ok)
					assert.Equal(t, "index_name-val", attrVal.Str())
				case "postgresql.index_tuples_read":
					assert.False(t, validatedMetrics["postgresql.index_tuples_read"], "Found a duplicate in the metrics slice: postgresql.index_tuples_read")
					validatedMetrics["postgresql.index_tuples_read"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of index entries returned by scans on this index (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{tuples}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("index_name")
					assert.True(t, ok)
					assert.Equal(t, "index_name-val", attrVal.Str())
				case "postgresql.last_analyze_age":
					assert.False(t, validatedMetrics["postgresql.last_analyze_age"], "Found a duplicate in the metrics slice: postgresql.last_analyze_age")
					validatedMetrics["postgresql.last_analyze_age"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Seconds since last manual ANALYZE on this table (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.last_autoanalyze_age":
					assert.False(t, validatedMetrics["postgresql.last_autoanalyze_age"], "Found a duplicate in the metrics slice: postgresql.last_autoanalyze_age")
					validatedMetrics["postgresql.last_autoanalyze_age"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Seconds since last autoanalyze on this table (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.last_autovacuum_age":
					assert.False(t, validatedMetrics["postgresql.last_autovacuum_age"], "Found a duplicate in the metrics slice: postgresql.last_autovacuum_age")
					validatedMetrics["postgresql.last_autovacuum_age"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Seconds since last autovacuum on this table (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.last_vacuum_age":
					assert.False(t, validatedMetrics["postgresql.last_vacuum_age"], "Found a duplicate in the metrics slice: postgresql.last_vacuum_age")
					validatedMetrics["postgresql.last_vacuum_age"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Seconds since last manual VACUUM on this table (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.max_connections":
					assert.False(t, validatedMetrics["postgresql.max_connections"], "Found a duplicate in the metrics slice: postgresql.max_connections")
					validatedMetrics["postgresql.max_connections"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Maximum number of concurrent connections allowed to the server (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{connections}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.percent_usage_connections":
					assert.False(t, validatedMetrics["postgresql.percent_usage_connections"], "Found a duplicate in the metrics slice: postgresql.percent_usage_connections")
					validatedMetrics["postgresql.percent_usage_connections"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Percentage of max_connections currently in use (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "%", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.pg_stat_statements.dealloc":
					assert.False(t, validatedMetrics["postgresql.pg_stat_statements.dealloc"], "Found a duplicate in the metrics slice: postgresql.pg_stat_statements.dealloc")
					validatedMetrics["postgresql.pg_stat_statements.dealloc"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of times pg_stat_statements has deallocated least-used statements (requires pg_stat_statements extension, PostgreSQL 13+)", ms.At(i).Description())
					assert.Equal(t, "{deallocations}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.recovery_prefetch.block_distance":
					assert.False(t, validatedMetrics["postgresql.recovery_prefetch.block_distance"], "Found a duplicate in the metrics slice: postgresql.recovery_prefetch.block_distance")
					validatedMetrics["postgresql.recovery_prefetch.block_distance"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of blocks between the current replay position and the prefetch position (PostgreSQL 15+)", ms.At(i).Description())
					assert.Equal(t, "{blocks}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.recovery_prefetch.hit":
					assert.False(t, validatedMetrics["postgresql.recovery_prefetch.hit"], "Found a duplicate in the metrics slice: postgresql.recovery_prefetch.hit")
					validatedMetrics["postgresql.recovery_prefetch.hit"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of prefetch requests that hit the buffer cache (PostgreSQL 15+)", ms.At(i).Description())
					assert.Equal(t, "{requests}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.recovery_prefetch.io_depth":
					assert.False(t, validatedMetrics["postgresql.recovery_prefetch.io_depth"], "Found a duplicate in the metrics slice: postgresql.recovery_prefetch.io_depth")
					validatedMetrics["postgresql.recovery_prefetch.io_depth"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of I/O operations in progress (PostgreSQL 15+)", ms.At(i).Description())
					assert.Equal(t, "{operations}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.recovery_prefetch.prefetch":
					assert.False(t, validatedMetrics["postgresql.recovery_prefetch.prefetch"], "Found a duplicate in the metrics slice: postgresql.recovery_prefetch.prefetch")
					validatedMetrics["postgresql.recovery_prefetch.prefetch"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of blocks prefetched during recovery (PostgreSQL 15+)", ms.At(i).Description())
					assert.Equal(t, "{blocks}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.recovery_prefetch.skip_fpw":
					assert.False(t, validatedMetrics["postgresql.recovery_prefetch.skip_fpw"], "Found a duplicate in the metrics slice: postgresql.recovery_prefetch.skip_fpw")
					validatedMetrics["postgresql.recovery_prefetch.skip_fpw"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of prefetch requests skipped because a full page write was found (PostgreSQL 15+)", ms.At(i).Description())
					assert.Equal(t, "{requests}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.recovery_prefetch.skip_init":
					assert.False(t, validatedMetrics["postgresql.recovery_prefetch.skip_init"], "Found a duplicate in the metrics slice: postgresql.recovery_prefetch.skip_init")
					validatedMetrics["postgresql.recovery_prefetch.skip_init"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of prefetch requests skipped because the relation was being initialized (PostgreSQL 15+)", ms.At(i).Description())
					assert.Equal(t, "{requests}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.recovery_prefetch.skip_new":
					assert.False(t, validatedMetrics["postgresql.recovery_prefetch.skip_new"], "Found a duplicate in the metrics slice: postgresql.recovery_prefetch.skip_new")
					validatedMetrics["postgresql.recovery_prefetch.skip_new"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of prefetch requests skipped because the relation did not exist yet (PostgreSQL 15+)", ms.At(i).Description())
					assert.Equal(t, "{requests}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.recovery_prefetch.skip_rep":
					assert.False(t, validatedMetrics["postgresql.recovery_prefetch.skip_rep"], "Found a duplicate in the metrics slice: postgresql.recovery_prefetch.skip_rep")
					validatedMetrics["postgresql.recovery_prefetch.skip_rep"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of prefetch requests skipped because they were already in progress (PostgreSQL 15+)", ms.At(i).Description())
					assert.Equal(t, "{requests}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.recovery_prefetch.wal_distance":
					assert.False(t, validatedMetrics["postgresql.recovery_prefetch.wal_distance"], "Found a duplicate in the metrics slice: postgresql.recovery_prefetch.wal_distance")
					validatedMetrics["postgresql.recovery_prefetch.wal_distance"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Distance in WAL bytes between the current replay position and the prefetch position (PostgreSQL 15+)", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.relation.all_visible":
					assert.False(t, validatedMetrics["postgresql.relation.all_visible"], "Found a duplicate in the metrics slice: postgresql.relation.all_visible")
					validatedMetrics["postgresql.relation.all_visible"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of pages marked all-visible in the visibility map (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{pages}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.relation.pages":
					assert.False(t, validatedMetrics["postgresql.relation.pages"], "Found a duplicate in the metrics slice: postgresql.relation.pages")
					validatedMetrics["postgresql.relation.pages"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of disk pages in the relation (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{pages}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.relation.tuples":
					assert.False(t, validatedMetrics["postgresql.relation.tuples"], "Found a duplicate in the metrics slice: postgresql.relation.tuples")
					validatedMetrics["postgresql.relation.tuples"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Estimated number of live rows in the relation (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{rows}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.relation.xmin":
					assert.False(t, validatedMetrics["postgresql.relation.xmin"], "Found a duplicate in the metrics slice: postgresql.relation.xmin")
					validatedMetrics["postgresql.relation.xmin"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Age of the oldest unfrozen transaction ID in the relation (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{transactions}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.relation_size":
					assert.False(t, validatedMetrics["postgresql.relation_size"], "Found a duplicate in the metrics slice: postgresql.relation_size")
					validatedMetrics["postgresql.relation_size"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Size of the table data (heap) in bytes (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.replication.backend_xmin_age":
					assert.False(t, validatedMetrics["postgresql.replication.backend_xmin_age"], "Found a duplicate in the metrics slice: postgresql.replication.backend_xmin_age")
					validatedMetrics["postgresql.replication.backend_xmin_age"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Age of the oldest transaction on the standby server that is holding back vacuum", ms.At(i).Description())
					assert.Equal(t, "{transactions}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("application_name")
					assert.True(t, ok)
					assert.Equal(t, "application_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("client_address")
					assert.True(t, ok)
					assert.Equal(t, "client_address-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("replication_state")
					assert.True(t, ok)
					assert.Equal(t, "replication_state-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("sync_state")
					assert.True(t, ok)
					assert.Equal(t, "sync_state-val", attrVal.Str())
				case "postgresql.replication.flush_lsn_delay":
					assert.False(t, validatedMetrics["postgresql.replication.flush_lsn_delay"], "Found a duplicate in the metrics slice: postgresql.replication.flush_lsn_delay")
					validatedMetrics["postgresql.replication.flush_lsn_delay"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of bytes of WAL flushed but not yet applied on standby", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("application_name")
					assert.True(t, ok)
					assert.Equal(t, "application_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("client_address")
					assert.True(t, ok)
					assert.Equal(t, "client_address-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("replication_state")
					assert.True(t, ok)
					assert.Equal(t, "replication_state-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("sync_state")
					assert.True(t, ok)
					assert.Equal(t, "sync_state-val", attrVal.Str())
				case "postgresql.replication.replay_lsn_delay":
					assert.False(t, validatedMetrics["postgresql.replication.replay_lsn_delay"], "Found a duplicate in the metrics slice: postgresql.replication.replay_lsn_delay")
					validatedMetrics["postgresql.replication.replay_lsn_delay"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of bytes of WAL not yet replayed on standby (total replication lag in bytes)", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("application_name")
					assert.True(t, ok)
					assert.Equal(t, "application_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("client_address")
					assert.True(t, ok)
					assert.Equal(t, "client_address-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("replication_state")
					assert.True(t, ok)
					assert.Equal(t, "replication_state-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("sync_state")
					assert.True(t, ok)
					assert.Equal(t, "sync_state-val", attrVal.Str())
				case "postgresql.replication.sent_lsn_delay":
					assert.False(t, validatedMetrics["postgresql.replication.sent_lsn_delay"], "Found a duplicate in the metrics slice: postgresql.replication.sent_lsn_delay")
					validatedMetrics["postgresql.replication.sent_lsn_delay"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of bytes of WAL sent but not yet written to disk on standby", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("application_name")
					assert.True(t, ok)
					assert.Equal(t, "application_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("client_address")
					assert.True(t, ok)
					assert.Equal(t, "client_address-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("replication_state")
					assert.True(t, ok)
					assert.Equal(t, "replication_state-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("sync_state")
					assert.True(t, ok)
					assert.Equal(t, "sync_state-val", attrVal.Str())
				case "postgresql.replication.wal_flush_lag":
					assert.False(t, validatedMetrics["postgresql.replication.wal_flush_lag"], "Found a duplicate in the metrics slice: postgresql.replication.wal_flush_lag")
					validatedMetrics["postgresql.replication.wal_flush_lag"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time elapsed between WAL flush on primary and confirmation from standby (PostgreSQL 10+)", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("application_name")
					assert.True(t, ok)
					assert.Equal(t, "application_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("client_address")
					assert.True(t, ok)
					assert.Equal(t, "client_address-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("replication_state")
					assert.True(t, ok)
					assert.Equal(t, "replication_state-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("sync_state")
					assert.True(t, ok)
					assert.Equal(t, "sync_state-val", attrVal.Str())
				case "postgresql.replication.wal_replay_lag":
					assert.False(t, validatedMetrics["postgresql.replication.wal_replay_lag"], "Found a duplicate in the metrics slice: postgresql.replication.wal_replay_lag")
					validatedMetrics["postgresql.replication.wal_replay_lag"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time elapsed between WAL replay on primary and confirmation from standby (PostgreSQL 10+)", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("application_name")
					assert.True(t, ok)
					assert.Equal(t, "application_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("client_address")
					assert.True(t, ok)
					assert.Equal(t, "client_address-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("replication_state")
					assert.True(t, ok)
					assert.Equal(t, "replication_state-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("sync_state")
					assert.True(t, ok)
					assert.Equal(t, "sync_state-val", attrVal.Str())
				case "postgresql.replication.wal_write_lag":
					assert.False(t, validatedMetrics["postgresql.replication.wal_write_lag"], "Found a duplicate in the metrics slice: postgresql.replication.wal_write_lag")
					validatedMetrics["postgresql.replication.wal_write_lag"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time elapsed between WAL write on primary and confirmation from standby (PostgreSQL 10+)", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("application_name")
					assert.True(t, ok)
					assert.Equal(t, "application_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("client_address")
					assert.True(t, ok)
					assert.Equal(t, "client_address-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("replication_state")
					assert.True(t, ok)
					assert.Equal(t, "replication_state-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("sync_state")
					assert.True(t, ok)
					assert.Equal(t, "sync_state-val", attrVal.Str())
				case "postgresql.replication.write_lsn_delay":
					assert.False(t, validatedMetrics["postgresql.replication.write_lsn_delay"], "Found a duplicate in the metrics slice: postgresql.replication.write_lsn_delay")
					validatedMetrics["postgresql.replication.write_lsn_delay"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of bytes of WAL written but not yet flushed on standby", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("application_name")
					assert.True(t, ok)
					assert.Equal(t, "application_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("client_address")
					assert.True(t, ok)
					assert.Equal(t, "client_address-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("replication_state")
					assert.True(t, ok)
					assert.Equal(t, "replication_state-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("sync_state")
					assert.True(t, ok)
					assert.Equal(t, "sync_state-val", attrVal.Str())
				case "postgresql.replication_delay":
					assert.False(t, validatedMetrics["postgresql.replication_delay"], "Found a duplicate in the metrics slice: postgresql.replication_delay")
					validatedMetrics["postgresql.replication_delay"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time lag between primary and standby (standby-side metric, PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.replication_delay_bytes":
					assert.False(t, validatedMetrics["postgresql.replication_delay_bytes"], "Found a duplicate in the metrics slice: postgresql.replication_delay_bytes")
					validatedMetrics["postgresql.replication_delay_bytes"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Byte lag between WAL received and replayed on standby (standby-side metric, PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.replication_slot.catalog_xmin_age":
					assert.False(t, validatedMetrics["postgresql.replication_slot.catalog_xmin_age"], "Found a duplicate in the metrics slice: postgresql.replication_slot.catalog_xmin_age")
					validatedMetrics["postgresql.replication_slot.catalog_xmin_age"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Age of oldest transaction affecting system catalogs that this slot needs to keep (PostgreSQL 9.4+)", ms.At(i).Description())
					assert.Equal(t, "{transactions}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("slot_name")
					assert.True(t, ok)
					assert.Equal(t, "slot_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("slot_type")
					assert.True(t, ok)
					assert.Equal(t, "slot_type-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("plugin")
					assert.True(t, ok)
					assert.Equal(t, "plugin-val", attrVal.Str())
				case "postgresql.replication_slot.confirmed_flush_delay_bytes":
					assert.False(t, validatedMetrics["postgresql.replication_slot.confirmed_flush_delay_bytes"], "Found a duplicate in the metrics slice: postgresql.replication_slot.confirmed_flush_delay_bytes")
					validatedMetrics["postgresql.replication_slot.confirmed_flush_delay_bytes"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of bytes between current WAL position and confirmed_flush_lsn (logical slots only, PostgreSQL 9.4+)", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("slot_name")
					assert.True(t, ok)
					assert.Equal(t, "slot_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("slot_type")
					assert.True(t, ok)
					assert.Equal(t, "slot_type-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("plugin")
					assert.True(t, ok)
					assert.Equal(t, "plugin-val", attrVal.Str())
				case "postgresql.replication_slot.restart_delay_bytes":
					assert.False(t, validatedMetrics["postgresql.replication_slot.restart_delay_bytes"], "Found a duplicate in the metrics slice: postgresql.replication_slot.restart_delay_bytes")
					validatedMetrics["postgresql.replication_slot.restart_delay_bytes"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of bytes of WAL between current position and slot's restart_lsn (PostgreSQL 9.4+)", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("slot_name")
					assert.True(t, ok)
					assert.Equal(t, "slot_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("slot_type")
					assert.True(t, ok)
					assert.Equal(t, "slot_type-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("plugin")
					assert.True(t, ok)
					assert.Equal(t, "plugin-val", attrVal.Str())
				case "postgresql.replication_slot.spill_bytes":
					assert.False(t, validatedMetrics["postgresql.replication_slot.spill_bytes"], "Found a duplicate in the metrics slice: postgresql.replication_slot.spill_bytes")
					validatedMetrics["postgresql.replication_slot.spill_bytes"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Total amount of data spilled to disk for logical decoding (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("slot_name")
					assert.True(t, ok)
					assert.Equal(t, "slot_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("slot_type")
					assert.True(t, ok)
					assert.Equal(t, "slot_type-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("state")
					assert.True(t, ok)
					assert.Equal(t, "state-val", attrVal.Str())
				case "postgresql.replication_slot.spill_count":
					assert.False(t, validatedMetrics["postgresql.replication_slot.spill_count"], "Found a duplicate in the metrics slice: postgresql.replication_slot.spill_count")
					validatedMetrics["postgresql.replication_slot.spill_count"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of times transactions were spilled to disk during logical decoding (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "{spills}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("slot_name")
					assert.True(t, ok)
					assert.Equal(t, "slot_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("slot_type")
					assert.True(t, ok)
					assert.Equal(t, "slot_type-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("state")
					assert.True(t, ok)
					assert.Equal(t, "state-val", attrVal.Str())
				case "postgresql.replication_slot.spill_txns":
					assert.False(t, validatedMetrics["postgresql.replication_slot.spill_txns"], "Found a duplicate in the metrics slice: postgresql.replication_slot.spill_txns")
					validatedMetrics["postgresql.replication_slot.spill_txns"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of transactions spilled to disk during logical decoding (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "{transactions}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("slot_name")
					assert.True(t, ok)
					assert.Equal(t, "slot_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("slot_type")
					assert.True(t, ok)
					assert.Equal(t, "slot_type-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("state")
					assert.True(t, ok)
					assert.Equal(t, "state-val", attrVal.Str())
				case "postgresql.replication_slot.stream_bytes":
					assert.False(t, validatedMetrics["postgresql.replication_slot.stream_bytes"], "Found a duplicate in the metrics slice: postgresql.replication_slot.stream_bytes")
					validatedMetrics["postgresql.replication_slot.stream_bytes"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Total amount of data streamed for in-progress transactions during logical decoding (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("slot_name")
					assert.True(t, ok)
					assert.Equal(t, "slot_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("slot_type")
					assert.True(t, ok)
					assert.Equal(t, "slot_type-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("state")
					assert.True(t, ok)
					assert.Equal(t, "state-val", attrVal.Str())
				case "postgresql.replication_slot.stream_count":
					assert.False(t, validatedMetrics["postgresql.replication_slot.stream_count"], "Found a duplicate in the metrics slice: postgresql.replication_slot.stream_count")
					validatedMetrics["postgresql.replication_slot.stream_count"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of times in-progress transactions were streamed during logical decoding (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "{streams}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("slot_name")
					assert.True(t, ok)
					assert.Equal(t, "slot_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("slot_type")
					assert.True(t, ok)
					assert.Equal(t, "slot_type-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("state")
					assert.True(t, ok)
					assert.Equal(t, "state-val", attrVal.Str())
				case "postgresql.replication_slot.stream_txns":
					assert.False(t, validatedMetrics["postgresql.replication_slot.stream_txns"], "Found a duplicate in the metrics slice: postgresql.replication_slot.stream_txns")
					validatedMetrics["postgresql.replication_slot.stream_txns"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of in-progress transactions streamed during logical decoding (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "{transactions}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("slot_name")
					assert.True(t, ok)
					assert.Equal(t, "slot_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("slot_type")
					assert.True(t, ok)
					assert.Equal(t, "slot_type-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("state")
					assert.True(t, ok)
					assert.Equal(t, "state-val", attrVal.Str())
				case "postgresql.replication_slot.total_bytes":
					assert.False(t, validatedMetrics["postgresql.replication_slot.total_bytes"], "Found a duplicate in the metrics slice: postgresql.replication_slot.total_bytes")
					validatedMetrics["postgresql.replication_slot.total_bytes"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Total amount of data decoded for transactions during logical decoding (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("slot_name")
					assert.True(t, ok)
					assert.Equal(t, "slot_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("slot_type")
					assert.True(t, ok)
					assert.Equal(t, "slot_type-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("state")
					assert.True(t, ok)
					assert.Equal(t, "state-val", attrVal.Str())
				case "postgresql.replication_slot.total_txns":
					assert.False(t, validatedMetrics["postgresql.replication_slot.total_txns"], "Found a duplicate in the metrics slice: postgresql.replication_slot.total_txns")
					validatedMetrics["postgresql.replication_slot.total_txns"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Total number of decoded transactions during logical decoding (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "{transactions}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("slot_name")
					assert.True(t, ok)
					assert.Equal(t, "slot_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("slot_type")
					assert.True(t, ok)
					assert.Equal(t, "slot_type-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("state")
					assert.True(t, ok)
					assert.Equal(t, "state-val", attrVal.Str())
				case "postgresql.replication_slot.xmin_age":
					assert.False(t, validatedMetrics["postgresql.replication_slot.xmin_age"], "Found a duplicate in the metrics slice: postgresql.replication_slot.xmin_age")
					validatedMetrics["postgresql.replication_slot.xmin_age"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Age of oldest transaction that this replication slot needs to keep (PostgreSQL 9.4+)", ms.At(i).Description())
					assert.Equal(t, "{transactions}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("slot_name")
					assert.True(t, ok)
					assert.Equal(t, "slot_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("slot_type")
					assert.True(t, ok)
					assert.Equal(t, "slot_type-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("plugin")
					assert.True(t, ok)
					assert.Equal(t, "plugin-val", attrVal.Str())
				case "postgresql.rollbacks":
					assert.False(t, validatedMetrics["postgresql.rollbacks"], "Found a duplicate in the metrics slice: postgresql.rollbacks")
					validatedMetrics["postgresql.rollbacks"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of transactions that have been rolled back", ms.At(i).Description())
					assert.Equal(t, "{transactions}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.rows_deleted":
					assert.False(t, validatedMetrics["postgresql.rows_deleted"], "Found a duplicate in the metrics slice: postgresql.rows_deleted")
					validatedMetrics["postgresql.rows_deleted"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of rows deleted", ms.At(i).Description())
					assert.Equal(t, "{rows}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.rows_fetched":
					assert.False(t, validatedMetrics["postgresql.rows_fetched"], "Found a duplicate in the metrics slice: postgresql.rows_fetched")
					validatedMetrics["postgresql.rows_fetched"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of rows fetched by queries", ms.At(i).Description())
					assert.Equal(t, "{rows}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.rows_inserted":
					assert.False(t, validatedMetrics["postgresql.rows_inserted"], "Found a duplicate in the metrics slice: postgresql.rows_inserted")
					validatedMetrics["postgresql.rows_inserted"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of rows inserted", ms.At(i).Description())
					assert.Equal(t, "{rows}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.rows_returned":
					assert.False(t, validatedMetrics["postgresql.rows_returned"], "Found a duplicate in the metrics slice: postgresql.rows_returned")
					validatedMetrics["postgresql.rows_returned"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of rows returned by queries", ms.At(i).Description())
					assert.Equal(t, "{rows}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.rows_updated":
					assert.False(t, validatedMetrics["postgresql.rows_updated"], "Found a duplicate in the metrics slice: postgresql.rows_updated")
					validatedMetrics["postgresql.rows_updated"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of rows updated", ms.At(i).Description())
					assert.Equal(t, "{rows}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.running":
					assert.False(t, validatedMetrics["postgresql.running"], "Found a duplicate in the metrics slice: postgresql.running")
					validatedMetrics["postgresql.running"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "PostgreSQL server running status health check (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{status}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.sessions.abandoned":
					assert.False(t, validatedMetrics["postgresql.sessions.abandoned"], "Found a duplicate in the metrics slice: postgresql.sessions.abandoned")
					validatedMetrics["postgresql.sessions.abandoned"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of sessions abandoned due to client disconnection (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "{sessions}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.sessions.active_time":
					assert.False(t, validatedMetrics["postgresql.sessions.active_time"], "Found a duplicate in the metrics slice: postgresql.sessions.active_time")
					validatedMetrics["postgresql.sessions.active_time"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time spent executing queries in this database (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "ms", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.sessions.count":
					assert.False(t, validatedMetrics["postgresql.sessions.count"], "Found a duplicate in the metrics slice: postgresql.sessions.count")
					validatedMetrics["postgresql.sessions.count"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of sessions established to this database (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "{sessions}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.sessions.fatal":
					assert.False(t, validatedMetrics["postgresql.sessions.fatal"], "Found a duplicate in the metrics slice: postgresql.sessions.fatal")
					validatedMetrics["postgresql.sessions.fatal"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of sessions terminated by fatal errors (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "{sessions}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.sessions.idle_in_transaction_time":
					assert.False(t, validatedMetrics["postgresql.sessions.idle_in_transaction_time"], "Found a duplicate in the metrics slice: postgresql.sessions.idle_in_transaction_time")
					validatedMetrics["postgresql.sessions.idle_in_transaction_time"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time spent idle in transactions in this database (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "ms", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.sessions.killed":
					assert.False(t, validatedMetrics["postgresql.sessions.killed"], "Found a duplicate in the metrics slice: postgresql.sessions.killed")
					validatedMetrics["postgresql.sessions.killed"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of sessions terminated by operator intervention (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "{sessions}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.sessions.session_time":
					assert.False(t, validatedMetrics["postgresql.sessions.session_time"], "Found a duplicate in the metrics slice: postgresql.sessions.session_time")
					validatedMetrics["postgresql.sessions.session_time"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time spent in sessions for this database (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "ms", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.slru.blks_exists":
					assert.False(t, validatedMetrics["postgresql.slru.blks_exists"], "Found a duplicate in the metrics slice: postgresql.slru.blks_exists")
					validatedMetrics["postgresql.slru.blks_exists"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of blocks checked for existence for this SLRU (PostgreSQL 13+)", ms.At(i).Description())
					assert.Equal(t, "{blocks}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("slru_name")
					assert.True(t, ok)
					assert.Equal(t, "slru_name-val", attrVal.Str())
				case "postgresql.slru.blks_hit":
					assert.False(t, validatedMetrics["postgresql.slru.blks_hit"], "Found a duplicate in the metrics slice: postgresql.slru.blks_hit")
					validatedMetrics["postgresql.slru.blks_hit"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of times disk blocks were found already in the SLRU cache (PostgreSQL 13+)", ms.At(i).Description())
					assert.Equal(t, "{blocks}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("slru_name")
					assert.True(t, ok)
					assert.Equal(t, "slru_name-val", attrVal.Str())
				case "postgresql.slru.blks_read":
					assert.False(t, validatedMetrics["postgresql.slru.blks_read"], "Found a duplicate in the metrics slice: postgresql.slru.blks_read")
					validatedMetrics["postgresql.slru.blks_read"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of disk blocks read for this SLRU (PostgreSQL 13+)", ms.At(i).Description())
					assert.Equal(t, "{blocks}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("slru_name")
					assert.True(t, ok)
					assert.Equal(t, "slru_name-val", attrVal.Str())
				case "postgresql.slru.blks_written":
					assert.False(t, validatedMetrics["postgresql.slru.blks_written"], "Found a duplicate in the metrics slice: postgresql.slru.blks_written")
					validatedMetrics["postgresql.slru.blks_written"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of disk blocks written for this SLRU (PostgreSQL 13+)", ms.At(i).Description())
					assert.Equal(t, "{blocks}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("slru_name")
					assert.True(t, ok)
					assert.Equal(t, "slru_name-val", attrVal.Str())
				case "postgresql.slru.blks_zeroed":
					assert.False(t, validatedMetrics["postgresql.slru.blks_zeroed"], "Found a duplicate in the metrics slice: postgresql.slru.blks_zeroed")
					validatedMetrics["postgresql.slru.blks_zeroed"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of blocks zeroed during initializations for this SLRU (PostgreSQL 13+)", ms.At(i).Description())
					assert.Equal(t, "{blocks}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("slru_name")
					assert.True(t, ok)
					assert.Equal(t, "slru_name-val", attrVal.Str())
				case "postgresql.slru.flushes":
					assert.False(t, validatedMetrics["postgresql.slru.flushes"], "Found a duplicate in the metrics slice: postgresql.slru.flushes")
					validatedMetrics["postgresql.slru.flushes"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of flushes of dirty data for this SLRU (PostgreSQL 13+)", ms.At(i).Description())
					assert.Equal(t, "{flushes}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("slru_name")
					assert.True(t, ok)
					assert.Equal(t, "slru_name-val", attrVal.Str())
				case "postgresql.slru.truncates":
					assert.False(t, validatedMetrics["postgresql.slru.truncates"], "Found a duplicate in the metrics slice: postgresql.slru.truncates")
					validatedMetrics["postgresql.slru.truncates"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of truncates for this SLRU (PostgreSQL 13+)", ms.At(i).Description())
					assert.Equal(t, "{truncates}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("slru_name")
					assert.True(t, ok)
					assert.Equal(t, "slru_name-val", attrVal.Str())
				case "postgresql.snapshot.xip_count":
					assert.False(t, validatedMetrics["postgresql.snapshot.xip_count"], "Found a duplicate in the metrics slice: postgresql.snapshot.xip_count")
					validatedMetrics["postgresql.snapshot.xip_count"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of in-progress transactions in the current snapshot (PostgreSQL 13+)", ms.At(i).Description())
					assert.Equal(t, "{transactions}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.snapshot.xmax":
					assert.False(t, validatedMetrics["postgresql.snapshot.xmax"], "Found a duplicate in the metrics slice: postgresql.snapshot.xmax")
					validatedMetrics["postgresql.snapshot.xmax"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "First as-yet-unassigned transaction ID in the current snapshot (PostgreSQL 13+)", ms.At(i).Description())
					assert.Equal(t, "{xid}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.snapshot.xmin":
					assert.False(t, validatedMetrics["postgresql.snapshot.xmin"], "Found a duplicate in the metrics slice: postgresql.snapshot.xmin")
					validatedMetrics["postgresql.snapshot.xmin"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Earliest transaction ID still active in the current snapshot (PostgreSQL 13+)", ms.At(i).Description())
					assert.Equal(t, "{xid}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.subscription.apply_error":
					assert.False(t, validatedMetrics["postgresql.subscription.apply_error"], "Found a duplicate in the metrics slice: postgresql.subscription.apply_error")
					validatedMetrics["postgresql.subscription.apply_error"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of errors encountered while applying logical replication changes (PostgreSQL 15+)", ms.At(i).Description())
					assert.Equal(t, "{errors}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("subscription_name")
					assert.True(t, ok)
					assert.Equal(t, "subscription_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("state")
					assert.True(t, ok)
					assert.Equal(t, "state-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.subscription.last_msg_receipt_age":
					assert.False(t, validatedMetrics["postgresql.subscription.last_msg_receipt_age"], "Found a duplicate in the metrics slice: postgresql.subscription.last_msg_receipt_age")
					validatedMetrics["postgresql.subscription.last_msg_receipt_age"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time elapsed since last message received from publisher in logical replication (PostgreSQL 15+)", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("subscription_name")
					assert.True(t, ok)
					assert.Equal(t, "subscription_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("state")
					assert.True(t, ok)
					assert.Equal(t, "state-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.subscription.last_msg_send_age":
					assert.False(t, validatedMetrics["postgresql.subscription.last_msg_send_age"], "Found a duplicate in the metrics slice: postgresql.subscription.last_msg_send_age")
					validatedMetrics["postgresql.subscription.last_msg_send_age"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time elapsed since last message sent from publisher in logical replication (PostgreSQL 15+)", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("subscription_name")
					assert.True(t, ok)
					assert.Equal(t, "subscription_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("state")
					assert.True(t, ok)
					assert.Equal(t, "state-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.subscription.latest_end_age":
					assert.False(t, validatedMetrics["postgresql.subscription.latest_end_age"], "Found a duplicate in the metrics slice: postgresql.subscription.latest_end_age")
					validatedMetrics["postgresql.subscription.latest_end_age"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time elapsed since latest WAL location reported to publisher in logical replication (PostgreSQL 15+)", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("subscription_name")
					assert.True(t, ok)
					assert.Equal(t, "subscription_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("state")
					assert.True(t, ok)
					assert.Equal(t, "state-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.subscription.sync_error":
					assert.False(t, validatedMetrics["postgresql.subscription.sync_error"], "Found a duplicate in the metrics slice: postgresql.subscription.sync_error")
					validatedMetrics["postgresql.subscription.sync_error"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of errors encountered during initial sync in logical replication (PostgreSQL 15+)", ms.At(i).Description())
					assert.Equal(t, "{errors}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("subscription_name")
					assert.True(t, ok)
					assert.Equal(t, "subscription_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("state")
					assert.True(t, ok)
					assert.Equal(t, "state-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.temp_bytes":
					assert.False(t, validatedMetrics["postgresql.temp_bytes"], "Found a duplicate in the metrics slice: postgresql.temp_bytes")
					validatedMetrics["postgresql.temp_bytes"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Total amount of data written to temporary files", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.temp_files":
					assert.False(t, validatedMetrics["postgresql.temp_files"], "Found a duplicate in the metrics slice: postgresql.temp_files")
					validatedMetrics["postgresql.temp_files"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of temporary files created", ms.At(i).Description())
					assert.Equal(t, "{files}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.toast.autovacuumed":
					assert.False(t, validatedMetrics["postgresql.toast.autovacuumed"], "Found a duplicate in the metrics slice: postgresql.toast.autovacuumed")
					validatedMetrics["postgresql.toast.autovacuumed"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of times this TOAST table has been vacuumed by autovacuum (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{operations}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.toast.last_autovacuum_age":
					assert.False(t, validatedMetrics["postgresql.toast.last_autovacuum_age"], "Found a duplicate in the metrics slice: postgresql.toast.last_autovacuum_age")
					validatedMetrics["postgresql.toast.last_autovacuum_age"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Seconds since last autovacuum on this TOAST table (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.toast.last_vacuum_age":
					assert.False(t, validatedMetrics["postgresql.toast.last_vacuum_age"], "Found a duplicate in the metrics slice: postgresql.toast.last_vacuum_age")
					validatedMetrics["postgresql.toast.last_vacuum_age"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Seconds since last manual VACUUM on this TOAST table (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.toast.vacuumed":
					assert.False(t, validatedMetrics["postgresql.toast.vacuumed"], "Found a duplicate in the metrics slice: postgresql.toast.vacuumed")
					validatedMetrics["postgresql.toast.vacuumed"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of times this TOAST table has been manually vacuumed (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{operations}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.toast_blocks_hit":
					assert.False(t, validatedMetrics["postgresql.toast_blocks_hit"], "Found a duplicate in the metrics slice: postgresql.toast_blocks_hit")
					validatedMetrics["postgresql.toast_blocks_hit"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of TOAST blocks read from buffer cache for this table (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{blocks}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.toast_blocks_read":
					assert.False(t, validatedMetrics["postgresql.toast_blocks_read"], "Found a duplicate in the metrics slice: postgresql.toast_blocks_read")
					validatedMetrics["postgresql.toast_blocks_read"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of TOAST blocks read from disk for this table (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{blocks}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.toast_index_blocks_hit":
					assert.False(t, validatedMetrics["postgresql.toast_index_blocks_hit"], "Found a duplicate in the metrics slice: postgresql.toast_index_blocks_hit")
					validatedMetrics["postgresql.toast_index_blocks_hit"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of TOAST index blocks read from buffer cache for this table (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{blocks}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.toast_index_blocks_read":
					assert.False(t, validatedMetrics["postgresql.toast_index_blocks_read"], "Found a duplicate in the metrics slice: postgresql.toast_index_blocks_read")
					validatedMetrics["postgresql.toast_index_blocks_read"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of TOAST index blocks read from disk for this table (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{blocks}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.toast_size":
					assert.False(t, validatedMetrics["postgresql.toast_size"], "Found a duplicate in the metrics slice: postgresql.toast_size")
					validatedMetrics["postgresql.toast_size"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Size of the TOAST data for this table in bytes (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.transactions.duration.max":
					assert.False(t, validatedMetrics["postgresql.transactions.duration.max"], "Found a duplicate in the metrics slice: postgresql.transactions.duration.max")
					validatedMetrics["postgresql.transactions.duration.max"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Maximum transaction duration in seconds across all active backends (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("user_name")
					assert.True(t, ok)
					assert.Equal(t, "user_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("application_name")
					assert.True(t, ok)
					assert.Equal(t, "application_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("backend_type")
					assert.True(t, ok)
					assert.Equal(t, "backend_type-val", attrVal.Str())
				case "postgresql.transactions.duration.sum":
					assert.False(t, validatedMetrics["postgresql.transactions.duration.sum"], "Found a duplicate in the metrics slice: postgresql.transactions.duration.sum")
					validatedMetrics["postgresql.transactions.duration.sum"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Sum of transaction durations in seconds across all active backends (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("user_name")
					assert.True(t, ok)
					assert.Equal(t, "user_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("application_name")
					assert.True(t, ok)
					assert.Equal(t, "application_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("backend_type")
					assert.True(t, ok)
					assert.Equal(t, "backend_type-val", attrVal.Str())
				case "postgresql.uptime":
					assert.False(t, validatedMetrics["postgresql.uptime"], "Found a duplicate in the metrics slice: postgresql.uptime")
					validatedMetrics["postgresql.uptime"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "PostgreSQL server uptime in seconds (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.vacuum.heap_blks_scanned":
					assert.False(t, validatedMetrics["postgresql.vacuum.heap_blks_scanned"], "Found a duplicate in the metrics slice: postgresql.vacuum.heap_blks_scanned")
					validatedMetrics["postgresql.vacuum.heap_blks_scanned"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of heap blocks scanned during VACUUM operation (PostgreSQL 12+)", ms.At(i).Description())
					assert.Equal(t, "{blocks}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.vacuum.heap_blks_total":
					assert.False(t, validatedMetrics["postgresql.vacuum.heap_blks_total"], "Found a duplicate in the metrics slice: postgresql.vacuum.heap_blks_total")
					validatedMetrics["postgresql.vacuum.heap_blks_total"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Total number of heap blocks to be scanned during VACUUM (PostgreSQL 12+)", ms.At(i).Description())
					assert.Equal(t, "{blocks}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.vacuum.heap_blks_vacuumed":
					assert.False(t, validatedMetrics["postgresql.vacuum.heap_blks_vacuumed"], "Found a duplicate in the metrics slice: postgresql.vacuum.heap_blks_vacuumed")
					validatedMetrics["postgresql.vacuum.heap_blks_vacuumed"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of heap blocks vacuumed during VACUUM operation (PostgreSQL 12+)", ms.At(i).Description())
					assert.Equal(t, "{blocks}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.vacuum.index_vacuum_count":
					assert.False(t, validatedMetrics["postgresql.vacuum.index_vacuum_count"], "Found a duplicate in the metrics slice: postgresql.vacuum.index_vacuum_count")
					validatedMetrics["postgresql.vacuum.index_vacuum_count"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of completed index vacuum cycles during VACUUM operation (PostgreSQL 12+)", ms.At(i).Description())
					assert.Equal(t, "{cycles}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.vacuum.max_dead_tuples":
					assert.False(t, validatedMetrics["postgresql.vacuum.max_dead_tuples"], "Found a duplicate in the metrics slice: postgresql.vacuum.max_dead_tuples")
					validatedMetrics["postgresql.vacuum.max_dead_tuples"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Maximum number of dead tuples that can be stored before index vacuum is required (PostgreSQL 12+)", ms.At(i).Description())
					assert.Equal(t, "{tuples}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.vacuum.num_dead_tuples":
					assert.False(t, validatedMetrics["postgresql.vacuum.num_dead_tuples"], "Found a duplicate in the metrics slice: postgresql.vacuum.num_dead_tuples")
					validatedMetrics["postgresql.vacuum.num_dead_tuples"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Current number of dead tuples collected during VACUUM operation (PostgreSQL 12+)", ms.At(i).Description())
					assert.Equal(t, "{tuples}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("database_name")
					assert.True(t, ok)
					assert.Equal(t, "database_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.vacuumed":
					assert.False(t, validatedMetrics["postgresql.vacuumed"], "Found a duplicate in the metrics slice: postgresql.vacuumed")
					validatedMetrics["postgresql.vacuumed"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of times this table has been manually vacuumed (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{operations}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("schema_name")
					assert.True(t, ok)
					assert.Equal(t, "schema_name-val", attrVal.Str())
					attrVal, ok = dp.Attributes().Get("table_name")
					assert.True(t, ok)
					assert.Equal(t, "table_name-val", attrVal.Str())
				case "postgresql.wal.buffers_full":
					assert.False(t, validatedMetrics["postgresql.wal.buffers_full"], "Found a duplicate in the metrics slice: postgresql.wal.buffers_full")
					validatedMetrics["postgresql.wal.buffers_full"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of times WAL data was written because WAL buffers became full (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "{buffers}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.wal.bytes":
					assert.False(t, validatedMetrics["postgresql.wal.bytes"], "Found a duplicate in the metrics slice: postgresql.wal.bytes")
					validatedMetrics["postgresql.wal.bytes"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Total amount of WAL bytes generated (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.wal.fpi":
					assert.False(t, validatedMetrics["postgresql.wal.fpi"], "Found a duplicate in the metrics slice: postgresql.wal.fpi")
					validatedMetrics["postgresql.wal.fpi"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Total number of WAL full page images generated (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "{images}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.wal.records":
					assert.False(t, validatedMetrics["postgresql.wal.records"], "Found a duplicate in the metrics slice: postgresql.wal.records")
					validatedMetrics["postgresql.wal.records"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Total number of WAL records generated (PostgreSQL 14+)", ms.At(i).Description())
					assert.Equal(t, "{records}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.wal.sync":
					assert.False(t, validatedMetrics["postgresql.wal.sync"], "Found a duplicate in the metrics slice: postgresql.wal.sync")
					validatedMetrics["postgresql.wal.sync"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of times WAL files were synced to disk (PostgreSQL 14-17)", ms.At(i).Description())
					assert.Equal(t, "{syncs}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.wal.sync_time":
					assert.False(t, validatedMetrics["postgresql.wal.sync_time"], "Found a duplicate in the metrics slice: postgresql.wal.sync_time")
					validatedMetrics["postgresql.wal.sync_time"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Total time spent syncing WAL files to disk (PostgreSQL 14-17)", ms.At(i).Description())
					assert.Equal(t, "ms", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.wal.write":
					assert.False(t, validatedMetrics["postgresql.wal.write"], "Found a duplicate in the metrics slice: postgresql.wal.write")
					validatedMetrics["postgresql.wal.write"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Number of times WAL buffers were written to disk (PostgreSQL 14-17)", ms.At(i).Description())
					assert.Equal(t, "{writes}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.wal.write_time":
					assert.False(t, validatedMetrics["postgresql.wal.write_time"], "Found a duplicate in the metrics slice: postgresql.wal.write_time")
					validatedMetrics["postgresql.wal.write_time"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Total time spent writing WAL buffers to disk (PostgreSQL 14-17)", ms.At(i).Description())
					assert.Equal(t, "ms", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.wal_files.age":
					assert.False(t, validatedMetrics["postgresql.wal_files.age"], "Found a duplicate in the metrics slice: postgresql.wal_files.age")
					validatedMetrics["postgresql.wal_files.age"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Age of the oldest WAL file in seconds (PostgreSQL 10+)", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.wal_files.count":
					assert.False(t, validatedMetrics["postgresql.wal_files.count"], "Found a duplicate in the metrics slice: postgresql.wal_files.count")
					validatedMetrics["postgresql.wal_files.count"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Total number of WAL files in the pg_wal directory (PostgreSQL 10+)", ms.At(i).Description())
					assert.Equal(t, "{files}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.wal_files.size":
					assert.False(t, validatedMetrics["postgresql.wal_files.size"], "Found a duplicate in the metrics slice: postgresql.wal_files.size")
					validatedMetrics["postgresql.wal_files.size"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Total size of all WAL files in bytes (PostgreSQL 10+)", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.wal_receiver.connected":
					assert.False(t, validatedMetrics["postgresql.wal_receiver.connected"], "Found a duplicate in the metrics slice: postgresql.wal_receiver.connected")
					validatedMetrics["postgresql.wal_receiver.connected"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Whether WAL receiver is connected (1 if streaming, 0 otherwise, PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{status}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.wal_receiver.last_msg_receipt_age":
					assert.False(t, validatedMetrics["postgresql.wal_receiver.last_msg_receipt_age"], "Found a duplicate in the metrics slice: postgresql.wal_receiver.last_msg_receipt_age")
					validatedMetrics["postgresql.wal_receiver.last_msg_receipt_age"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time elapsed since last message received by WAL receiver from primary (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.wal_receiver.last_msg_send_age":
					assert.False(t, validatedMetrics["postgresql.wal_receiver.last_msg_send_age"], "Found a duplicate in the metrics slice: postgresql.wal_receiver.last_msg_send_age")
					validatedMetrics["postgresql.wal_receiver.last_msg_send_age"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time elapsed since last message sent from primary to WAL receiver (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.wal_receiver.latest_end_age":
					assert.False(t, validatedMetrics["postgresql.wal_receiver.latest_end_age"], "Found a duplicate in the metrics slice: postgresql.wal_receiver.latest_end_age")
					validatedMetrics["postgresql.wal_receiver.latest_end_age"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Time elapsed since last WAL location reported back to primary by WAL receiver (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				case "postgresql.wal_receiver.received_timeline":
					assert.False(t, validatedMetrics["postgresql.wal_receiver.received_timeline"], "Found a duplicate in the metrics slice: postgresql.wal_receiver.received_timeline")
					validatedMetrics["postgresql.wal_receiver.received_timeline"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Timeline number of last WAL file received and synced to disk by WAL receiver (PostgreSQL 9.6+)", ms.At(i).Description())
					assert.Equal(t, "{timeline}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("newrelicpostgresql.instance_name")
					assert.True(t, ok)
					assert.Equal(t, "newrelicpostgresql.instance_name-val", attrVal.Str())
				}
			}
		})
	}
}
