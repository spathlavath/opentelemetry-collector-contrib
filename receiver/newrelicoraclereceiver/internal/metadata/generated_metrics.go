// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"time"

	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/filter"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
	"go.opentelemetry.io/collector/receiver"
)

var MetricsInfo = metricsInfo{
	NewrelicoracledbConcurrencyEnqueueRoFastObjectReuse: metricInfo{
		Name: "newrelicoracledb.concurrency.enqueue_ro_fast_object_reuse",
	},
	NewrelicoracledbConcurrencyReadByOtherSession: metricInfo{
		Name: "newrelicoracledb.concurrency.read_by_other_session",
	},
	NewrelicoracledbIoControlFileParallelWrite: metricInfo{
		Name: "newrelicoracledb.io.control_file_parallel_write",
	},
	NewrelicoracledbIoControlFileSequentialRead: metricInfo{
		Name: "newrelicoracledb.io.control_file_sequential_read",
	},
	NewrelicoracledbIoDataFileInitWrite: metricInfo{
		Name: "newrelicoracledb.io.data_file_init_write",
	},
	NewrelicoracledbIoDbFileScatteredRead: metricInfo{
		Name: "newrelicoracledb.io.db_file_scattered_read",
	},
	NewrelicoracledbIoDbFileSequentialRead: metricInfo{
		Name: "newrelicoracledb.io.db_file_sequential_read",
	},
	NewrelicoracledbIoDiskFileOperations: metricInfo{
		Name: "newrelicoracledb.io.disk_file_operations",
	},
	NewrelicoracledbIoLocalWriteWait: metricInfo{
		Name: "newrelicoracledb.io.local_write_wait",
	},
	NewrelicoracledbLockedAccounts: metricInfo{
		Name: "newrelicoracledb.locked_accounts",
	},
	NewrelicoracledbRedoLogLogFileSwitch: metricInfo{
		Name: "newrelicoracledb.redo_log.log_file_switch",
	},
	NewrelicoracledbRedoLogLogFileSwitchArchivingNeeded: metricInfo{
		Name: "newrelicoracledb.redo_log.log_file_switch_archiving_needed",
	},
	NewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete: metricInfo{
		Name: "newrelicoracledb.redo_log.log_file_switch_checkpoint_incomplete",
	},
	NewrelicoracledbRedoLogSync: metricInfo{
		Name: "newrelicoracledb.redo_log.sync",
	},
	NewrelicoracledbRedoLogWaits: metricInfo{
		Name: "newrelicoracledb.redo_log.waits",
	},
	NewrelicoracledbSessionsCount: metricInfo{
		Name: "newrelicoracledb.sessions.count",
	},
	NewrelicoracledbSgaBufferBusyWaits: metricInfo{
		Name: "newrelicoracledb.sga.buffer_busy_waits",
	},
	NewrelicoracledbSgaFreeBufferInspected: metricInfo{
		Name: "newrelicoracledb.sga.free_buffer_inspected",
	},
	NewrelicoracledbSgaFreeBufferWaits: metricInfo{
		Name: "newrelicoracledb.sga.free_buffer_waits",
	},
	NewrelicoracledbSynchronizationDirectPathSync: metricInfo{
		Name: "newrelicoracledb.synchronization.direct_path_sync",
	},
	NewrelicoracledbTablespaceDbID: metricInfo{
		Name: "newrelicoracledb.tablespace.db_id",
	},
	NewrelicoracledbTablespaceGlobalName: metricInfo{
		Name: "newrelicoracledb.tablespace.global_name",
	},
	NewrelicoracledbTablespaceIsOffline: metricInfo{
		Name: "newrelicoracledb.tablespace.is_offline",
	},
	NewrelicoracledbTablespaceOfflineCdbDatafiles: metricInfo{
		Name: "newrelicoracledb.tablespace.offline_cdb_datafiles",
	},
	NewrelicoracledbTablespaceOfflinePdbDatafiles: metricInfo{
		Name: "newrelicoracledb.tablespace.offline_pdb_datafiles",
	},
	NewrelicoracledbTablespacePdbNonWriteMode: metricInfo{
		Name: "newrelicoracledb.tablespace.pdb_non_write_mode",
	},
	NewrelicoracledbTablespaceSpaceConsumedBytes: metricInfo{
		Name: "newrelicoracledb.tablespace.space_consumed_bytes",
	},
	NewrelicoracledbTablespaceSpaceReservedBytes: metricInfo{
		Name: "newrelicoracledb.tablespace.space_reserved_bytes",
	},
	NewrelicoracledbTablespaceSpaceUsedPercentage: metricInfo{
		Name: "newrelicoracledb.tablespace.space_used_percentage",
	},
}

type metricsInfo struct {
	NewrelicoracledbConcurrencyEnqueueRoFastObjectReuse      metricInfo
	NewrelicoracledbConcurrencyReadByOtherSession            metricInfo
	NewrelicoracledbIoControlFileParallelWrite               metricInfo
	NewrelicoracledbIoControlFileSequentialRead              metricInfo
	NewrelicoracledbIoDataFileInitWrite                      metricInfo
	NewrelicoracledbIoDbFileScatteredRead                    metricInfo
	NewrelicoracledbIoDbFileSequentialRead                   metricInfo
	NewrelicoracledbIoDiskFileOperations                     metricInfo
	NewrelicoracledbIoLocalWriteWait                         metricInfo
	NewrelicoracledbLockedAccounts                           metricInfo
	NewrelicoracledbRedoLogLogFileSwitch                     metricInfo
	NewrelicoracledbRedoLogLogFileSwitchArchivingNeeded      metricInfo
	NewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete metricInfo
	NewrelicoracledbRedoLogSync                              metricInfo
	NewrelicoracledbRedoLogWaits                             metricInfo
	NewrelicoracledbSessionsCount                            metricInfo
	NewrelicoracledbSgaBufferBusyWaits                       metricInfo
	NewrelicoracledbSgaFreeBufferInspected                   metricInfo
	NewrelicoracledbSgaFreeBufferWaits                       metricInfo
	NewrelicoracledbSynchronizationDirectPathSync            metricInfo
	NewrelicoracledbTablespaceDbID                           metricInfo
	NewrelicoracledbTablespaceGlobalName                     metricInfo
	NewrelicoracledbTablespaceIsOffline                      metricInfo
	NewrelicoracledbTablespaceOfflineCdbDatafiles            metricInfo
	NewrelicoracledbTablespaceOfflinePdbDatafiles            metricInfo
	NewrelicoracledbTablespacePdbNonWriteMode                metricInfo
	NewrelicoracledbTablespaceSpaceConsumedBytes             metricInfo
	NewrelicoracledbTablespaceSpaceReservedBytes             metricInfo
	NewrelicoracledbTablespaceSpaceUsedPercentage            metricInfo
}

type metricInfo struct {
	Name string
}

type metricNewrelicoracledbConcurrencyEnqueueRoFastObjectReuse struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.concurrency.enqueue_ro_fast_object_reuse metric with initial data.
func (m *metricNewrelicoracledbConcurrencyEnqueueRoFastObjectReuse) init() {
	m.data.SetName("newrelicoracledb.concurrency.enqueue_ro_fast_object_reuse")
	m.data.SetDescription("Total waits for enqueue RO fast object reuse events")
	m.data.SetUnit("{waits}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbConcurrencyEnqueueRoFastObjectReuse) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbConcurrencyEnqueueRoFastObjectReuse) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbConcurrencyEnqueueRoFastObjectReuse) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbConcurrencyEnqueueRoFastObjectReuse(cfg MetricConfig) metricNewrelicoracledbConcurrencyEnqueueRoFastObjectReuse {
	m := metricNewrelicoracledbConcurrencyEnqueueRoFastObjectReuse{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbConcurrencyReadByOtherSession struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.concurrency.read_by_other_session metric with initial data.
func (m *metricNewrelicoracledbConcurrencyReadByOtherSession) init() {
	m.data.SetName("newrelicoracledb.concurrency.read_by_other_session")
	m.data.SetDescription("Total waits for read by other session events")
	m.data.SetUnit("{waits}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbConcurrencyReadByOtherSession) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbConcurrencyReadByOtherSession) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbConcurrencyReadByOtherSession) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbConcurrencyReadByOtherSession(cfg MetricConfig) metricNewrelicoracledbConcurrencyReadByOtherSession {
	m := metricNewrelicoracledbConcurrencyReadByOtherSession{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbIoControlFileParallelWrite struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.io.control_file_parallel_write metric with initial data.
func (m *metricNewrelicoracledbIoControlFileParallelWrite) init() {
	m.data.SetName("newrelicoracledb.io.control_file_parallel_write")
	m.data.SetDescription("Total waits for control file parallel write operations")
	m.data.SetUnit("{waits}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbIoControlFileParallelWrite) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbIoControlFileParallelWrite) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbIoControlFileParallelWrite) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbIoControlFileParallelWrite(cfg MetricConfig) metricNewrelicoracledbIoControlFileParallelWrite {
	m := metricNewrelicoracledbIoControlFileParallelWrite{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbIoControlFileSequentialRead struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.io.control_file_sequential_read metric with initial data.
func (m *metricNewrelicoracledbIoControlFileSequentialRead) init() {
	m.data.SetName("newrelicoracledb.io.control_file_sequential_read")
	m.data.SetDescription("Total waits for control file sequential read operations")
	m.data.SetUnit("{waits}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbIoControlFileSequentialRead) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbIoControlFileSequentialRead) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbIoControlFileSequentialRead) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbIoControlFileSequentialRead(cfg MetricConfig) metricNewrelicoracledbIoControlFileSequentialRead {
	m := metricNewrelicoracledbIoControlFileSequentialRead{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbIoDataFileInitWrite struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.io.data_file_init_write metric with initial data.
func (m *metricNewrelicoracledbIoDataFileInitWrite) init() {
	m.data.SetName("newrelicoracledb.io.data_file_init_write")
	m.data.SetDescription("Total waits for data file initialization write operations")
	m.data.SetUnit("{waits}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbIoDataFileInitWrite) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbIoDataFileInitWrite) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbIoDataFileInitWrite) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbIoDataFileInitWrite(cfg MetricConfig) metricNewrelicoracledbIoDataFileInitWrite {
	m := metricNewrelicoracledbIoDataFileInitWrite{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbIoDbFileScatteredRead struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.io.db_file_scattered_read metric with initial data.
func (m *metricNewrelicoracledbIoDbFileScatteredRead) init() {
	m.data.SetName("newrelicoracledb.io.db_file_scattered_read")
	m.data.SetDescription("Total waits for database file scattered read operations")
	m.data.SetUnit("{waits}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbIoDbFileScatteredRead) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbIoDbFileScatteredRead) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbIoDbFileScatteredRead) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbIoDbFileScatteredRead(cfg MetricConfig) metricNewrelicoracledbIoDbFileScatteredRead {
	m := metricNewrelicoracledbIoDbFileScatteredRead{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbIoDbFileSequentialRead struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.io.db_file_sequential_read metric with initial data.
func (m *metricNewrelicoracledbIoDbFileSequentialRead) init() {
	m.data.SetName("newrelicoracledb.io.db_file_sequential_read")
	m.data.SetDescription("Total waits for database file sequential read operations")
	m.data.SetUnit("{waits}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbIoDbFileSequentialRead) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbIoDbFileSequentialRead) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbIoDbFileSequentialRead) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbIoDbFileSequentialRead(cfg MetricConfig) metricNewrelicoracledbIoDbFileSequentialRead {
	m := metricNewrelicoracledbIoDbFileSequentialRead{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbIoDiskFileOperations struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.io.disk_file_operations metric with initial data.
func (m *metricNewrelicoracledbIoDiskFileOperations) init() {
	m.data.SetName("newrelicoracledb.io.disk_file_operations")
	m.data.SetDescription("Total waits for disk file operations I/O")
	m.data.SetUnit("{waits}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbIoDiskFileOperations) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbIoDiskFileOperations) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbIoDiskFileOperations) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbIoDiskFileOperations(cfg MetricConfig) metricNewrelicoracledbIoDiskFileOperations {
	m := metricNewrelicoracledbIoDiskFileOperations{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbIoLocalWriteWait struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.io.local_write_wait metric with initial data.
func (m *metricNewrelicoracledbIoLocalWriteWait) init() {
	m.data.SetName("newrelicoracledb.io.local_write_wait")
	m.data.SetDescription("Total waits for local write operations")
	m.data.SetUnit("{waits}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbIoLocalWriteWait) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbIoLocalWriteWait) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbIoLocalWriteWait) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbIoLocalWriteWait(cfg MetricConfig) metricNewrelicoracledbIoLocalWriteWait {
	m := metricNewrelicoracledbIoLocalWriteWait{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbLockedAccounts struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.locked_accounts metric with initial data.
func (m *metricNewrelicoracledbLockedAccounts) init() {
	m.data.SetName("newrelicoracledb.locked_accounts")
	m.data.SetDescription("Count of locked user accounts in the database")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbLockedAccounts) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbLockedAccounts) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbLockedAccounts) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbLockedAccounts(cfg MetricConfig) metricNewrelicoracledbLockedAccounts {
	m := metricNewrelicoracledbLockedAccounts{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbRedoLogLogFileSwitch struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.redo_log.log_file_switch metric with initial data.
func (m *metricNewrelicoracledbRedoLogLogFileSwitch) init() {
	m.data.SetName("newrelicoracledb.redo_log.log_file_switch")
	m.data.SetDescription("Total waits for log file switch completion events")
	m.data.SetUnit("{waits}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbRedoLogLogFileSwitch) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbRedoLogLogFileSwitch) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbRedoLogLogFileSwitch) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbRedoLogLogFileSwitch(cfg MetricConfig) metricNewrelicoracledbRedoLogLogFileSwitch {
	m := metricNewrelicoracledbRedoLogLogFileSwitch{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbRedoLogLogFileSwitchArchivingNeeded struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.redo_log.log_file_switch_archiving_needed metric with initial data.
func (m *metricNewrelicoracledbRedoLogLogFileSwitchArchivingNeeded) init() {
	m.data.SetName("newrelicoracledb.redo_log.log_file_switch_archiving_needed")
	m.data.SetDescription("Total waits for log file switch archiving needed events")
	m.data.SetUnit("{waits}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbRedoLogLogFileSwitchArchivingNeeded) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbRedoLogLogFileSwitchArchivingNeeded) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbRedoLogLogFileSwitchArchivingNeeded) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbRedoLogLogFileSwitchArchivingNeeded(cfg MetricConfig) metricNewrelicoracledbRedoLogLogFileSwitchArchivingNeeded {
	m := metricNewrelicoracledbRedoLogLogFileSwitchArchivingNeeded{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.redo_log.log_file_switch_checkpoint_incomplete metric with initial data.
func (m *metricNewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete) init() {
	m.data.SetName("newrelicoracledb.redo_log.log_file_switch_checkpoint_incomplete")
	m.data.SetDescription("Total waits for log file switch checkpoint incomplete events")
	m.data.SetUnit("{waits}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete(cfg MetricConfig) metricNewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete {
	m := metricNewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbRedoLogSync struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.redo_log.sync metric with initial data.
func (m *metricNewrelicoracledbRedoLogSync) init() {
	m.data.SetName("newrelicoracledb.redo_log.sync")
	m.data.SetDescription("Total waits for log file sync events")
	m.data.SetUnit("{waits}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbRedoLogSync) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbRedoLogSync) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbRedoLogSync) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbRedoLogSync(cfg MetricConfig) metricNewrelicoracledbRedoLogSync {
	m := metricNewrelicoracledbRedoLogSync{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbRedoLogWaits struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.redo_log.waits metric with initial data.
func (m *metricNewrelicoracledbRedoLogWaits) init() {
	m.data.SetName("newrelicoracledb.redo_log.waits")
	m.data.SetDescription("Total waits for log file parallel write events")
	m.data.SetUnit("{waits}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbRedoLogWaits) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbRedoLogWaits) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbRedoLogWaits) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbRedoLogWaits(cfg MetricConfig) metricNewrelicoracledbRedoLogWaits {
	m := metricNewrelicoracledbRedoLogWaits{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbSessionsCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.sessions.count metric with initial data.
func (m *metricNewrelicoracledbSessionsCount) init() {
	m.data.SetName("newrelicoracledb.sessions.count")
	m.data.SetDescription("Total number of active Oracle database sessions")
	m.data.SetUnit("{sessions}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbSessionsCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbSessionsCount) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbSessionsCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbSessionsCount(cfg MetricConfig) metricNewrelicoracledbSessionsCount {
	m := metricNewrelicoracledbSessionsCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbSgaBufferBusyWaits struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.sga.buffer_busy_waits metric with initial data.
func (m *metricNewrelicoracledbSgaBufferBusyWaits) init() {
	m.data.SetName("newrelicoracledb.sga.buffer_busy_waits")
	m.data.SetDescription("Total buffer busy waits")
	m.data.SetUnit("{waits}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbSgaBufferBusyWaits) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbSgaBufferBusyWaits) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbSgaBufferBusyWaits) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbSgaBufferBusyWaits(cfg MetricConfig) metricNewrelicoracledbSgaBufferBusyWaits {
	m := metricNewrelicoracledbSgaBufferBusyWaits{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbSgaFreeBufferInspected struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.sga.free_buffer_inspected metric with initial data.
func (m *metricNewrelicoracledbSgaFreeBufferInspected) init() {
	m.data.SetName("newrelicoracledb.sga.free_buffer_inspected")
	m.data.SetDescription("Total free buffer inspected events")
	m.data.SetUnit("{waits}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbSgaFreeBufferInspected) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbSgaFreeBufferInspected) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbSgaFreeBufferInspected) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbSgaFreeBufferInspected(cfg MetricConfig) metricNewrelicoracledbSgaFreeBufferInspected {
	m := metricNewrelicoracledbSgaFreeBufferInspected{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbSgaFreeBufferWaits struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.sga.free_buffer_waits metric with initial data.
func (m *metricNewrelicoracledbSgaFreeBufferWaits) init() {
	m.data.SetName("newrelicoracledb.sga.free_buffer_waits")
	m.data.SetDescription("Total free buffer waits")
	m.data.SetUnit("{waits}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbSgaFreeBufferWaits) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbSgaFreeBufferWaits) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbSgaFreeBufferWaits) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbSgaFreeBufferWaits(cfg MetricConfig) metricNewrelicoracledbSgaFreeBufferWaits {
	m := metricNewrelicoracledbSgaFreeBufferWaits{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbSynchronizationDirectPathSync struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.synchronization.direct_path_sync metric with initial data.
func (m *metricNewrelicoracledbSynchronizationDirectPathSync) init() {
	m.data.SetName("newrelicoracledb.synchronization.direct_path_sync")
	m.data.SetDescription("Total waits for direct path sync operations")
	m.data.SetUnit("{waits}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbSynchronizationDirectPathSync) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("instance.id", instanceIDAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbSynchronizationDirectPathSync) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbSynchronizationDirectPathSync) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbSynchronizationDirectPathSync(cfg MetricConfig) metricNewrelicoracledbSynchronizationDirectPathSync {
	m := metricNewrelicoracledbSynchronizationDirectPathSync{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbTablespaceDbID struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.tablespace.db_id metric with initial data.
func (m *metricNewrelicoracledbTablespaceDbID) init() {
	m.data.SetName("newrelicoracledb.tablespace.db_id")
	m.data.SetDescription("Database ID information for tablespace")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbTablespaceDbID) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("tablespace.name", tablespaceNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbTablespaceDbID) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbTablespaceDbID) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbTablespaceDbID(cfg MetricConfig) metricNewrelicoracledbTablespaceDbID {
	m := metricNewrelicoracledbTablespaceDbID{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbTablespaceGlobalName struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.tablespace.global_name metric with initial data.
func (m *metricNewrelicoracledbTablespaceGlobalName) init() {
	m.data.SetName("newrelicoracledb.tablespace.global_name")
	m.data.SetDescription("Global name information for tablespace")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbTablespaceGlobalName) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("tablespace.name", tablespaceNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbTablespaceGlobalName) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbTablespaceGlobalName) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbTablespaceGlobalName(cfg MetricConfig) metricNewrelicoracledbTablespaceGlobalName {
	m := metricNewrelicoracledbTablespaceGlobalName{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbTablespaceIsOffline struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.tablespace.is_offline metric with initial data.
func (m *metricNewrelicoracledbTablespaceIsOffline) init() {
	m.data.SetName("newrelicoracledb.tablespace.is_offline")
	m.data.SetDescription("Whether the tablespace is offline (1) or online (0)")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbTablespaceIsOffline) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("tablespace.name", tablespaceNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbTablespaceIsOffline) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbTablespaceIsOffline) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbTablespaceIsOffline(cfg MetricConfig) metricNewrelicoracledbTablespaceIsOffline {
	m := metricNewrelicoracledbTablespaceIsOffline{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbTablespaceOfflineCdbDatafiles struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.tablespace.offline_cdb_datafiles metric with initial data.
func (m *metricNewrelicoracledbTablespaceOfflineCdbDatafiles) init() {
	m.data.SetName("newrelicoracledb.tablespace.offline_cdb_datafiles")
	m.data.SetDescription("Count of offline CDB datafiles by tablespace")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbTablespaceOfflineCdbDatafiles) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("tablespace.name", tablespaceNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbTablespaceOfflineCdbDatafiles) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbTablespaceOfflineCdbDatafiles) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbTablespaceOfflineCdbDatafiles(cfg MetricConfig) metricNewrelicoracledbTablespaceOfflineCdbDatafiles {
	m := metricNewrelicoracledbTablespaceOfflineCdbDatafiles{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbTablespaceOfflinePdbDatafiles struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.tablespace.offline_pdb_datafiles metric with initial data.
func (m *metricNewrelicoracledbTablespaceOfflinePdbDatafiles) init() {
	m.data.SetName("newrelicoracledb.tablespace.offline_pdb_datafiles")
	m.data.SetDescription("Count of offline PDB datafiles by tablespace")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbTablespaceOfflinePdbDatafiles) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("tablespace.name", tablespaceNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbTablespaceOfflinePdbDatafiles) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbTablespaceOfflinePdbDatafiles) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbTablespaceOfflinePdbDatafiles(cfg MetricConfig) metricNewrelicoracledbTablespaceOfflinePdbDatafiles {
	m := metricNewrelicoracledbTablespaceOfflinePdbDatafiles{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbTablespacePdbNonWriteMode struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.tablespace.pdb_non_write_mode metric with initial data.
func (m *metricNewrelicoracledbTablespacePdbNonWriteMode) init() {
	m.data.SetName("newrelicoracledb.tablespace.pdb_non_write_mode")
	m.data.SetDescription("Count of PDB datafiles in non-write mode by tablespace")
	m.data.SetUnit("1")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbTablespacePdbNonWriteMode) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("tablespace.name", tablespaceNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbTablespacePdbNonWriteMode) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbTablespacePdbNonWriteMode) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbTablespacePdbNonWriteMode(cfg MetricConfig) metricNewrelicoracledbTablespacePdbNonWriteMode {
	m := metricNewrelicoracledbTablespacePdbNonWriteMode{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbTablespaceSpaceConsumedBytes struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.tablespace.space_consumed_bytes metric with initial data.
func (m *metricNewrelicoracledbTablespaceSpaceConsumedBytes) init() {
	m.data.SetName("newrelicoracledb.tablespace.space_consumed_bytes")
	m.data.SetDescription("Total bytes consumed by the tablespace")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbTablespaceSpaceConsumedBytes) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("tablespace.name", tablespaceNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbTablespaceSpaceConsumedBytes) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbTablespaceSpaceConsumedBytes) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbTablespaceSpaceConsumedBytes(cfg MetricConfig) metricNewrelicoracledbTablespaceSpaceConsumedBytes {
	m := metricNewrelicoracledbTablespaceSpaceConsumedBytes{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbTablespaceSpaceReservedBytes struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.tablespace.space_reserved_bytes metric with initial data.
func (m *metricNewrelicoracledbTablespaceSpaceReservedBytes) init() {
	m.data.SetName("newrelicoracledb.tablespace.space_reserved_bytes")
	m.data.SetDescription("Total bytes reserved by the tablespace")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbTablespaceSpaceReservedBytes) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("tablespace.name", tablespaceNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbTablespaceSpaceReservedBytes) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbTablespaceSpaceReservedBytes) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbTablespaceSpaceReservedBytes(cfg MetricConfig) metricNewrelicoracledbTablespaceSpaceReservedBytes {
	m := metricNewrelicoracledbTablespaceSpaceReservedBytes{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricNewrelicoracledbTablespaceSpaceUsedPercentage struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills newrelicoracledb.tablespace.space_used_percentage metric with initial data.
func (m *metricNewrelicoracledbTablespaceSpaceUsedPercentage) init() {
	m.data.SetName("newrelicoracledb.tablespace.space_used_percentage")
	m.data.SetDescription("Percentage of tablespace space currently used")
	m.data.SetUnit("%")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricNewrelicoracledbTablespaceSpaceUsedPercentage) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("newrelic.entity_name", newrelicEntityNameAttributeValue)
	dp.Attributes().PutStr("tablespace.name", tablespaceNameAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricNewrelicoracledbTablespaceSpaceUsedPercentage) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricNewrelicoracledbTablespaceSpaceUsedPercentage) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricNewrelicoracledbTablespaceSpaceUsedPercentage(cfg MetricConfig) metricNewrelicoracledbTablespaceSpaceUsedPercentage {
	m := metricNewrelicoracledbTablespaceSpaceUsedPercentage{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

// MetricsBuilder provides an interface for scrapers to report metrics while taking care of all the transformations
// required to produce metric representation defined in metadata and user config.
type MetricsBuilder struct {
	config                                                         MetricsBuilderConfig // config of the metrics builder.
	startTime                                                      pcommon.Timestamp    // start time that will be applied to all recorded data points.
	metricsCapacity                                                int                  // maximum observed number of metrics per resource.
	metricsBuffer                                                  pmetric.Metrics      // accumulates metrics data before emitting.
	buildInfo                                                      component.BuildInfo  // contains version information.
	resourceAttributeIncludeFilter                                 map[string]filter.Filter
	resourceAttributeExcludeFilter                                 map[string]filter.Filter
	metricNewrelicoracledbConcurrencyEnqueueRoFastObjectReuse      metricNewrelicoracledbConcurrencyEnqueueRoFastObjectReuse
	metricNewrelicoracledbConcurrencyReadByOtherSession            metricNewrelicoracledbConcurrencyReadByOtherSession
	metricNewrelicoracledbIoControlFileParallelWrite               metricNewrelicoracledbIoControlFileParallelWrite
	metricNewrelicoracledbIoControlFileSequentialRead              metricNewrelicoracledbIoControlFileSequentialRead
	metricNewrelicoracledbIoDataFileInitWrite                      metricNewrelicoracledbIoDataFileInitWrite
	metricNewrelicoracledbIoDbFileScatteredRead                    metricNewrelicoracledbIoDbFileScatteredRead
	metricNewrelicoracledbIoDbFileSequentialRead                   metricNewrelicoracledbIoDbFileSequentialRead
	metricNewrelicoracledbIoDiskFileOperations                     metricNewrelicoracledbIoDiskFileOperations
	metricNewrelicoracledbIoLocalWriteWait                         metricNewrelicoracledbIoLocalWriteWait
	metricNewrelicoracledbLockedAccounts                           metricNewrelicoracledbLockedAccounts
	metricNewrelicoracledbRedoLogLogFileSwitch                     metricNewrelicoracledbRedoLogLogFileSwitch
	metricNewrelicoracledbRedoLogLogFileSwitchArchivingNeeded      metricNewrelicoracledbRedoLogLogFileSwitchArchivingNeeded
	metricNewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete metricNewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete
	metricNewrelicoracledbRedoLogSync                              metricNewrelicoracledbRedoLogSync
	metricNewrelicoracledbRedoLogWaits                             metricNewrelicoracledbRedoLogWaits
	metricNewrelicoracledbSessionsCount                            metricNewrelicoracledbSessionsCount
	metricNewrelicoracledbSgaBufferBusyWaits                       metricNewrelicoracledbSgaBufferBusyWaits
	metricNewrelicoracledbSgaFreeBufferInspected                   metricNewrelicoracledbSgaFreeBufferInspected
	metricNewrelicoracledbSgaFreeBufferWaits                       metricNewrelicoracledbSgaFreeBufferWaits
	metricNewrelicoracledbSynchronizationDirectPathSync            metricNewrelicoracledbSynchronizationDirectPathSync
	metricNewrelicoracledbTablespaceDbID                           metricNewrelicoracledbTablespaceDbID
	metricNewrelicoracledbTablespaceGlobalName                     metricNewrelicoracledbTablespaceGlobalName
	metricNewrelicoracledbTablespaceIsOffline                      metricNewrelicoracledbTablespaceIsOffline
	metricNewrelicoracledbTablespaceOfflineCdbDatafiles            metricNewrelicoracledbTablespaceOfflineCdbDatafiles
	metricNewrelicoracledbTablespaceOfflinePdbDatafiles            metricNewrelicoracledbTablespaceOfflinePdbDatafiles
	metricNewrelicoracledbTablespacePdbNonWriteMode                metricNewrelicoracledbTablespacePdbNonWriteMode
	metricNewrelicoracledbTablespaceSpaceConsumedBytes             metricNewrelicoracledbTablespaceSpaceConsumedBytes
	metricNewrelicoracledbTablespaceSpaceReservedBytes             metricNewrelicoracledbTablespaceSpaceReservedBytes
	metricNewrelicoracledbTablespaceSpaceUsedPercentage            metricNewrelicoracledbTablespaceSpaceUsedPercentage
}

// MetricBuilderOption applies changes to default metrics builder.
type MetricBuilderOption interface {
	apply(*MetricsBuilder)
}

type metricBuilderOptionFunc func(mb *MetricsBuilder)

func (mbof metricBuilderOptionFunc) apply(mb *MetricsBuilder) {
	mbof(mb)
}

// WithStartTime sets startTime on the metrics builder.
func WithStartTime(startTime pcommon.Timestamp) MetricBuilderOption {
	return metricBuilderOptionFunc(func(mb *MetricsBuilder) {
		mb.startTime = startTime
	})
}
func NewMetricsBuilder(mbc MetricsBuilderConfig, settings receiver.Settings, options ...MetricBuilderOption) *MetricsBuilder {
	mb := &MetricsBuilder{
		config:        mbc,
		startTime:     pcommon.NewTimestampFromTime(time.Now()),
		metricsBuffer: pmetric.NewMetrics(),
		buildInfo:     settings.BuildInfo,
		metricNewrelicoracledbConcurrencyEnqueueRoFastObjectReuse:      newMetricNewrelicoracledbConcurrencyEnqueueRoFastObjectReuse(mbc.Metrics.NewrelicoracledbConcurrencyEnqueueRoFastObjectReuse),
		metricNewrelicoracledbConcurrencyReadByOtherSession:            newMetricNewrelicoracledbConcurrencyReadByOtherSession(mbc.Metrics.NewrelicoracledbConcurrencyReadByOtherSession),
		metricNewrelicoracledbIoControlFileParallelWrite:               newMetricNewrelicoracledbIoControlFileParallelWrite(mbc.Metrics.NewrelicoracledbIoControlFileParallelWrite),
		metricNewrelicoracledbIoControlFileSequentialRead:              newMetricNewrelicoracledbIoControlFileSequentialRead(mbc.Metrics.NewrelicoracledbIoControlFileSequentialRead),
		metricNewrelicoracledbIoDataFileInitWrite:                      newMetricNewrelicoracledbIoDataFileInitWrite(mbc.Metrics.NewrelicoracledbIoDataFileInitWrite),
		metricNewrelicoracledbIoDbFileScatteredRead:                    newMetricNewrelicoracledbIoDbFileScatteredRead(mbc.Metrics.NewrelicoracledbIoDbFileScatteredRead),
		metricNewrelicoracledbIoDbFileSequentialRead:                   newMetricNewrelicoracledbIoDbFileSequentialRead(mbc.Metrics.NewrelicoracledbIoDbFileSequentialRead),
		metricNewrelicoracledbIoDiskFileOperations:                     newMetricNewrelicoracledbIoDiskFileOperations(mbc.Metrics.NewrelicoracledbIoDiskFileOperations),
		metricNewrelicoracledbIoLocalWriteWait:                         newMetricNewrelicoracledbIoLocalWriteWait(mbc.Metrics.NewrelicoracledbIoLocalWriteWait),
		metricNewrelicoracledbLockedAccounts:                           newMetricNewrelicoracledbLockedAccounts(mbc.Metrics.NewrelicoracledbLockedAccounts),
		metricNewrelicoracledbRedoLogLogFileSwitch:                     newMetricNewrelicoracledbRedoLogLogFileSwitch(mbc.Metrics.NewrelicoracledbRedoLogLogFileSwitch),
		metricNewrelicoracledbRedoLogLogFileSwitchArchivingNeeded:      newMetricNewrelicoracledbRedoLogLogFileSwitchArchivingNeeded(mbc.Metrics.NewrelicoracledbRedoLogLogFileSwitchArchivingNeeded),
		metricNewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete: newMetricNewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete(mbc.Metrics.NewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete),
		metricNewrelicoracledbRedoLogSync:                              newMetricNewrelicoracledbRedoLogSync(mbc.Metrics.NewrelicoracledbRedoLogSync),
		metricNewrelicoracledbRedoLogWaits:                             newMetricNewrelicoracledbRedoLogWaits(mbc.Metrics.NewrelicoracledbRedoLogWaits),
		metricNewrelicoracledbSessionsCount:                            newMetricNewrelicoracledbSessionsCount(mbc.Metrics.NewrelicoracledbSessionsCount),
		metricNewrelicoracledbSgaBufferBusyWaits:                       newMetricNewrelicoracledbSgaBufferBusyWaits(mbc.Metrics.NewrelicoracledbSgaBufferBusyWaits),
		metricNewrelicoracledbSgaFreeBufferInspected:                   newMetricNewrelicoracledbSgaFreeBufferInspected(mbc.Metrics.NewrelicoracledbSgaFreeBufferInspected),
		metricNewrelicoracledbSgaFreeBufferWaits:                       newMetricNewrelicoracledbSgaFreeBufferWaits(mbc.Metrics.NewrelicoracledbSgaFreeBufferWaits),
		metricNewrelicoracledbSynchronizationDirectPathSync:            newMetricNewrelicoracledbSynchronizationDirectPathSync(mbc.Metrics.NewrelicoracledbSynchronizationDirectPathSync),
		metricNewrelicoracledbTablespaceDbID:                           newMetricNewrelicoracledbTablespaceDbID(mbc.Metrics.NewrelicoracledbTablespaceDbID),
		metricNewrelicoracledbTablespaceGlobalName:                     newMetricNewrelicoracledbTablespaceGlobalName(mbc.Metrics.NewrelicoracledbTablespaceGlobalName),
		metricNewrelicoracledbTablespaceIsOffline:                      newMetricNewrelicoracledbTablespaceIsOffline(mbc.Metrics.NewrelicoracledbTablespaceIsOffline),
		metricNewrelicoracledbTablespaceOfflineCdbDatafiles:            newMetricNewrelicoracledbTablespaceOfflineCdbDatafiles(mbc.Metrics.NewrelicoracledbTablespaceOfflineCdbDatafiles),
		metricNewrelicoracledbTablespaceOfflinePdbDatafiles:            newMetricNewrelicoracledbTablespaceOfflinePdbDatafiles(mbc.Metrics.NewrelicoracledbTablespaceOfflinePdbDatafiles),
		metricNewrelicoracledbTablespacePdbNonWriteMode:                newMetricNewrelicoracledbTablespacePdbNonWriteMode(mbc.Metrics.NewrelicoracledbTablespacePdbNonWriteMode),
		metricNewrelicoracledbTablespaceSpaceConsumedBytes:             newMetricNewrelicoracledbTablespaceSpaceConsumedBytes(mbc.Metrics.NewrelicoracledbTablespaceSpaceConsumedBytes),
		metricNewrelicoracledbTablespaceSpaceReservedBytes:             newMetricNewrelicoracledbTablespaceSpaceReservedBytes(mbc.Metrics.NewrelicoracledbTablespaceSpaceReservedBytes),
		metricNewrelicoracledbTablespaceSpaceUsedPercentage:            newMetricNewrelicoracledbTablespaceSpaceUsedPercentage(mbc.Metrics.NewrelicoracledbTablespaceSpaceUsedPercentage),
		resourceAttributeIncludeFilter:                                 make(map[string]filter.Filter),
		resourceAttributeExcludeFilter:                                 make(map[string]filter.Filter),
	}
	if mbc.ResourceAttributes.HostName.MetricsInclude != nil {
		mb.resourceAttributeIncludeFilter["host.name"] = filter.CreateFilter(mbc.ResourceAttributes.HostName.MetricsInclude)
	}
	if mbc.ResourceAttributes.HostName.MetricsExclude != nil {
		mb.resourceAttributeExcludeFilter["host.name"] = filter.CreateFilter(mbc.ResourceAttributes.HostName.MetricsExclude)
	}
	if mbc.ResourceAttributes.NewrelicoracledbInstanceName.MetricsInclude != nil {
		mb.resourceAttributeIncludeFilter["newrelicoracledb.instance.name"] = filter.CreateFilter(mbc.ResourceAttributes.NewrelicoracledbInstanceName.MetricsInclude)
	}
	if mbc.ResourceAttributes.NewrelicoracledbInstanceName.MetricsExclude != nil {
		mb.resourceAttributeExcludeFilter["newrelicoracledb.instance.name"] = filter.CreateFilter(mbc.ResourceAttributes.NewrelicoracledbInstanceName.MetricsExclude)
	}

	for _, op := range options {
		op.apply(mb)
	}
	return mb
}

// NewResourceBuilder returns a new resource builder that should be used to build a resource associated with for the emitted metrics.
func (mb *MetricsBuilder) NewResourceBuilder() *ResourceBuilder {
	return NewResourceBuilder(mb.config.ResourceAttributes)
}

// updateCapacity updates max length of metrics and resource attributes that will be used for the slice capacity.
func (mb *MetricsBuilder) updateCapacity(rm pmetric.ResourceMetrics) {
	if mb.metricsCapacity < rm.ScopeMetrics().At(0).Metrics().Len() {
		mb.metricsCapacity = rm.ScopeMetrics().At(0).Metrics().Len()
	}
}

// ResourceMetricsOption applies changes to provided resource metrics.
type ResourceMetricsOption interface {
	apply(pmetric.ResourceMetrics)
}

type resourceMetricsOptionFunc func(pmetric.ResourceMetrics)

func (rmof resourceMetricsOptionFunc) apply(rm pmetric.ResourceMetrics) {
	rmof(rm)
}

// WithResource sets the provided resource on the emitted ResourceMetrics.
// It's recommended to use ResourceBuilder to create the resource.
func WithResource(res pcommon.Resource) ResourceMetricsOption {
	return resourceMetricsOptionFunc(func(rm pmetric.ResourceMetrics) {
		res.CopyTo(rm.Resource())
	})
}

// WithStartTimeOverride overrides start time for all the resource metrics data points.
// This option should be only used if different start time has to be set on metrics coming from different resources.
func WithStartTimeOverride(start pcommon.Timestamp) ResourceMetricsOption {
	return resourceMetricsOptionFunc(func(rm pmetric.ResourceMetrics) {
		var dps pmetric.NumberDataPointSlice
		metrics := rm.ScopeMetrics().At(0).Metrics()
		for i := 0; i < metrics.Len(); i++ {
			switch metrics.At(i).Type() {
			case pmetric.MetricTypeGauge:
				dps = metrics.At(i).Gauge().DataPoints()
			case pmetric.MetricTypeSum:
				dps = metrics.At(i).Sum().DataPoints()
			}
			for j := 0; j < dps.Len(); j++ {
				dps.At(j).SetStartTimestamp(start)
			}
		}
	})
}

// EmitForResource saves all the generated metrics under a new resource and updates the internal state to be ready for
// recording another set of data points as part of another resource. This function can be helpful when one scraper
// needs to emit metrics from several resources. Otherwise calling this function is not required,
// just `Emit` function can be called instead.
// Resource attributes should be provided as ResourceMetricsOption arguments.
func (mb *MetricsBuilder) EmitForResource(options ...ResourceMetricsOption) {
	rm := pmetric.NewResourceMetrics()
	ils := rm.ScopeMetrics().AppendEmpty()
	ils.Scope().SetName(ScopeName)
	ils.Scope().SetVersion(mb.buildInfo.Version)
	ils.Metrics().EnsureCapacity(mb.metricsCapacity)
	mb.metricNewrelicoracledbConcurrencyEnqueueRoFastObjectReuse.emit(ils.Metrics())
	mb.metricNewrelicoracledbConcurrencyReadByOtherSession.emit(ils.Metrics())
	mb.metricNewrelicoracledbIoControlFileParallelWrite.emit(ils.Metrics())
	mb.metricNewrelicoracledbIoControlFileSequentialRead.emit(ils.Metrics())
	mb.metricNewrelicoracledbIoDataFileInitWrite.emit(ils.Metrics())
	mb.metricNewrelicoracledbIoDbFileScatteredRead.emit(ils.Metrics())
	mb.metricNewrelicoracledbIoDbFileSequentialRead.emit(ils.Metrics())
	mb.metricNewrelicoracledbIoDiskFileOperations.emit(ils.Metrics())
	mb.metricNewrelicoracledbIoLocalWriteWait.emit(ils.Metrics())
	mb.metricNewrelicoracledbLockedAccounts.emit(ils.Metrics())
	mb.metricNewrelicoracledbRedoLogLogFileSwitch.emit(ils.Metrics())
	mb.metricNewrelicoracledbRedoLogLogFileSwitchArchivingNeeded.emit(ils.Metrics())
	mb.metricNewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete.emit(ils.Metrics())
	mb.metricNewrelicoracledbRedoLogSync.emit(ils.Metrics())
	mb.metricNewrelicoracledbRedoLogWaits.emit(ils.Metrics())
	mb.metricNewrelicoracledbSessionsCount.emit(ils.Metrics())
	mb.metricNewrelicoracledbSgaBufferBusyWaits.emit(ils.Metrics())
	mb.metricNewrelicoracledbSgaFreeBufferInspected.emit(ils.Metrics())
	mb.metricNewrelicoracledbSgaFreeBufferWaits.emit(ils.Metrics())
	mb.metricNewrelicoracledbSynchronizationDirectPathSync.emit(ils.Metrics())
	mb.metricNewrelicoracledbTablespaceDbID.emit(ils.Metrics())
	mb.metricNewrelicoracledbTablespaceGlobalName.emit(ils.Metrics())
	mb.metricNewrelicoracledbTablespaceIsOffline.emit(ils.Metrics())
	mb.metricNewrelicoracledbTablespaceOfflineCdbDatafiles.emit(ils.Metrics())
	mb.metricNewrelicoracledbTablespaceOfflinePdbDatafiles.emit(ils.Metrics())
	mb.metricNewrelicoracledbTablespacePdbNonWriteMode.emit(ils.Metrics())
	mb.metricNewrelicoracledbTablespaceSpaceConsumedBytes.emit(ils.Metrics())
	mb.metricNewrelicoracledbTablespaceSpaceReservedBytes.emit(ils.Metrics())
	mb.metricNewrelicoracledbTablespaceSpaceUsedPercentage.emit(ils.Metrics())

	for _, op := range options {
		op.apply(rm)
	}
	for attr, filter := range mb.resourceAttributeIncludeFilter {
		if val, ok := rm.Resource().Attributes().Get(attr); ok && !filter.Matches(val.AsString()) {
			return
		}
	}
	for attr, filter := range mb.resourceAttributeExcludeFilter {
		if val, ok := rm.Resource().Attributes().Get(attr); ok && filter.Matches(val.AsString()) {
			return
		}
	}

	if ils.Metrics().Len() > 0 {
		mb.updateCapacity(rm)
		rm.MoveTo(mb.metricsBuffer.ResourceMetrics().AppendEmpty())
	}
}

// Emit returns all the metrics accumulated by the metrics builder and updates the internal state to be ready for
// recording another set of metrics. This function will be responsible for applying all the transformations required to
// produce metric representation defined in metadata and user config, e.g. delta or cumulative.
func (mb *MetricsBuilder) Emit(options ...ResourceMetricsOption) pmetric.Metrics {
	mb.EmitForResource(options...)
	metrics := mb.metricsBuffer
	mb.metricsBuffer = pmetric.NewMetrics()
	return metrics
}

// RecordNewrelicoracledbConcurrencyEnqueueRoFastObjectReuseDataPoint adds a data point to newrelicoracledb.concurrency.enqueue_ro_fast_object_reuse metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbConcurrencyEnqueueRoFastObjectReuseDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbConcurrencyEnqueueRoFastObjectReuse.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbConcurrencyReadByOtherSessionDataPoint adds a data point to newrelicoracledb.concurrency.read_by_other_session metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbConcurrencyReadByOtherSessionDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbConcurrencyReadByOtherSession.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbIoControlFileParallelWriteDataPoint adds a data point to newrelicoracledb.io.control_file_parallel_write metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbIoControlFileParallelWriteDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbIoControlFileParallelWrite.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbIoControlFileSequentialReadDataPoint adds a data point to newrelicoracledb.io.control_file_sequential_read metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbIoControlFileSequentialReadDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbIoControlFileSequentialRead.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbIoDataFileInitWriteDataPoint adds a data point to newrelicoracledb.io.data_file_init_write metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbIoDataFileInitWriteDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbIoDataFileInitWrite.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbIoDbFileScatteredReadDataPoint adds a data point to newrelicoracledb.io.db_file_scattered_read metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbIoDbFileScatteredReadDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbIoDbFileScatteredRead.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbIoDbFileSequentialReadDataPoint adds a data point to newrelicoracledb.io.db_file_sequential_read metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbIoDbFileSequentialReadDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbIoDbFileSequentialRead.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbIoDiskFileOperationsDataPoint adds a data point to newrelicoracledb.io.disk_file_operations metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbIoDiskFileOperationsDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbIoDiskFileOperations.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbIoLocalWriteWaitDataPoint adds a data point to newrelicoracledb.io.local_write_wait metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbIoLocalWriteWaitDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbIoLocalWriteWait.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbLockedAccountsDataPoint adds a data point to newrelicoracledb.locked_accounts metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbLockedAccountsDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbLockedAccounts.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbRedoLogLogFileSwitchDataPoint adds a data point to newrelicoracledb.redo_log.log_file_switch metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbRedoLogLogFileSwitchDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbRedoLogLogFileSwitch.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbRedoLogLogFileSwitchArchivingNeededDataPoint adds a data point to newrelicoracledb.redo_log.log_file_switch_archiving_needed metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbRedoLogLogFileSwitchArchivingNeededDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbRedoLogLogFileSwitchArchivingNeeded.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbRedoLogLogFileSwitchCheckpointIncompleteDataPoint adds a data point to newrelicoracledb.redo_log.log_file_switch_checkpoint_incomplete metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbRedoLogLogFileSwitchCheckpointIncompleteDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbRedoLogLogFileSwitchCheckpointIncomplete.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbRedoLogSyncDataPoint adds a data point to newrelicoracledb.redo_log.sync metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbRedoLogSyncDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbRedoLogSync.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbRedoLogWaitsDataPoint adds a data point to newrelicoracledb.redo_log.waits metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbRedoLogWaitsDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbRedoLogWaits.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbSessionsCountDataPoint adds a data point to newrelicoracledb.sessions.count metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbSessionsCountDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string) {
	mb.metricNewrelicoracledbSessionsCount.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue)
}

// RecordNewrelicoracledbSgaBufferBusyWaitsDataPoint adds a data point to newrelicoracledb.sga.buffer_busy_waits metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbSgaBufferBusyWaitsDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbSgaBufferBusyWaits.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbSgaFreeBufferInspectedDataPoint adds a data point to newrelicoracledb.sga.free_buffer_inspected metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbSgaFreeBufferInspectedDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbSgaFreeBufferInspected.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbSgaFreeBufferWaitsDataPoint adds a data point to newrelicoracledb.sga.free_buffer_waits metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbSgaFreeBufferWaitsDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbSgaFreeBufferWaits.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbSynchronizationDirectPathSyncDataPoint adds a data point to newrelicoracledb.synchronization.direct_path_sync metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbSynchronizationDirectPathSyncDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, instanceIDAttributeValue string) {
	mb.metricNewrelicoracledbSynchronizationDirectPathSync.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, instanceIDAttributeValue)
}

// RecordNewrelicoracledbTablespaceDbIDDataPoint adds a data point to newrelicoracledb.tablespace.db_id metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbTablespaceDbIDDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	mb.metricNewrelicoracledbTablespaceDbID.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, tablespaceNameAttributeValue)
}

// RecordNewrelicoracledbTablespaceGlobalNameDataPoint adds a data point to newrelicoracledb.tablespace.global_name metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbTablespaceGlobalNameDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	mb.metricNewrelicoracledbTablespaceGlobalName.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, tablespaceNameAttributeValue)
}

// RecordNewrelicoracledbTablespaceIsOfflineDataPoint adds a data point to newrelicoracledb.tablespace.is_offline metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbTablespaceIsOfflineDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	mb.metricNewrelicoracledbTablespaceIsOffline.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, tablespaceNameAttributeValue)
}

// RecordNewrelicoracledbTablespaceOfflineCdbDatafilesDataPoint adds a data point to newrelicoracledb.tablespace.offline_cdb_datafiles metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbTablespaceOfflineCdbDatafilesDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	mb.metricNewrelicoracledbTablespaceOfflineCdbDatafiles.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, tablespaceNameAttributeValue)
}

// RecordNewrelicoracledbTablespaceOfflinePdbDatafilesDataPoint adds a data point to newrelicoracledb.tablespace.offline_pdb_datafiles metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbTablespaceOfflinePdbDatafilesDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	mb.metricNewrelicoracledbTablespaceOfflinePdbDatafiles.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, tablespaceNameAttributeValue)
}

// RecordNewrelicoracledbTablespacePdbNonWriteModeDataPoint adds a data point to newrelicoracledb.tablespace.pdb_non_write_mode metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbTablespacePdbNonWriteModeDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	mb.metricNewrelicoracledbTablespacePdbNonWriteMode.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, tablespaceNameAttributeValue)
}

// RecordNewrelicoracledbTablespaceSpaceConsumedBytesDataPoint adds a data point to newrelicoracledb.tablespace.space_consumed_bytes metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbTablespaceSpaceConsumedBytesDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	mb.metricNewrelicoracledbTablespaceSpaceConsumedBytes.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, tablespaceNameAttributeValue)
}

// RecordNewrelicoracledbTablespaceSpaceReservedBytesDataPoint adds a data point to newrelicoracledb.tablespace.space_reserved_bytes metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbTablespaceSpaceReservedBytesDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	mb.metricNewrelicoracledbTablespaceSpaceReservedBytes.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, tablespaceNameAttributeValue)
}

// RecordNewrelicoracledbTablespaceSpaceUsedPercentageDataPoint adds a data point to newrelicoracledb.tablespace.space_used_percentage metric.
func (mb *MetricsBuilder) RecordNewrelicoracledbTablespaceSpaceUsedPercentageDataPoint(ts pcommon.Timestamp, val int64, newrelicEntityNameAttributeValue string, tablespaceNameAttributeValue string) {
	mb.metricNewrelicoracledbTablespaceSpaceUsedPercentage.recordDataPoint(mb.startTime, ts, val, newrelicEntityNameAttributeValue, tablespaceNameAttributeValue)
}

// Reset resets metrics builder to its initial state. It should be used when external metrics source is restarted,
// and metrics builder should update its startTime and reset it's internal state accordingly.
func (mb *MetricsBuilder) Reset(options ...MetricBuilderOption) {
	mb.startTime = pcommon.NewTimestampFromTime(time.Now())
	for _, op := range options {
		op.apply(mb)
	}
}
