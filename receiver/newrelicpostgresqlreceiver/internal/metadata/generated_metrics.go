// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"time"

	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/filter"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
	"go.opentelemetry.io/collector/receiver"
)

var MetricsInfo = metricsInfo{
	PostgresqlConnectionCount: metricInfo{
		Name: "postgresql.connection.count",
	},
	PostgresqlReplicationBackendXminAge: metricInfo{
		Name: "postgresql.replication.backend_xmin_age",
	},
	PostgresqlReplicationFlushLsnDelay: metricInfo{
		Name: "postgresql.replication.flush_lsn_delay",
	},
	PostgresqlReplicationReplayLsnDelay: metricInfo{
		Name: "postgresql.replication.replay_lsn_delay",
	},
	PostgresqlReplicationSentLsnDelay: metricInfo{
		Name: "postgresql.replication.sent_lsn_delay",
	},
	PostgresqlReplicationWalFlushLag: metricInfo{
		Name: "postgresql.replication.wal_flush_lag",
	},
	PostgresqlReplicationWalReplayLag: metricInfo{
		Name: "postgresql.replication.wal_replay_lag",
	},
	PostgresqlReplicationWalWriteLag: metricInfo{
		Name: "postgresql.replication.wal_write_lag",
	},
	PostgresqlReplicationWriteLsnDelay: metricInfo{
		Name: "postgresql.replication.write_lsn_delay",
	},
}

type metricsInfo struct {
	PostgresqlConnectionCount           metricInfo
	PostgresqlReplicationBackendXminAge metricInfo
	PostgresqlReplicationFlushLsnDelay  metricInfo
	PostgresqlReplicationReplayLsnDelay metricInfo
	PostgresqlReplicationSentLsnDelay   metricInfo
	PostgresqlReplicationWalFlushLag    metricInfo
	PostgresqlReplicationWalReplayLag   metricInfo
	PostgresqlReplicationWalWriteLag    metricInfo
	PostgresqlReplicationWriteLsnDelay  metricInfo
}

type metricInfo struct {
	Name string
}

type metricPostgresqlConnectionCount struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills postgresql.connection.count metric with initial data.
func (m *metricPostgresqlConnectionCount) init() {
	m.data.SetName("postgresql.connection.count")
	m.data.SetDescription("Number of active connections to the PostgreSQL database")
	m.data.SetUnit("{connections}")
	m.data.SetEmptySum()
	m.data.Sum().SetIsMonotonic(false)
	m.data.Sum().SetAggregationTemporality(pmetric.AggregationTemporalityCumulative)
}

func (m *metricPostgresqlConnectionCount) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Sum().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricPostgresqlConnectionCount) updateCapacity() {
	if m.data.Sum().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Sum().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricPostgresqlConnectionCount) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Sum().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricPostgresqlConnectionCount(cfg MetricConfig) metricPostgresqlConnectionCount {
	m := metricPostgresqlConnectionCount{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricPostgresqlReplicationBackendXminAge struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills postgresql.replication.backend_xmin_age metric with initial data.
func (m *metricPostgresqlReplicationBackendXminAge) init() {
	m.data.SetName("postgresql.replication.backend_xmin_age")
	m.data.SetDescription("Age of the oldest transaction on the standby server that is holding back vacuum")
	m.data.SetUnit("{transactions}")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricPostgresqlReplicationBackendXminAge) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, applicationNameAttributeValue string, clientAddressAttributeValue string, replicationStateAttributeValue string, syncStateAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("application_name", applicationNameAttributeValue)
	dp.Attributes().PutStr("client_address", clientAddressAttributeValue)
	dp.Attributes().PutStr("replication_state", replicationStateAttributeValue)
	dp.Attributes().PutStr("sync_state", syncStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricPostgresqlReplicationBackendXminAge) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricPostgresqlReplicationBackendXminAge) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricPostgresqlReplicationBackendXminAge(cfg MetricConfig) metricPostgresqlReplicationBackendXminAge {
	m := metricPostgresqlReplicationBackendXminAge{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricPostgresqlReplicationFlushLsnDelay struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills postgresql.replication.flush_lsn_delay metric with initial data.
func (m *metricPostgresqlReplicationFlushLsnDelay) init() {
	m.data.SetName("postgresql.replication.flush_lsn_delay")
	m.data.SetDescription("Number of bytes of WAL flushed but not yet applied on standby")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricPostgresqlReplicationFlushLsnDelay) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, applicationNameAttributeValue string, clientAddressAttributeValue string, replicationStateAttributeValue string, syncStateAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("application_name", applicationNameAttributeValue)
	dp.Attributes().PutStr("client_address", clientAddressAttributeValue)
	dp.Attributes().PutStr("replication_state", replicationStateAttributeValue)
	dp.Attributes().PutStr("sync_state", syncStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricPostgresqlReplicationFlushLsnDelay) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricPostgresqlReplicationFlushLsnDelay) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricPostgresqlReplicationFlushLsnDelay(cfg MetricConfig) metricPostgresqlReplicationFlushLsnDelay {
	m := metricPostgresqlReplicationFlushLsnDelay{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricPostgresqlReplicationReplayLsnDelay struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills postgresql.replication.replay_lsn_delay metric with initial data.
func (m *metricPostgresqlReplicationReplayLsnDelay) init() {
	m.data.SetName("postgresql.replication.replay_lsn_delay")
	m.data.SetDescription("Number of bytes of WAL not yet replayed on standby (total replication lag in bytes)")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricPostgresqlReplicationReplayLsnDelay) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, applicationNameAttributeValue string, clientAddressAttributeValue string, replicationStateAttributeValue string, syncStateAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("application_name", applicationNameAttributeValue)
	dp.Attributes().PutStr("client_address", clientAddressAttributeValue)
	dp.Attributes().PutStr("replication_state", replicationStateAttributeValue)
	dp.Attributes().PutStr("sync_state", syncStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricPostgresqlReplicationReplayLsnDelay) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricPostgresqlReplicationReplayLsnDelay) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricPostgresqlReplicationReplayLsnDelay(cfg MetricConfig) metricPostgresqlReplicationReplayLsnDelay {
	m := metricPostgresqlReplicationReplayLsnDelay{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricPostgresqlReplicationSentLsnDelay struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills postgresql.replication.sent_lsn_delay metric with initial data.
func (m *metricPostgresqlReplicationSentLsnDelay) init() {
	m.data.SetName("postgresql.replication.sent_lsn_delay")
	m.data.SetDescription("Number of bytes of WAL sent but not yet written to disk on standby")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricPostgresqlReplicationSentLsnDelay) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, applicationNameAttributeValue string, clientAddressAttributeValue string, replicationStateAttributeValue string, syncStateAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("application_name", applicationNameAttributeValue)
	dp.Attributes().PutStr("client_address", clientAddressAttributeValue)
	dp.Attributes().PutStr("replication_state", replicationStateAttributeValue)
	dp.Attributes().PutStr("sync_state", syncStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricPostgresqlReplicationSentLsnDelay) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricPostgresqlReplicationSentLsnDelay) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricPostgresqlReplicationSentLsnDelay(cfg MetricConfig) metricPostgresqlReplicationSentLsnDelay {
	m := metricPostgresqlReplicationSentLsnDelay{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricPostgresqlReplicationWalFlushLag struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills postgresql.replication.wal_flush_lag metric with initial data.
func (m *metricPostgresqlReplicationWalFlushLag) init() {
	m.data.SetName("postgresql.replication.wal_flush_lag")
	m.data.SetDescription("Time elapsed between WAL flush on primary and confirmation from standby (PostgreSQL 10+)")
	m.data.SetUnit("s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricPostgresqlReplicationWalFlushLag) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, applicationNameAttributeValue string, clientAddressAttributeValue string, replicationStateAttributeValue string, syncStateAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("application_name", applicationNameAttributeValue)
	dp.Attributes().PutStr("client_address", clientAddressAttributeValue)
	dp.Attributes().PutStr("replication_state", replicationStateAttributeValue)
	dp.Attributes().PutStr("sync_state", syncStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricPostgresqlReplicationWalFlushLag) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricPostgresqlReplicationWalFlushLag) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricPostgresqlReplicationWalFlushLag(cfg MetricConfig) metricPostgresqlReplicationWalFlushLag {
	m := metricPostgresqlReplicationWalFlushLag{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricPostgresqlReplicationWalReplayLag struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills postgresql.replication.wal_replay_lag metric with initial data.
func (m *metricPostgresqlReplicationWalReplayLag) init() {
	m.data.SetName("postgresql.replication.wal_replay_lag")
	m.data.SetDescription("Time elapsed between WAL replay on primary and confirmation from standby (PostgreSQL 10+)")
	m.data.SetUnit("s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricPostgresqlReplicationWalReplayLag) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, applicationNameAttributeValue string, clientAddressAttributeValue string, replicationStateAttributeValue string, syncStateAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("application_name", applicationNameAttributeValue)
	dp.Attributes().PutStr("client_address", clientAddressAttributeValue)
	dp.Attributes().PutStr("replication_state", replicationStateAttributeValue)
	dp.Attributes().PutStr("sync_state", syncStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricPostgresqlReplicationWalReplayLag) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricPostgresqlReplicationWalReplayLag) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricPostgresqlReplicationWalReplayLag(cfg MetricConfig) metricPostgresqlReplicationWalReplayLag {
	m := metricPostgresqlReplicationWalReplayLag{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricPostgresqlReplicationWalWriteLag struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills postgresql.replication.wal_write_lag metric with initial data.
func (m *metricPostgresqlReplicationWalWriteLag) init() {
	m.data.SetName("postgresql.replication.wal_write_lag")
	m.data.SetDescription("Time elapsed between WAL write on primary and confirmation from standby (PostgreSQL 10+)")
	m.data.SetUnit("s")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricPostgresqlReplicationWalWriteLag) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val float64, applicationNameAttributeValue string, clientAddressAttributeValue string, replicationStateAttributeValue string, syncStateAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetDoubleValue(val)
	dp.Attributes().PutStr("application_name", applicationNameAttributeValue)
	dp.Attributes().PutStr("client_address", clientAddressAttributeValue)
	dp.Attributes().PutStr("replication_state", replicationStateAttributeValue)
	dp.Attributes().PutStr("sync_state", syncStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricPostgresqlReplicationWalWriteLag) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricPostgresqlReplicationWalWriteLag) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricPostgresqlReplicationWalWriteLag(cfg MetricConfig) metricPostgresqlReplicationWalWriteLag {
	m := metricPostgresqlReplicationWalWriteLag{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

type metricPostgresqlReplicationWriteLsnDelay struct {
	data     pmetric.Metric // data buffer for generated metric.
	config   MetricConfig   // metric config provided by user.
	capacity int            // max observed number of data points added to the metric.
}

// init fills postgresql.replication.write_lsn_delay metric with initial data.
func (m *metricPostgresqlReplicationWriteLsnDelay) init() {
	m.data.SetName("postgresql.replication.write_lsn_delay")
	m.data.SetDescription("Number of bytes of WAL written but not yet flushed on standby")
	m.data.SetUnit("By")
	m.data.SetEmptyGauge()
	m.data.Gauge().DataPoints().EnsureCapacity(m.capacity)
}

func (m *metricPostgresqlReplicationWriteLsnDelay) recordDataPoint(start pcommon.Timestamp, ts pcommon.Timestamp, val int64, applicationNameAttributeValue string, clientAddressAttributeValue string, replicationStateAttributeValue string, syncStateAttributeValue string) {
	if !m.config.Enabled {
		return
	}
	dp := m.data.Gauge().DataPoints().AppendEmpty()
	dp.SetStartTimestamp(start)
	dp.SetTimestamp(ts)
	dp.SetIntValue(val)
	dp.Attributes().PutStr("application_name", applicationNameAttributeValue)
	dp.Attributes().PutStr("client_address", clientAddressAttributeValue)
	dp.Attributes().PutStr("replication_state", replicationStateAttributeValue)
	dp.Attributes().PutStr("sync_state", syncStateAttributeValue)
}

// updateCapacity saves max length of data point slices that will be used for the slice capacity.
func (m *metricPostgresqlReplicationWriteLsnDelay) updateCapacity() {
	if m.data.Gauge().DataPoints().Len() > m.capacity {
		m.capacity = m.data.Gauge().DataPoints().Len()
	}
}

// emit appends recorded metric data to a metrics slice and prepares it for recording another set of data points.
func (m *metricPostgresqlReplicationWriteLsnDelay) emit(metrics pmetric.MetricSlice) {
	if m.config.Enabled && m.data.Gauge().DataPoints().Len() > 0 {
		m.updateCapacity()
		m.data.MoveTo(metrics.AppendEmpty())
		m.init()
	}
}

func newMetricPostgresqlReplicationWriteLsnDelay(cfg MetricConfig) metricPostgresqlReplicationWriteLsnDelay {
	m := metricPostgresqlReplicationWriteLsnDelay{config: cfg}
	if cfg.Enabled {
		m.data = pmetric.NewMetric()
		m.init()
	}
	return m
}

// MetricsBuilder provides an interface for scrapers to report metrics while taking care of all the transformations
// required to produce metric representation defined in metadata and user config.
type MetricsBuilder struct {
	config                                    MetricsBuilderConfig // config of the metrics builder.
	startTime                                 pcommon.Timestamp    // start time that will be applied to all recorded data points.
	metricsCapacity                           int                  // maximum observed number of metrics per resource.
	metricsBuffer                             pmetric.Metrics      // accumulates metrics data before emitting.
	buildInfo                                 component.BuildInfo  // contains version information.
	resourceAttributeIncludeFilter            map[string]filter.Filter
	resourceAttributeExcludeFilter            map[string]filter.Filter
	metricPostgresqlConnectionCount           metricPostgresqlConnectionCount
	metricPostgresqlReplicationBackendXminAge metricPostgresqlReplicationBackendXminAge
	metricPostgresqlReplicationFlushLsnDelay  metricPostgresqlReplicationFlushLsnDelay
	metricPostgresqlReplicationReplayLsnDelay metricPostgresqlReplicationReplayLsnDelay
	metricPostgresqlReplicationSentLsnDelay   metricPostgresqlReplicationSentLsnDelay
	metricPostgresqlReplicationWalFlushLag    metricPostgresqlReplicationWalFlushLag
	metricPostgresqlReplicationWalReplayLag   metricPostgresqlReplicationWalReplayLag
	metricPostgresqlReplicationWalWriteLag    metricPostgresqlReplicationWalWriteLag
	metricPostgresqlReplicationWriteLsnDelay  metricPostgresqlReplicationWriteLsnDelay
}

// MetricBuilderOption applies changes to default metrics builder.
type MetricBuilderOption interface {
	apply(*MetricsBuilder)
}

type metricBuilderOptionFunc func(mb *MetricsBuilder)

func (mbof metricBuilderOptionFunc) apply(mb *MetricsBuilder) {
	mbof(mb)
}

// WithStartTime sets startTime on the metrics builder.
func WithStartTime(startTime pcommon.Timestamp) MetricBuilderOption {
	return metricBuilderOptionFunc(func(mb *MetricsBuilder) {
		mb.startTime = startTime
	})
}
func NewMetricsBuilder(mbc MetricsBuilderConfig, settings receiver.Settings, options ...MetricBuilderOption) *MetricsBuilder {
	mb := &MetricsBuilder{
		config:                          mbc,
		startTime:                       pcommon.NewTimestampFromTime(time.Now()),
		metricsBuffer:                   pmetric.NewMetrics(),
		buildInfo:                       settings.BuildInfo,
		metricPostgresqlConnectionCount: newMetricPostgresqlConnectionCount(mbc.Metrics.PostgresqlConnectionCount),
		metricPostgresqlReplicationBackendXminAge: newMetricPostgresqlReplicationBackendXminAge(mbc.Metrics.PostgresqlReplicationBackendXminAge),
		metricPostgresqlReplicationFlushLsnDelay:  newMetricPostgresqlReplicationFlushLsnDelay(mbc.Metrics.PostgresqlReplicationFlushLsnDelay),
		metricPostgresqlReplicationReplayLsnDelay: newMetricPostgresqlReplicationReplayLsnDelay(mbc.Metrics.PostgresqlReplicationReplayLsnDelay),
		metricPostgresqlReplicationSentLsnDelay:   newMetricPostgresqlReplicationSentLsnDelay(mbc.Metrics.PostgresqlReplicationSentLsnDelay),
		metricPostgresqlReplicationWalFlushLag:    newMetricPostgresqlReplicationWalFlushLag(mbc.Metrics.PostgresqlReplicationWalFlushLag),
		metricPostgresqlReplicationWalReplayLag:   newMetricPostgresqlReplicationWalReplayLag(mbc.Metrics.PostgresqlReplicationWalReplayLag),
		metricPostgresqlReplicationWalWriteLag:    newMetricPostgresqlReplicationWalWriteLag(mbc.Metrics.PostgresqlReplicationWalWriteLag),
		metricPostgresqlReplicationWriteLsnDelay:  newMetricPostgresqlReplicationWriteLsnDelay(mbc.Metrics.PostgresqlReplicationWriteLsnDelay),
		resourceAttributeIncludeFilter:            make(map[string]filter.Filter),
		resourceAttributeExcludeFilter:            make(map[string]filter.Filter),
	}
	if mbc.ResourceAttributes.DatabaseName.MetricsInclude != nil {
		mb.resourceAttributeIncludeFilter["database_name"] = filter.CreateFilter(mbc.ResourceAttributes.DatabaseName.MetricsInclude)
	}
	if mbc.ResourceAttributes.DatabaseName.MetricsExclude != nil {
		mb.resourceAttributeExcludeFilter["database_name"] = filter.CreateFilter(mbc.ResourceAttributes.DatabaseName.MetricsExclude)
	}
	if mbc.ResourceAttributes.DbSystem.MetricsInclude != nil {
		mb.resourceAttributeIncludeFilter["db.system"] = filter.CreateFilter(mbc.ResourceAttributes.DbSystem.MetricsInclude)
	}
	if mbc.ResourceAttributes.DbSystem.MetricsExclude != nil {
		mb.resourceAttributeExcludeFilter["db.system"] = filter.CreateFilter(mbc.ResourceAttributes.DbSystem.MetricsExclude)
	}
	if mbc.ResourceAttributes.PostgresqlVersion.MetricsInclude != nil {
		mb.resourceAttributeIncludeFilter["postgresql.version"] = filter.CreateFilter(mbc.ResourceAttributes.PostgresqlVersion.MetricsInclude)
	}
	if mbc.ResourceAttributes.PostgresqlVersion.MetricsExclude != nil {
		mb.resourceAttributeExcludeFilter["postgresql.version"] = filter.CreateFilter(mbc.ResourceAttributes.PostgresqlVersion.MetricsExclude)
	}
	if mbc.ResourceAttributes.ServerAddress.MetricsInclude != nil {
		mb.resourceAttributeIncludeFilter["server.address"] = filter.CreateFilter(mbc.ResourceAttributes.ServerAddress.MetricsInclude)
	}
	if mbc.ResourceAttributes.ServerAddress.MetricsExclude != nil {
		mb.resourceAttributeExcludeFilter["server.address"] = filter.CreateFilter(mbc.ResourceAttributes.ServerAddress.MetricsExclude)
	}
	if mbc.ResourceAttributes.ServerPort.MetricsInclude != nil {
		mb.resourceAttributeIncludeFilter["server.port"] = filter.CreateFilter(mbc.ResourceAttributes.ServerPort.MetricsInclude)
	}
	if mbc.ResourceAttributes.ServerPort.MetricsExclude != nil {
		mb.resourceAttributeExcludeFilter["server.port"] = filter.CreateFilter(mbc.ResourceAttributes.ServerPort.MetricsExclude)
	}

	for _, op := range options {
		op.apply(mb)
	}
	return mb
}

// NewResourceBuilder returns a new resource builder that should be used to build a resource associated with for the emitted metrics.
func (mb *MetricsBuilder) NewResourceBuilder() *ResourceBuilder {
	return NewResourceBuilder(mb.config.ResourceAttributes)
}

// updateCapacity updates max length of metrics and resource attributes that will be used for the slice capacity.
func (mb *MetricsBuilder) updateCapacity(rm pmetric.ResourceMetrics) {
	if mb.metricsCapacity < rm.ScopeMetrics().At(0).Metrics().Len() {
		mb.metricsCapacity = rm.ScopeMetrics().At(0).Metrics().Len()
	}
}

// ResourceMetricsOption applies changes to provided resource metrics.
type ResourceMetricsOption interface {
	apply(pmetric.ResourceMetrics)
}

type resourceMetricsOptionFunc func(pmetric.ResourceMetrics)

func (rmof resourceMetricsOptionFunc) apply(rm pmetric.ResourceMetrics) {
	rmof(rm)
}

// WithResource sets the provided resource on the emitted ResourceMetrics.
// It's recommended to use ResourceBuilder to create the resource.
func WithResource(res pcommon.Resource) ResourceMetricsOption {
	return resourceMetricsOptionFunc(func(rm pmetric.ResourceMetrics) {
		res.CopyTo(rm.Resource())
	})
}

// WithStartTimeOverride overrides start time for all the resource metrics data points.
// This option should be only used if different start time has to be set on metrics coming from different resources.
func WithStartTimeOverride(start pcommon.Timestamp) ResourceMetricsOption {
	return resourceMetricsOptionFunc(func(rm pmetric.ResourceMetrics) {
		var dps pmetric.NumberDataPointSlice
		metrics := rm.ScopeMetrics().At(0).Metrics()
		for i := 0; i < metrics.Len(); i++ {
			switch metrics.At(i).Type() {
			case pmetric.MetricTypeGauge:
				dps = metrics.At(i).Gauge().DataPoints()
			case pmetric.MetricTypeSum:
				dps = metrics.At(i).Sum().DataPoints()
			}
			for j := 0; j < dps.Len(); j++ {
				dps.At(j).SetStartTimestamp(start)
			}
		}
	})
}

// EmitForResource saves all the generated metrics under a new resource and updates the internal state to be ready for
// recording another set of data points as part of another resource. This function can be helpful when one scraper
// needs to emit metrics from several resources. Otherwise calling this function is not required,
// just `Emit` function can be called instead.
// Resource attributes should be provided as ResourceMetricsOption arguments.
func (mb *MetricsBuilder) EmitForResource(options ...ResourceMetricsOption) {
	rm := pmetric.NewResourceMetrics()
	ils := rm.ScopeMetrics().AppendEmpty()
	ils.Scope().SetName(ScopeName)
	ils.Scope().SetVersion(mb.buildInfo.Version)
	ils.Metrics().EnsureCapacity(mb.metricsCapacity)
	mb.metricPostgresqlConnectionCount.emit(ils.Metrics())
	mb.metricPostgresqlReplicationBackendXminAge.emit(ils.Metrics())
	mb.metricPostgresqlReplicationFlushLsnDelay.emit(ils.Metrics())
	mb.metricPostgresqlReplicationReplayLsnDelay.emit(ils.Metrics())
	mb.metricPostgresqlReplicationSentLsnDelay.emit(ils.Metrics())
	mb.metricPostgresqlReplicationWalFlushLag.emit(ils.Metrics())
	mb.metricPostgresqlReplicationWalReplayLag.emit(ils.Metrics())
	mb.metricPostgresqlReplicationWalWriteLag.emit(ils.Metrics())
	mb.metricPostgresqlReplicationWriteLsnDelay.emit(ils.Metrics())

	for _, op := range options {
		op.apply(rm)
	}
	for attr, filter := range mb.resourceAttributeIncludeFilter {
		if val, ok := rm.Resource().Attributes().Get(attr); ok && !filter.Matches(val.AsString()) {
			return
		}
	}
	for attr, filter := range mb.resourceAttributeExcludeFilter {
		if val, ok := rm.Resource().Attributes().Get(attr); ok && filter.Matches(val.AsString()) {
			return
		}
	}

	if ils.Metrics().Len() > 0 {
		mb.updateCapacity(rm)
		rm.MoveTo(mb.metricsBuffer.ResourceMetrics().AppendEmpty())
	}
}

// Emit returns all the metrics accumulated by the metrics builder and updates the internal state to be ready for
// recording another set of metrics. This function will be responsible for applying all the transformations required to
// produce metric representation defined in metadata and user config, e.g. delta or cumulative.
func (mb *MetricsBuilder) Emit(options ...ResourceMetricsOption) pmetric.Metrics {
	mb.EmitForResource(options...)
	metrics := mb.metricsBuffer
	mb.metricsBuffer = pmetric.NewMetrics()
	return metrics
}

// RecordPostgresqlConnectionCountDataPoint adds a data point to postgresql.connection.count metric.
func (mb *MetricsBuilder) RecordPostgresqlConnectionCountDataPoint(ts pcommon.Timestamp, val int64) {
	mb.metricPostgresqlConnectionCount.recordDataPoint(mb.startTime, ts, val)
}

// RecordPostgresqlReplicationBackendXminAgeDataPoint adds a data point to postgresql.replication.backend_xmin_age metric.
func (mb *MetricsBuilder) RecordPostgresqlReplicationBackendXminAgeDataPoint(ts pcommon.Timestamp, val int64, applicationNameAttributeValue string, clientAddressAttributeValue string, replicationStateAttributeValue string, syncStateAttributeValue string) {
	mb.metricPostgresqlReplicationBackendXminAge.recordDataPoint(mb.startTime, ts, val, applicationNameAttributeValue, clientAddressAttributeValue, replicationStateAttributeValue, syncStateAttributeValue)
}

// RecordPostgresqlReplicationFlushLsnDelayDataPoint adds a data point to postgresql.replication.flush_lsn_delay metric.
func (mb *MetricsBuilder) RecordPostgresqlReplicationFlushLsnDelayDataPoint(ts pcommon.Timestamp, val int64, applicationNameAttributeValue string, clientAddressAttributeValue string, replicationStateAttributeValue string, syncStateAttributeValue string) {
	mb.metricPostgresqlReplicationFlushLsnDelay.recordDataPoint(mb.startTime, ts, val, applicationNameAttributeValue, clientAddressAttributeValue, replicationStateAttributeValue, syncStateAttributeValue)
}

// RecordPostgresqlReplicationReplayLsnDelayDataPoint adds a data point to postgresql.replication.replay_lsn_delay metric.
func (mb *MetricsBuilder) RecordPostgresqlReplicationReplayLsnDelayDataPoint(ts pcommon.Timestamp, val int64, applicationNameAttributeValue string, clientAddressAttributeValue string, replicationStateAttributeValue string, syncStateAttributeValue string) {
	mb.metricPostgresqlReplicationReplayLsnDelay.recordDataPoint(mb.startTime, ts, val, applicationNameAttributeValue, clientAddressAttributeValue, replicationStateAttributeValue, syncStateAttributeValue)
}

// RecordPostgresqlReplicationSentLsnDelayDataPoint adds a data point to postgresql.replication.sent_lsn_delay metric.
func (mb *MetricsBuilder) RecordPostgresqlReplicationSentLsnDelayDataPoint(ts pcommon.Timestamp, val int64, applicationNameAttributeValue string, clientAddressAttributeValue string, replicationStateAttributeValue string, syncStateAttributeValue string) {
	mb.metricPostgresqlReplicationSentLsnDelay.recordDataPoint(mb.startTime, ts, val, applicationNameAttributeValue, clientAddressAttributeValue, replicationStateAttributeValue, syncStateAttributeValue)
}

// RecordPostgresqlReplicationWalFlushLagDataPoint adds a data point to postgresql.replication.wal_flush_lag metric.
func (mb *MetricsBuilder) RecordPostgresqlReplicationWalFlushLagDataPoint(ts pcommon.Timestamp, val float64, applicationNameAttributeValue string, clientAddressAttributeValue string, replicationStateAttributeValue string, syncStateAttributeValue string) {
	mb.metricPostgresqlReplicationWalFlushLag.recordDataPoint(mb.startTime, ts, val, applicationNameAttributeValue, clientAddressAttributeValue, replicationStateAttributeValue, syncStateAttributeValue)
}

// RecordPostgresqlReplicationWalReplayLagDataPoint adds a data point to postgresql.replication.wal_replay_lag metric.
func (mb *MetricsBuilder) RecordPostgresqlReplicationWalReplayLagDataPoint(ts pcommon.Timestamp, val float64, applicationNameAttributeValue string, clientAddressAttributeValue string, replicationStateAttributeValue string, syncStateAttributeValue string) {
	mb.metricPostgresqlReplicationWalReplayLag.recordDataPoint(mb.startTime, ts, val, applicationNameAttributeValue, clientAddressAttributeValue, replicationStateAttributeValue, syncStateAttributeValue)
}

// RecordPostgresqlReplicationWalWriteLagDataPoint adds a data point to postgresql.replication.wal_write_lag metric.
func (mb *MetricsBuilder) RecordPostgresqlReplicationWalWriteLagDataPoint(ts pcommon.Timestamp, val float64, applicationNameAttributeValue string, clientAddressAttributeValue string, replicationStateAttributeValue string, syncStateAttributeValue string) {
	mb.metricPostgresqlReplicationWalWriteLag.recordDataPoint(mb.startTime, ts, val, applicationNameAttributeValue, clientAddressAttributeValue, replicationStateAttributeValue, syncStateAttributeValue)
}

// RecordPostgresqlReplicationWriteLsnDelayDataPoint adds a data point to postgresql.replication.write_lsn_delay metric.
func (mb *MetricsBuilder) RecordPostgresqlReplicationWriteLsnDelayDataPoint(ts pcommon.Timestamp, val int64, applicationNameAttributeValue string, clientAddressAttributeValue string, replicationStateAttributeValue string, syncStateAttributeValue string) {
	mb.metricPostgresqlReplicationWriteLsnDelay.recordDataPoint(mb.startTime, ts, val, applicationNameAttributeValue, clientAddressAttributeValue, replicationStateAttributeValue, syncStateAttributeValue)
}

// Reset resets metrics builder to its initial state. It should be used when external metrics source is restarted,
// and metrics builder should update its startTime and reset it's internal state accordingly.
func (mb *MetricsBuilder) Reset(options ...MetricBuilderOption) {
	mb.startTime = pcommon.NewTimestampFromTime(time.Now())
	for _, op := range options {
		op.apply(mb)
	}
}
