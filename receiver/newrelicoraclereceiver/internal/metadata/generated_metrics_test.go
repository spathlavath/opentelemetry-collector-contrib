// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"testing"

	"github.com/stretchr/testify/assert"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
	"go.opentelemetry.io/collector/receiver/receivertest"
	"go.uber.org/zap"
	"go.uber.org/zap/zaptest/observer"
)

type testDataSet int

const (
	testDataSetDefault testDataSet = iota
	testDataSetAll
	testDataSetNone
)

func TestMetricsBuilder(t *testing.T) {
	tests := []struct {
		name        string
		metricsSet  testDataSet
		resAttrsSet testDataSet
		expectEmpty bool
	}{
		{
			name: "default",
		},
		{
			name:        "all_set",
			metricsSet:  testDataSetAll,
			resAttrsSet: testDataSetAll,
		},
		{
			name:        "none_set",
			metricsSet:  testDataSetNone,
			resAttrsSet: testDataSetNone,
			expectEmpty: true,
		},
		{
			name:        "filter_set_include",
			resAttrsSet: testDataSetAll,
		},
		{
			name:        "filter_set_exclude",
			resAttrsSet: testDataSetAll,
			expectEmpty: true,
		},
	}
	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			start := pcommon.Timestamp(1_000_000_000)
			ts := pcommon.Timestamp(1_000_001_000)
			observedZapCore, observedLogs := observer.New(zap.WarnLevel)
			settings := receivertest.NewNopSettings(receivertest.NopType)
			settings.Logger = zap.New(observedZapCore)
			mb := NewMetricsBuilder(loadMetricsBuilderConfig(t, tt.name), settings, WithStartTime(start))

			expectedWarnings := 0

			assert.Equal(t, expectedWarnings, observedLogs.Len())

			defaultMetricsCount := 0
			allMetricsCount := 0

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbActiveParallelSessionsDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbActiveSerialSessionsDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbAverageActiveSessionsDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbBackgroundCheckpointsPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbBackgroundCPUUsagePerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbBackgroundTimePerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbBlockChangesPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbBlockChangesPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbBlockChangesPerUserCallDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbBlockGetsPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbBlockGetsPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbBlockGetsPerUserCallDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbBranchNodeSplitsPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbBranchNodeSplitsPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbCapturedUserCallsDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbConsistentReadChangesPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbConsistentReadChangesPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbConsistentReadGetsPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbConsistentReadGetsPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbCPUTimeRatioDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbCPUUsagePerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbCPUUsagePerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbCrBlocksCreatedPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbCrBlocksCreatedPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbCrUndoRecordsAppliedPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbCrUndoRecordsAppliedPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbCurrentLogonsDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbCurrentOpenCursorsDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbCursorCacheHitsPerAttemptsDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbDatabaseCPUTimePerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbDbwrCheckpointsPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbEnqueueDeadlocksPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbEnqueueDeadlocksPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbEnqueueRequestsPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbEnqueueRequestsPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbEnqueueTimeoutsPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbEnqueueTimeoutsPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbEnqueueWaitsPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbEnqueueWaitsPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbExecuteWithoutParseRatioDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbExecutionsPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbExecutionsPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbExecutionsPerUserCallDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbFullIndexScansPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbFullIndexScansPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbGcCrBlockReceivedPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbGcCrBlockReceivedPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbGcCurrentBlockReceivedPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbGcCurrentBlockReceivedPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbGlobalCacheAverageCrGetTimeDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbGlobalCacheAverageCurrentGetTimeDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbHardParseCountPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbHardParseCountPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbHostCPUUsagePerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbHostCPUUtilizationDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbLeafNodeSplitsPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbLeafNodeSplitsPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbLibraryCacheHitRatioDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbLibraryCacheMissRatioDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbLogicalReadsPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbLogicalReadsPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbLogonsPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbLogonsPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbLongTableScansPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbLongTableScansPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbOpenCursorsPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbOpenCursorsPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbOsLoadDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbParseFailureCountPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbParseFailureCountPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbPgaCacheHitPercentageDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbPhysicalReadBytesPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbPhysicalReadIoRequestsPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbPhysicalReadsPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbPhysicalWriteBytesPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbPhysicalWritesPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbProcessLimitPercentageDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbRecursiveCallsPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbRecursiveCallsPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbRedoWritesPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbRedoWritesPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbResponseTimePerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbRowCacheHitRatioDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbRowCacheMissRatioDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbRowsPerSortDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbSessionCountDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbSessionLimitPercentageDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbSharedPoolFreePercentageDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbSoftParseRatioDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbSortsPerUserCallDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbSQLServiceResponseTimeDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbStreamsPoolUsagePercentageDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbTableScansPerUserCallDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbTotalIndexScansPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbTotalIndexScansPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbTotalParseCountPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbTotalParseCountPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbTotalTableScansPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbTotalTableScansPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbTransactionsPerLogonDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbUserCallsPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbUserCallsPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbUserCallsRatioDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbUserCommitsPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbUserCommitsPercentageDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbUserLimitPercentageDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbUserRollbackUndoRecordsAppliedPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbUserRollbackUndoRecordsAppliedPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbUserRollbacksPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbUserRollbacksPercentageDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDbWaitTimeRatioDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDiskBlocksReadDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDiskBlocksWrittenDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDiskLogicalReadsPerUserCallDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDiskPhysicalLobsReadsPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDiskPhysicalLobsWritesPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDiskPhysicalReadBytesPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDiskPhysicalReadIoRequestsPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDiskPhysicalReadsPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDiskPhysicalWriteBytesPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDiskPhysicalWriteTotalIoRequestsPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDiskPhysicalWritesPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDiskReadTimeMillisecondsDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDiskReadsDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDiskSortPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDiskSortPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDiskTempSpaceUsedBytesDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDiskWriteTimeMillisecondsDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleDiskWritesDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleLockedAccountsDataPoint(ts, 1, "instance_id-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleLongRunningQueriesDataPoint(ts, 1, "instance_id-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleMemoryBufferCacheHitRatioDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleMemoryGlobalCacheBlocksCorruptedDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleMemoryGlobalCacheBlocksLostDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleMemoryPgaAllocatedBytesDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleMemoryPgaFreeableBytesDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleMemoryPgaInUseBytesDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleMemoryPgaMaxSizeBytesDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleMemoryRedoAllocationHitRatioDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleMemoryRedoGeneratedBytesPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleMemoryRedoGeneratedBytesPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleMemorySortsRatioDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleNetworkIoMegabytesPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleNetworkIoRequestsPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleNetworkTrafficBytesPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleQueryPhysicalLobsReadsPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleQueryPhysicalLobsWritesPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleQueryPhysicalReadsPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleQueryPhysicalWritesPerTransactionDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleQueryTransactionsPerSecondDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleRedoLogFileSwitchDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleRedoLogFileSwitchArchivingNeededDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleRedoLogFileSwitchCheckpointIncompleteDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleRedoLogWaitsDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleRollbackSegmentsGetsDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleRollbackSegmentsRatioWaitDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleRollbackSegmentsWaitsDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleSgaBufferBusyWaitsDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleSgaFixedSizeBytesDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleSgaFreeBufferInspectedDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleSgaFreeBufferWaitsDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleSgaHitRatioDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleSgaLogBufferAllocationRetriesRatioDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleSgaLogBufferRedoAllocationRetriesDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleSgaLogBufferRedoEntriesDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleSgaLogBufferSpaceWaitsDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleSgaRedoBuffersBytesDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleSgaSharedPoolDictCacheMissRatioDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleSgaSharedPoolLibraryCacheHitRatioDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleSgaSharedPoolLibraryCacheReloadRatioDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleSgaSharedPoolLibraryCacheShareableMemoryPerStatementBytesDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleSgaSharedPoolLibraryCacheShareableMemoryPerUserBytesDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleSgaUgaTotalMemoryBytesDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleSortsDiskBytesDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleSortsMemoryBytesDataPoint(ts, 1)

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleTablespaceIsOfflineDataPoint(ts, 1, "tablespace_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleTablespaceOfflineCdbDatafilesDataPoint(ts, 1, "tablespace_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleTablespaceOfflinePdbDatafilesDataPoint(ts, 1, "tablespace_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleTablespacePdbDatafilesNonWriteDataPoint(ts, 1, "tablespace_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleTablespaceSpaceConsumedBytesDataPoint(ts, 1, "tablespace_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleTablespaceSpaceReservedBytesDataPoint(ts, 1, "tablespace_name-val")

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordNewrelicOracleTablespaceSpaceUsedPercentageDataPoint(ts, 1, "tablespace_name-val")

			rb := mb.NewResourceBuilder()
			rb.SetHostName("host.name-val")
			rb.SetNewrelicOracleDbID("newrelic.oracle.db.id-val")
			rb.SetNewrelicOracleGlobalName("newrelic.oracle.global.name-val")
			rb.SetNewrelicOracleInstanceID("newrelic.oracle.instance.id-val")
			rb.SetNewrelicOracleInstanceName("newrelic.oracle.instance.name-val")
			res := rb.Emit()
			metrics := mb.Emit(WithResource(res))

			if tt.expectEmpty {
				assert.Equal(t, 0, metrics.ResourceMetrics().Len())
				return
			}

			assert.Equal(t, 1, metrics.ResourceMetrics().Len())
			rm := metrics.ResourceMetrics().At(0)
			assert.Equal(t, res, rm.Resource())
			assert.Equal(t, 1, rm.ScopeMetrics().Len())
			ms := rm.ScopeMetrics().At(0).Metrics()
			if tt.metricsSet == testDataSetDefault {
				assert.Equal(t, defaultMetricsCount, ms.Len())
			}
			if tt.metricsSet == testDataSetAll {
				assert.Equal(t, allMetricsCount, ms.Len())
			}
			validatedMetrics := make(map[string]bool)
			for i := 0; i < ms.Len(); i++ {
				switch ms.At(i).Name() {
				case "newrelic.oracle.db.active_parallel_sessions":
					assert.False(t, validatedMetrics["newrelic.oracle.db.active_parallel_sessions"], "Found a duplicate in the metrics slice: newrelic.oracle.db.active_parallel_sessions")
					validatedMetrics["newrelic.oracle.db.active_parallel_sessions"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Active parallel sessions", ms.At(i).Description())
					assert.Equal(t, "{sessions}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.db.active_serial_sessions":
					assert.False(t, validatedMetrics["newrelic.oracle.db.active_serial_sessions"], "Found a duplicate in the metrics slice: newrelic.oracle.db.active_serial_sessions")
					validatedMetrics["newrelic.oracle.db.active_serial_sessions"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Active serial sessions", ms.At(i).Description())
					assert.Equal(t, "{sessions}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.db.average_active_sessions":
					assert.False(t, validatedMetrics["newrelic.oracle.db.average_active_sessions"], "Found a duplicate in the metrics slice: newrelic.oracle.db.average_active_sessions")
					validatedMetrics["newrelic.oracle.db.average_active_sessions"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Average active sessions", ms.At(i).Description())
					assert.Equal(t, "{sessions}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.background_checkpoints_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.background_checkpoints_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.background_checkpoints_per_second")
					validatedMetrics["newrelic.oracle.db.background_checkpoints_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Background checkpoints per second", ms.At(i).Description())
					assert.Equal(t, "{checkpoints}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.background_cpu_usage_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.background_cpu_usage_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.background_cpu_usage_per_second")
					validatedMetrics["newrelic.oracle.db.background_cpu_usage_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Background CPU usage per second", ms.At(i).Description())
					assert.Equal(t, "{cpu}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.background_time_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.background_time_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.background_time_per_second")
					validatedMetrics["newrelic.oracle.db.background_time_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Background time per second", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.block_changes_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.block_changes_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.block_changes_per_second")
					validatedMetrics["newrelic.oracle.db.block_changes_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "DB block changes per second", ms.At(i).Description())
					assert.Equal(t, "{changes}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.block_changes_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.db.block_changes_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.db.block_changes_per_transaction")
					validatedMetrics["newrelic.oracle.db.block_changes_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "DB block changes per transaction", ms.At(i).Description())
					assert.Equal(t, "{changes}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.block_changes_per_user_call":
					assert.False(t, validatedMetrics["newrelic.oracle.db.block_changes_per_user_call"], "Found a duplicate in the metrics slice: newrelic.oracle.db.block_changes_per_user_call")
					validatedMetrics["newrelic.oracle.db.block_changes_per_user_call"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "DB block changes per user call", ms.At(i).Description())
					assert.Equal(t, "{changes}/{call}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.block_gets_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.block_gets_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.block_gets_per_second")
					validatedMetrics["newrelic.oracle.db.block_gets_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "DB block gets per second", ms.At(i).Description())
					assert.Equal(t, "{gets}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.block_gets_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.db.block_gets_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.db.block_gets_per_transaction")
					validatedMetrics["newrelic.oracle.db.block_gets_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "DB block gets per transaction", ms.At(i).Description())
					assert.Equal(t, "{gets}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.block_gets_per_user_call":
					assert.False(t, validatedMetrics["newrelic.oracle.db.block_gets_per_user_call"], "Found a duplicate in the metrics slice: newrelic.oracle.db.block_gets_per_user_call")
					validatedMetrics["newrelic.oracle.db.block_gets_per_user_call"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "DB block gets per user call", ms.At(i).Description())
					assert.Equal(t, "{gets}/{call}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.branch_node_splits_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.branch_node_splits_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.branch_node_splits_per_second")
					validatedMetrics["newrelic.oracle.db.branch_node_splits_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Branch node splits per second", ms.At(i).Description())
					assert.Equal(t, "{splits}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.branch_node_splits_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.db.branch_node_splits_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.db.branch_node_splits_per_transaction")
					validatedMetrics["newrelic.oracle.db.branch_node_splits_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Branch node splits per transaction", ms.At(i).Description())
					assert.Equal(t, "{splits}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.captured_user_calls":
					assert.False(t, validatedMetrics["newrelic.oracle.db.captured_user_calls"], "Found a duplicate in the metrics slice: newrelic.oracle.db.captured_user_calls")
					validatedMetrics["newrelic.oracle.db.captured_user_calls"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Captured user calls", ms.At(i).Description())
					assert.Equal(t, "{calls}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.db.consistent_read_changes_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.consistent_read_changes_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.consistent_read_changes_per_second")
					validatedMetrics["newrelic.oracle.db.consistent_read_changes_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Consistent read changes per second", ms.At(i).Description())
					assert.Equal(t, "{changes}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.consistent_read_changes_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.db.consistent_read_changes_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.db.consistent_read_changes_per_transaction")
					validatedMetrics["newrelic.oracle.db.consistent_read_changes_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Consistent read changes per transaction", ms.At(i).Description())
					assert.Equal(t, "{changes}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.consistent_read_gets_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.consistent_read_gets_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.consistent_read_gets_per_second")
					validatedMetrics["newrelic.oracle.db.consistent_read_gets_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Consistent read gets per second", ms.At(i).Description())
					assert.Equal(t, "{gets}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.consistent_read_gets_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.db.consistent_read_gets_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.db.consistent_read_gets_per_transaction")
					validatedMetrics["newrelic.oracle.db.consistent_read_gets_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Consistent read gets per transaction", ms.At(i).Description())
					assert.Equal(t, "{gets}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.cpu_time_ratio":
					assert.False(t, validatedMetrics["newrelic.oracle.db.cpu_time_ratio"], "Found a duplicate in the metrics slice: newrelic.oracle.db.cpu_time_ratio")
					validatedMetrics["newrelic.oracle.db.cpu_time_ratio"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Database CPU time ratio", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.cpu_usage_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.cpu_usage_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.cpu_usage_per_second")
					validatedMetrics["newrelic.oracle.db.cpu_usage_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "CPU usage per second", ms.At(i).Description())
					assert.Equal(t, "{cpu}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.cpu_usage_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.db.cpu_usage_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.db.cpu_usage_per_transaction")
					validatedMetrics["newrelic.oracle.db.cpu_usage_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "CPU usage per transaction", ms.At(i).Description())
					assert.Equal(t, "{cpu}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.cr_blocks_created_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.cr_blocks_created_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.cr_blocks_created_per_second")
					validatedMetrics["newrelic.oracle.db.cr_blocks_created_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "CR blocks created per second", ms.At(i).Description())
					assert.Equal(t, "{blocks}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.cr_blocks_created_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.db.cr_blocks_created_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.db.cr_blocks_created_per_transaction")
					validatedMetrics["newrelic.oracle.db.cr_blocks_created_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "CR blocks created per transaction", ms.At(i).Description())
					assert.Equal(t, "{blocks}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.cr_undo_records_applied_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.cr_undo_records_applied_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.cr_undo_records_applied_per_second")
					validatedMetrics["newrelic.oracle.db.cr_undo_records_applied_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "CR undo records applied per second", ms.At(i).Description())
					assert.Equal(t, "{records}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.cr_undo_records_applied_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.db.cr_undo_records_applied_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.db.cr_undo_records_applied_per_transaction")
					validatedMetrics["newrelic.oracle.db.cr_undo_records_applied_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "CR undo records applied per transaction", ms.At(i).Description())
					assert.Equal(t, "{records}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.current_logons":
					assert.False(t, validatedMetrics["newrelic.oracle.db.current_logons"], "Found a duplicate in the metrics slice: newrelic.oracle.db.current_logons")
					validatedMetrics["newrelic.oracle.db.current_logons"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Current logons count", ms.At(i).Description())
					assert.Equal(t, "{logons}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.db.current_open_cursors":
					assert.False(t, validatedMetrics["newrelic.oracle.db.current_open_cursors"], "Found a duplicate in the metrics slice: newrelic.oracle.db.current_open_cursors")
					validatedMetrics["newrelic.oracle.db.current_open_cursors"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Current open cursors count", ms.At(i).Description())
					assert.Equal(t, "{cursors}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.db.cursor_cache_hits_per_attempts":
					assert.False(t, validatedMetrics["newrelic.oracle.db.cursor_cache_hits_per_attempts"], "Found a duplicate in the metrics slice: newrelic.oracle.db.cursor_cache_hits_per_attempts")
					validatedMetrics["newrelic.oracle.db.cursor_cache_hits_per_attempts"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Cursor cache hit ratio", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.database_cpu_time_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.database_cpu_time_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.database_cpu_time_per_second")
					validatedMetrics["newrelic.oracle.db.database_cpu_time_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Database CPU time per second", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.dbwr_checkpoints_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.dbwr_checkpoints_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.dbwr_checkpoints_per_second")
					validatedMetrics["newrelic.oracle.db.dbwr_checkpoints_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "DBWR checkpoints per second", ms.At(i).Description())
					assert.Equal(t, "{checkpoints}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.enqueue_deadlocks_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.enqueue_deadlocks_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.enqueue_deadlocks_per_second")
					validatedMetrics["newrelic.oracle.db.enqueue_deadlocks_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Enqueue deadlocks per second", ms.At(i).Description())
					assert.Equal(t, "{deadlocks}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.enqueue_deadlocks_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.db.enqueue_deadlocks_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.db.enqueue_deadlocks_per_transaction")
					validatedMetrics["newrelic.oracle.db.enqueue_deadlocks_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Enqueue deadlocks per transaction", ms.At(i).Description())
					assert.Equal(t, "{deadlocks}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.enqueue_requests_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.enqueue_requests_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.enqueue_requests_per_second")
					validatedMetrics["newrelic.oracle.db.enqueue_requests_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Enqueue requests per second", ms.At(i).Description())
					assert.Equal(t, "{requests}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.enqueue_requests_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.db.enqueue_requests_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.db.enqueue_requests_per_transaction")
					validatedMetrics["newrelic.oracle.db.enqueue_requests_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Enqueue requests per transaction", ms.At(i).Description())
					assert.Equal(t, "{requests}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.enqueue_timeouts_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.enqueue_timeouts_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.enqueue_timeouts_per_second")
					validatedMetrics["newrelic.oracle.db.enqueue_timeouts_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Enqueue timeouts per second", ms.At(i).Description())
					assert.Equal(t, "{timeouts}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.enqueue_timeouts_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.db.enqueue_timeouts_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.db.enqueue_timeouts_per_transaction")
					validatedMetrics["newrelic.oracle.db.enqueue_timeouts_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Enqueue timeouts per transaction", ms.At(i).Description())
					assert.Equal(t, "{timeouts}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.enqueue_waits_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.enqueue_waits_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.enqueue_waits_per_second")
					validatedMetrics["newrelic.oracle.db.enqueue_waits_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Enqueue waits per second", ms.At(i).Description())
					assert.Equal(t, "{waits}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.enqueue_waits_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.db.enqueue_waits_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.db.enqueue_waits_per_transaction")
					validatedMetrics["newrelic.oracle.db.enqueue_waits_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Enqueue waits per transaction", ms.At(i).Description())
					assert.Equal(t, "{waits}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.execute_without_parse_ratio":
					assert.False(t, validatedMetrics["newrelic.oracle.db.execute_without_parse_ratio"], "Found a duplicate in the metrics slice: newrelic.oracle.db.execute_without_parse_ratio")
					validatedMetrics["newrelic.oracle.db.execute_without_parse_ratio"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Execute without parse ratio", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.executions_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.executions_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.executions_per_second")
					validatedMetrics["newrelic.oracle.db.executions_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Executions per second", ms.At(i).Description())
					assert.Equal(t, "{executions}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.executions_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.db.executions_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.db.executions_per_transaction")
					validatedMetrics["newrelic.oracle.db.executions_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Executions per transaction", ms.At(i).Description())
					assert.Equal(t, "{executions}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.executions_per_user_call":
					assert.False(t, validatedMetrics["newrelic.oracle.db.executions_per_user_call"], "Found a duplicate in the metrics slice: newrelic.oracle.db.executions_per_user_call")
					validatedMetrics["newrelic.oracle.db.executions_per_user_call"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Executions per user call", ms.At(i).Description())
					assert.Equal(t, "{executions}/{call}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.full_index_scans_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.full_index_scans_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.full_index_scans_per_second")
					validatedMetrics["newrelic.oracle.db.full_index_scans_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Full index scans per second", ms.At(i).Description())
					assert.Equal(t, "{scans}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.full_index_scans_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.db.full_index_scans_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.db.full_index_scans_per_transaction")
					validatedMetrics["newrelic.oracle.db.full_index_scans_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Full index scans per transaction", ms.At(i).Description())
					assert.Equal(t, "{scans}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.gc_cr_block_received_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.gc_cr_block_received_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.gc_cr_block_received_per_second")
					validatedMetrics["newrelic.oracle.db.gc_cr_block_received_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "GC CR block received per second", ms.At(i).Description())
					assert.Equal(t, "{blocks}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.gc_cr_block_received_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.db.gc_cr_block_received_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.db.gc_cr_block_received_per_transaction")
					validatedMetrics["newrelic.oracle.db.gc_cr_block_received_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "GC CR block received per transaction", ms.At(i).Description())
					assert.Equal(t, "{blocks}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.gc_current_block_received_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.gc_current_block_received_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.gc_current_block_received_per_second")
					validatedMetrics["newrelic.oracle.db.gc_current_block_received_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "GC current block received per second", ms.At(i).Description())
					assert.Equal(t, "{blocks}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.gc_current_block_received_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.db.gc_current_block_received_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.db.gc_current_block_received_per_transaction")
					validatedMetrics["newrelic.oracle.db.gc_current_block_received_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "GC current block received per transaction", ms.At(i).Description())
					assert.Equal(t, "{blocks}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.global_cache_average_cr_get_time":
					assert.False(t, validatedMetrics["newrelic.oracle.db.global_cache_average_cr_get_time"], "Found a duplicate in the metrics slice: newrelic.oracle.db.global_cache_average_cr_get_time")
					validatedMetrics["newrelic.oracle.db.global_cache_average_cr_get_time"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Global cache average CR get time", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.global_cache_average_current_get_time":
					assert.False(t, validatedMetrics["newrelic.oracle.db.global_cache_average_current_get_time"], "Found a duplicate in the metrics slice: newrelic.oracle.db.global_cache_average_current_get_time")
					validatedMetrics["newrelic.oracle.db.global_cache_average_current_get_time"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Global cache average current get time", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.hard_parse_count_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.hard_parse_count_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.hard_parse_count_per_second")
					validatedMetrics["newrelic.oracle.db.hard_parse_count_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Hard parse count per second", ms.At(i).Description())
					assert.Equal(t, "{parses}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.hard_parse_count_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.db.hard_parse_count_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.db.hard_parse_count_per_transaction")
					validatedMetrics["newrelic.oracle.db.hard_parse_count_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Hard parse count per transaction", ms.At(i).Description())
					assert.Equal(t, "{parses}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.host_cpu_usage_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.host_cpu_usage_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.host_cpu_usage_per_second")
					validatedMetrics["newrelic.oracle.db.host_cpu_usage_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Host CPU usage per second", ms.At(i).Description())
					assert.Equal(t, "{cpu}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.host_cpu_utilization":
					assert.False(t, validatedMetrics["newrelic.oracle.db.host_cpu_utilization"], "Found a duplicate in the metrics slice: newrelic.oracle.db.host_cpu_utilization")
					validatedMetrics["newrelic.oracle.db.host_cpu_utilization"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Host CPU utilization percentage", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.leaf_node_splits_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.leaf_node_splits_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.leaf_node_splits_per_second")
					validatedMetrics["newrelic.oracle.db.leaf_node_splits_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Leaf node splits per second", ms.At(i).Description())
					assert.Equal(t, "{splits}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.leaf_node_splits_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.db.leaf_node_splits_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.db.leaf_node_splits_per_transaction")
					validatedMetrics["newrelic.oracle.db.leaf_node_splits_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Leaf node splits per transaction", ms.At(i).Description())
					assert.Equal(t, "{splits}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.library_cache_hit_ratio":
					assert.False(t, validatedMetrics["newrelic.oracle.db.library_cache_hit_ratio"], "Found a duplicate in the metrics slice: newrelic.oracle.db.library_cache_hit_ratio")
					validatedMetrics["newrelic.oracle.db.library_cache_hit_ratio"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Library cache hit ratio", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.library_cache_miss_ratio":
					assert.False(t, validatedMetrics["newrelic.oracle.db.library_cache_miss_ratio"], "Found a duplicate in the metrics slice: newrelic.oracle.db.library_cache_miss_ratio")
					validatedMetrics["newrelic.oracle.db.library_cache_miss_ratio"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Library cache miss ratio", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.logical_reads_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.logical_reads_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.logical_reads_per_second")
					validatedMetrics["newrelic.oracle.db.logical_reads_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Logical reads per second", ms.At(i).Description())
					assert.Equal(t, "{reads}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.logical_reads_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.db.logical_reads_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.db.logical_reads_per_transaction")
					validatedMetrics["newrelic.oracle.db.logical_reads_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Logical reads per transaction", ms.At(i).Description())
					assert.Equal(t, "{reads}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.logons_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.logons_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.logons_per_second")
					validatedMetrics["newrelic.oracle.db.logons_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Logons per second", ms.At(i).Description())
					assert.Equal(t, "{logons}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.logons_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.db.logons_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.db.logons_per_transaction")
					validatedMetrics["newrelic.oracle.db.logons_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Logons per transaction", ms.At(i).Description())
					assert.Equal(t, "{logons}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.long_table_scans_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.long_table_scans_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.long_table_scans_per_second")
					validatedMetrics["newrelic.oracle.db.long_table_scans_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Long table scans per second", ms.At(i).Description())
					assert.Equal(t, "{scans}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.long_table_scans_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.db.long_table_scans_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.db.long_table_scans_per_transaction")
					validatedMetrics["newrelic.oracle.db.long_table_scans_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Long table scans per transaction", ms.At(i).Description())
					assert.Equal(t, "{scans}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.open_cursors_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.open_cursors_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.open_cursors_per_second")
					validatedMetrics["newrelic.oracle.db.open_cursors_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Open cursors per second", ms.At(i).Description())
					assert.Equal(t, "{cursors}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.open_cursors_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.db.open_cursors_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.db.open_cursors_per_transaction")
					validatedMetrics["newrelic.oracle.db.open_cursors_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Open cursors per transaction", ms.At(i).Description())
					assert.Equal(t, "{cursors}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.os_load":
					assert.False(t, validatedMetrics["newrelic.oracle.db.os_load"], "Found a duplicate in the metrics slice: newrelic.oracle.db.os_load")
					validatedMetrics["newrelic.oracle.db.os_load"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Current OS load", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.parse_failure_count_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.parse_failure_count_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.parse_failure_count_per_second")
					validatedMetrics["newrelic.oracle.db.parse_failure_count_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Parse failure count per second", ms.At(i).Description())
					assert.Equal(t, "{failures}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.parse_failure_count_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.db.parse_failure_count_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.db.parse_failure_count_per_transaction")
					validatedMetrics["newrelic.oracle.db.parse_failure_count_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Parse failure count per transaction", ms.At(i).Description())
					assert.Equal(t, "{failures}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.pga_cache_hit_percentage":
					assert.False(t, validatedMetrics["newrelic.oracle.db.pga_cache_hit_percentage"], "Found a duplicate in the metrics slice: newrelic.oracle.db.pga_cache_hit_percentage")
					validatedMetrics["newrelic.oracle.db.pga_cache_hit_percentage"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "PGA cache hit percentage", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.physical_read_bytes_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.physical_read_bytes_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.physical_read_bytes_per_second")
					validatedMetrics["newrelic.oracle.db.physical_read_bytes_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Physical read bytes per second", ms.At(i).Description())
					assert.Equal(t, "By/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.physical_read_io_requests_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.physical_read_io_requests_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.physical_read_io_requests_per_second")
					validatedMetrics["newrelic.oracle.db.physical_read_io_requests_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Physical read I/O requests per second", ms.At(i).Description())
					assert.Equal(t, "{requests}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.physical_reads_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.physical_reads_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.physical_reads_per_second")
					validatedMetrics["newrelic.oracle.db.physical_reads_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Physical reads per second", ms.At(i).Description())
					assert.Equal(t, "{reads}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.physical_write_bytes_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.physical_write_bytes_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.physical_write_bytes_per_second")
					validatedMetrics["newrelic.oracle.db.physical_write_bytes_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Physical write bytes per second", ms.At(i).Description())
					assert.Equal(t, "By/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.physical_writes_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.physical_writes_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.physical_writes_per_second")
					validatedMetrics["newrelic.oracle.db.physical_writes_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Physical writes per second", ms.At(i).Description())
					assert.Equal(t, "{writes}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.process_limit_percentage":
					assert.False(t, validatedMetrics["newrelic.oracle.db.process_limit_percentage"], "Found a duplicate in the metrics slice: newrelic.oracle.db.process_limit_percentage")
					validatedMetrics["newrelic.oracle.db.process_limit_percentage"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Process limit percentage", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.recursive_calls_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.recursive_calls_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.recursive_calls_per_second")
					validatedMetrics["newrelic.oracle.db.recursive_calls_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Recursive calls per second", ms.At(i).Description())
					assert.Equal(t, "{calls}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.recursive_calls_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.db.recursive_calls_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.db.recursive_calls_per_transaction")
					validatedMetrics["newrelic.oracle.db.recursive_calls_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Recursive calls per transaction", ms.At(i).Description())
					assert.Equal(t, "{calls}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.redo_writes_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.redo_writes_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.redo_writes_per_second")
					validatedMetrics["newrelic.oracle.db.redo_writes_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Redo writes per second", ms.At(i).Description())
					assert.Equal(t, "{writes}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.redo_writes_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.db.redo_writes_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.db.redo_writes_per_transaction")
					validatedMetrics["newrelic.oracle.db.redo_writes_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Redo writes per transaction", ms.At(i).Description())
					assert.Equal(t, "{writes}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.response_time_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.db.response_time_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.db.response_time_per_transaction")
					validatedMetrics["newrelic.oracle.db.response_time_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Response time per transaction", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.row_cache_hit_ratio":
					assert.False(t, validatedMetrics["newrelic.oracle.db.row_cache_hit_ratio"], "Found a duplicate in the metrics slice: newrelic.oracle.db.row_cache_hit_ratio")
					validatedMetrics["newrelic.oracle.db.row_cache_hit_ratio"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Row cache hit ratio", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.row_cache_miss_ratio":
					assert.False(t, validatedMetrics["newrelic.oracle.db.row_cache_miss_ratio"], "Found a duplicate in the metrics slice: newrelic.oracle.db.row_cache_miss_ratio")
					validatedMetrics["newrelic.oracle.db.row_cache_miss_ratio"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Row cache miss ratio", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.rows_per_sort":
					assert.False(t, validatedMetrics["newrelic.oracle.db.rows_per_sort"], "Found a duplicate in the metrics slice: newrelic.oracle.db.rows_per_sort")
					validatedMetrics["newrelic.oracle.db.rows_per_sort"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Rows per sort", ms.At(i).Description())
					assert.Equal(t, "{rows}/{sort}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.session_count":
					assert.False(t, validatedMetrics["newrelic.oracle.db.session_count"], "Found a duplicate in the metrics slice: newrelic.oracle.db.session_count")
					validatedMetrics["newrelic.oracle.db.session_count"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Session count", ms.At(i).Description())
					assert.Equal(t, "{sessions}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.db.session_limit_percentage":
					assert.False(t, validatedMetrics["newrelic.oracle.db.session_limit_percentage"], "Found a duplicate in the metrics slice: newrelic.oracle.db.session_limit_percentage")
					validatedMetrics["newrelic.oracle.db.session_limit_percentage"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Session limit percentage", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.shared_pool_free_percentage":
					assert.False(t, validatedMetrics["newrelic.oracle.db.shared_pool_free_percentage"], "Found a duplicate in the metrics slice: newrelic.oracle.db.shared_pool_free_percentage")
					validatedMetrics["newrelic.oracle.db.shared_pool_free_percentage"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Shared pool free percentage", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.soft_parse_ratio":
					assert.False(t, validatedMetrics["newrelic.oracle.db.soft_parse_ratio"], "Found a duplicate in the metrics slice: newrelic.oracle.db.soft_parse_ratio")
					validatedMetrics["newrelic.oracle.db.soft_parse_ratio"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Soft parse ratio", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.sorts_per_user_call":
					assert.False(t, validatedMetrics["newrelic.oracle.db.sorts_per_user_call"], "Found a duplicate in the metrics slice: newrelic.oracle.db.sorts_per_user_call")
					validatedMetrics["newrelic.oracle.db.sorts_per_user_call"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Total sorts per user call", ms.At(i).Description())
					assert.Equal(t, "{sorts}/{call}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.sql_service_response_time":
					assert.False(t, validatedMetrics["newrelic.oracle.db.sql_service_response_time"], "Found a duplicate in the metrics slice: newrelic.oracle.db.sql_service_response_time")
					validatedMetrics["newrelic.oracle.db.sql_service_response_time"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "SQL service response time", ms.At(i).Description())
					assert.Equal(t, "s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.streams_pool_usage_percentage":
					assert.False(t, validatedMetrics["newrelic.oracle.db.streams_pool_usage_percentage"], "Found a duplicate in the metrics slice: newrelic.oracle.db.streams_pool_usage_percentage")
					validatedMetrics["newrelic.oracle.db.streams_pool_usage_percentage"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Streams pool usage percentage", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.table_scans_per_user_call":
					assert.False(t, validatedMetrics["newrelic.oracle.db.table_scans_per_user_call"], "Found a duplicate in the metrics slice: newrelic.oracle.db.table_scans_per_user_call")
					validatedMetrics["newrelic.oracle.db.table_scans_per_user_call"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Total table scans per user call", ms.At(i).Description())
					assert.Equal(t, "{scans}/{call}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.total_index_scans_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.total_index_scans_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.total_index_scans_per_second")
					validatedMetrics["newrelic.oracle.db.total_index_scans_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Total index scans per second", ms.At(i).Description())
					assert.Equal(t, "{scans}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.total_index_scans_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.db.total_index_scans_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.db.total_index_scans_per_transaction")
					validatedMetrics["newrelic.oracle.db.total_index_scans_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Total index scans per transaction", ms.At(i).Description())
					assert.Equal(t, "{scans}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.total_parse_count_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.total_parse_count_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.total_parse_count_per_second")
					validatedMetrics["newrelic.oracle.db.total_parse_count_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Total parse count per second", ms.At(i).Description())
					assert.Equal(t, "{parses}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.total_parse_count_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.db.total_parse_count_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.db.total_parse_count_per_transaction")
					validatedMetrics["newrelic.oracle.db.total_parse_count_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Total parse count per transaction", ms.At(i).Description())
					assert.Equal(t, "{parses}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.total_table_scans_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.total_table_scans_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.total_table_scans_per_second")
					validatedMetrics["newrelic.oracle.db.total_table_scans_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Total table scans per second", ms.At(i).Description())
					assert.Equal(t, "{scans}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.total_table_scans_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.db.total_table_scans_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.db.total_table_scans_per_transaction")
					validatedMetrics["newrelic.oracle.db.total_table_scans_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Total table scans per transaction", ms.At(i).Description())
					assert.Equal(t, "{scans}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.transactions_per_logon":
					assert.False(t, validatedMetrics["newrelic.oracle.db.transactions_per_logon"], "Found a duplicate in the metrics slice: newrelic.oracle.db.transactions_per_logon")
					validatedMetrics["newrelic.oracle.db.transactions_per_logon"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Transactions per logon", ms.At(i).Description())
					assert.Equal(t, "{transactions}/{logon}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.user_calls_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.user_calls_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.user_calls_per_second")
					validatedMetrics["newrelic.oracle.db.user_calls_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "User calls per second", ms.At(i).Description())
					assert.Equal(t, "{calls}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.user_calls_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.db.user_calls_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.db.user_calls_per_transaction")
					validatedMetrics["newrelic.oracle.db.user_calls_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "User calls per transaction", ms.At(i).Description())
					assert.Equal(t, "{calls}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.user_calls_ratio":
					assert.False(t, validatedMetrics["newrelic.oracle.db.user_calls_ratio"], "Found a duplicate in the metrics slice: newrelic.oracle.db.user_calls_ratio")
					validatedMetrics["newrelic.oracle.db.user_calls_ratio"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "User calls ratio", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.user_commits_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.user_commits_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.user_commits_per_second")
					validatedMetrics["newrelic.oracle.db.user_commits_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "User commits per second", ms.At(i).Description())
					assert.Equal(t, "{commits}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.user_commits_percentage":
					assert.False(t, validatedMetrics["newrelic.oracle.db.user_commits_percentage"], "Found a duplicate in the metrics slice: newrelic.oracle.db.user_commits_percentage")
					validatedMetrics["newrelic.oracle.db.user_commits_percentage"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "User commits percentage", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.user_limit_percentage":
					assert.False(t, validatedMetrics["newrelic.oracle.db.user_limit_percentage"], "Found a duplicate in the metrics slice: newrelic.oracle.db.user_limit_percentage")
					validatedMetrics["newrelic.oracle.db.user_limit_percentage"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "User limit percentage", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.user_rollback_undo_records_applied_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.user_rollback_undo_records_applied_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.user_rollback_undo_records_applied_per_second")
					validatedMetrics["newrelic.oracle.db.user_rollback_undo_records_applied_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "User rollback undo records applied per second", ms.At(i).Description())
					assert.Equal(t, "{records}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.user_rollback_undo_records_applied_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.db.user_rollback_undo_records_applied_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.db.user_rollback_undo_records_applied_per_transaction")
					validatedMetrics["newrelic.oracle.db.user_rollback_undo_records_applied_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "User rollback undo records applied per transaction", ms.At(i).Description())
					assert.Equal(t, "{records}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.user_rollbacks_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.db.user_rollbacks_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.db.user_rollbacks_per_second")
					validatedMetrics["newrelic.oracle.db.user_rollbacks_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "User rollbacks per second", ms.At(i).Description())
					assert.Equal(t, "{rollbacks}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.user_rollbacks_percentage":
					assert.False(t, validatedMetrics["newrelic.oracle.db.user_rollbacks_percentage"], "Found a duplicate in the metrics slice: newrelic.oracle.db.user_rollbacks_percentage")
					validatedMetrics["newrelic.oracle.db.user_rollbacks_percentage"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "User rollbacks percentage", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.db.wait_time_ratio":
					assert.False(t, validatedMetrics["newrelic.oracle.db.wait_time_ratio"], "Found a duplicate in the metrics slice: newrelic.oracle.db.wait_time_ratio")
					validatedMetrics["newrelic.oracle.db.wait_time_ratio"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Database wait time ratio", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.disk.blocks_read":
					assert.False(t, validatedMetrics["newrelic.oracle.disk.blocks_read"], "Found a duplicate in the metrics slice: newrelic.oracle.disk.blocks_read")
					validatedMetrics["newrelic.oracle.disk.blocks_read"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Physical blocks read", ms.At(i).Description())
					assert.Equal(t, "{blocks}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.disk.blocks_written":
					assert.False(t, validatedMetrics["newrelic.oracle.disk.blocks_written"], "Found a duplicate in the metrics slice: newrelic.oracle.disk.blocks_written")
					validatedMetrics["newrelic.oracle.disk.blocks_written"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Physical blocks written", ms.At(i).Description())
					assert.Equal(t, "{blocks}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.disk.logical_reads_per_user_call":
					assert.False(t, validatedMetrics["newrelic.oracle.disk.logical_reads_per_user_call"], "Found a duplicate in the metrics slice: newrelic.oracle.disk.logical_reads_per_user_call")
					validatedMetrics["newrelic.oracle.disk.logical_reads_per_user_call"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Logical reads per user call", ms.At(i).Description())
					assert.Equal(t, "{reads}/{call}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.disk.physical_lobs_reads_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.disk.physical_lobs_reads_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.disk.physical_lobs_reads_per_second")
					validatedMetrics["newrelic.oracle.disk.physical_lobs_reads_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Physical LOB reads per second", ms.At(i).Description())
					assert.Equal(t, "{reads}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.disk.physical_lobs_writes_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.disk.physical_lobs_writes_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.disk.physical_lobs_writes_per_second")
					validatedMetrics["newrelic.oracle.disk.physical_lobs_writes_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Physical LOB writes per second", ms.At(i).Description())
					assert.Equal(t, "{writes}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.disk.physical_read_bytes_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.disk.physical_read_bytes_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.disk.physical_read_bytes_per_second")
					validatedMetrics["newrelic.oracle.disk.physical_read_bytes_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Physical read bytes per second", ms.At(i).Description())
					assert.Equal(t, "By/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.disk.physical_read_io_requests_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.disk.physical_read_io_requests_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.disk.physical_read_io_requests_per_second")
					validatedMetrics["newrelic.oracle.disk.physical_read_io_requests_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Physical read I/O requests per second", ms.At(i).Description())
					assert.Equal(t, "{requests}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.disk.physical_reads_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.disk.physical_reads_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.disk.physical_reads_per_second")
					validatedMetrics["newrelic.oracle.disk.physical_reads_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Physical reads per second", ms.At(i).Description())
					assert.Equal(t, "{reads}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.disk.physical_write_bytes_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.disk.physical_write_bytes_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.disk.physical_write_bytes_per_second")
					validatedMetrics["newrelic.oracle.disk.physical_write_bytes_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Physical write bytes per second", ms.At(i).Description())
					assert.Equal(t, "By/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.disk.physical_write_total_io_requests_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.disk.physical_write_total_io_requests_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.disk.physical_write_total_io_requests_per_second")
					validatedMetrics["newrelic.oracle.disk.physical_write_total_io_requests_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Physical write total I/O requests per second", ms.At(i).Description())
					assert.Equal(t, "{requests}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.disk.physical_writes_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.disk.physical_writes_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.disk.physical_writes_per_second")
					validatedMetrics["newrelic.oracle.disk.physical_writes_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Physical writes per second", ms.At(i).Description())
					assert.Equal(t, "{writes}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.disk.read_time_milliseconds":
					assert.False(t, validatedMetrics["newrelic.oracle.disk.read_time_milliseconds"], "Found a duplicate in the metrics slice: newrelic.oracle.disk.read_time_milliseconds")
					validatedMetrics["newrelic.oracle.disk.read_time_milliseconds"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Disk read time in milliseconds", ms.At(i).Description())
					assert.Equal(t, "ms", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.disk.reads":
					assert.False(t, validatedMetrics["newrelic.oracle.disk.reads"], "Found a duplicate in the metrics slice: newrelic.oracle.disk.reads")
					validatedMetrics["newrelic.oracle.disk.reads"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Physical disk reads", ms.At(i).Description())
					assert.Equal(t, "{reads}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.disk.sort_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.disk.sort_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.disk.sort_per_second")
					validatedMetrics["newrelic.oracle.disk.sort_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Disk sorts per second", ms.At(i).Description())
					assert.Equal(t, "{sorts}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.disk.sort_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.disk.sort_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.disk.sort_per_transaction")
					validatedMetrics["newrelic.oracle.disk.sort_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Disk sorts per transaction", ms.At(i).Description())
					assert.Equal(t, "{sorts}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.disk.temp_space_used_bytes":
					assert.False(t, validatedMetrics["newrelic.oracle.disk.temp_space_used_bytes"], "Found a duplicate in the metrics slice: newrelic.oracle.disk.temp_space_used_bytes")
					validatedMetrics["newrelic.oracle.disk.temp_space_used_bytes"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Temporary space used in bytes", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.disk.write_time_milliseconds":
					assert.False(t, validatedMetrics["newrelic.oracle.disk.write_time_milliseconds"], "Found a duplicate in the metrics slice: newrelic.oracle.disk.write_time_milliseconds")
					validatedMetrics["newrelic.oracle.disk.write_time_milliseconds"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Disk write time in milliseconds", ms.At(i).Description())
					assert.Equal(t, "ms", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.disk.writes":
					assert.False(t, validatedMetrics["newrelic.oracle.disk.writes"], "Found a duplicate in the metrics slice: newrelic.oracle.disk.writes")
					validatedMetrics["newrelic.oracle.disk.writes"] = true
					assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
					assert.Equal(t, "Physical disk writes", ms.At(i).Description())
					assert.Equal(t, "{writes}", ms.At(i).Unit())
					assert.True(t, ms.At(i).Sum().IsMonotonic())
					assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
					dp := ms.At(i).Sum().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.locked_accounts":
					assert.False(t, validatedMetrics["newrelic.oracle.locked_accounts"], "Found a duplicate in the metrics slice: newrelic.oracle.locked_accounts")
					validatedMetrics["newrelic.oracle.locked_accounts"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of locked user accounts", ms.At(i).Description())
					assert.Equal(t, "{accounts}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("instance_id")
					assert.True(t, ok)
					assert.Equal(t, "instance_id-val", attrVal.Str())
				case "newrelic.oracle.long_running_queries":
					assert.False(t, validatedMetrics["newrelic.oracle.long_running_queries"], "Found a duplicate in the metrics slice: newrelic.oracle.long_running_queries")
					validatedMetrics["newrelic.oracle.long_running_queries"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of long running queries (> 60 seconds)", ms.At(i).Description())
					assert.Equal(t, "{queries}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("instance_id")
					assert.True(t, ok)
					assert.Equal(t, "instance_id-val", attrVal.Str())
				case "newrelic.oracle.memory.buffer_cache_hit_ratio":
					assert.False(t, validatedMetrics["newrelic.oracle.memory.buffer_cache_hit_ratio"], "Found a duplicate in the metrics slice: newrelic.oracle.memory.buffer_cache_hit_ratio")
					validatedMetrics["newrelic.oracle.memory.buffer_cache_hit_ratio"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Buffer cache hit ratio", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.memory.global_cache_blocks_corrupted":
					assert.False(t, validatedMetrics["newrelic.oracle.memory.global_cache_blocks_corrupted"], "Found a duplicate in the metrics slice: newrelic.oracle.memory.global_cache_blocks_corrupted")
					validatedMetrics["newrelic.oracle.memory.global_cache_blocks_corrupted"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Global cache blocks corrupted", ms.At(i).Description())
					assert.Equal(t, "{blocks}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.memory.global_cache_blocks_lost":
					assert.False(t, validatedMetrics["newrelic.oracle.memory.global_cache_blocks_lost"], "Found a duplicate in the metrics slice: newrelic.oracle.memory.global_cache_blocks_lost")
					validatedMetrics["newrelic.oracle.memory.global_cache_blocks_lost"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Global cache blocks lost", ms.At(i).Description())
					assert.Equal(t, "{blocks}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.memory.pga_allocated_bytes":
					assert.False(t, validatedMetrics["newrelic.oracle.memory.pga_allocated_bytes"], "Found a duplicate in the metrics slice: newrelic.oracle.memory.pga_allocated_bytes")
					validatedMetrics["newrelic.oracle.memory.pga_allocated_bytes"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "PGA memory allocated in bytes", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.memory.pga_freeable_bytes":
					assert.False(t, validatedMetrics["newrelic.oracle.memory.pga_freeable_bytes"], "Found a duplicate in the metrics slice: newrelic.oracle.memory.pga_freeable_bytes")
					validatedMetrics["newrelic.oracle.memory.pga_freeable_bytes"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "PGA freeable memory in bytes", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.memory.pga_in_use_bytes":
					assert.False(t, validatedMetrics["newrelic.oracle.memory.pga_in_use_bytes"], "Found a duplicate in the metrics slice: newrelic.oracle.memory.pga_in_use_bytes")
					validatedMetrics["newrelic.oracle.memory.pga_in_use_bytes"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "PGA memory in use in bytes", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.memory.pga_max_size_bytes":
					assert.False(t, validatedMetrics["newrelic.oracle.memory.pga_max_size_bytes"], "Found a duplicate in the metrics slice: newrelic.oracle.memory.pga_max_size_bytes")
					validatedMetrics["newrelic.oracle.memory.pga_max_size_bytes"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "PGA maximum size in bytes", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.memory.redo_allocation_hit_ratio":
					assert.False(t, validatedMetrics["newrelic.oracle.memory.redo_allocation_hit_ratio"], "Found a duplicate in the metrics slice: newrelic.oracle.memory.redo_allocation_hit_ratio")
					validatedMetrics["newrelic.oracle.memory.redo_allocation_hit_ratio"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Redo allocation hit ratio", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.memory.redo_generated_bytes_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.memory.redo_generated_bytes_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.memory.redo_generated_bytes_per_second")
					validatedMetrics["newrelic.oracle.memory.redo_generated_bytes_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Redo generated bytes per second", ms.At(i).Description())
					assert.Equal(t, "By/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.memory.redo_generated_bytes_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.memory.redo_generated_bytes_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.memory.redo_generated_bytes_per_transaction")
					validatedMetrics["newrelic.oracle.memory.redo_generated_bytes_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Redo generated bytes per transaction", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.memory.sorts_ratio":
					assert.False(t, validatedMetrics["newrelic.oracle.memory.sorts_ratio"], "Found a duplicate in the metrics slice: newrelic.oracle.memory.sorts_ratio")
					validatedMetrics["newrelic.oracle.memory.sorts_ratio"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Memory sorts ratio", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.network.io_megabytes_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.network.io_megabytes_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.network.io_megabytes_per_second")
					validatedMetrics["newrelic.oracle.network.io_megabytes_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "I/O megabytes per second", ms.At(i).Description())
					assert.Equal(t, "MBy/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.network.io_requests_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.network.io_requests_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.network.io_requests_per_second")
					validatedMetrics["newrelic.oracle.network.io_requests_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "I/O requests per second", ms.At(i).Description())
					assert.Equal(t, "{requests}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.network.traffic_bytes_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.network.traffic_bytes_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.network.traffic_bytes_per_second")
					validatedMetrics["newrelic.oracle.network.traffic_bytes_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Network traffic volume per second", ms.At(i).Description())
					assert.Equal(t, "By/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.query.physical_lobs_reads_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.query.physical_lobs_reads_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.query.physical_lobs_reads_per_transaction")
					validatedMetrics["newrelic.oracle.query.physical_lobs_reads_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Physical LOB reads per transaction", ms.At(i).Description())
					assert.Equal(t, "{reads}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.query.physical_lobs_writes_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.query.physical_lobs_writes_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.query.physical_lobs_writes_per_transaction")
					validatedMetrics["newrelic.oracle.query.physical_lobs_writes_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Physical LOB writes per transaction", ms.At(i).Description())
					assert.Equal(t, "{writes}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.query.physical_reads_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.query.physical_reads_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.query.physical_reads_per_transaction")
					validatedMetrics["newrelic.oracle.query.physical_reads_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Physical reads per transaction", ms.At(i).Description())
					assert.Equal(t, "{reads}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.query.physical_writes_per_transaction":
					assert.False(t, validatedMetrics["newrelic.oracle.query.physical_writes_per_transaction"], "Found a duplicate in the metrics slice: newrelic.oracle.query.physical_writes_per_transaction")
					validatedMetrics["newrelic.oracle.query.physical_writes_per_transaction"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Physical writes per transaction", ms.At(i).Description())
					assert.Equal(t, "{writes}/{transaction}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.query.transactions_per_second":
					assert.False(t, validatedMetrics["newrelic.oracle.query.transactions_per_second"], "Found a duplicate in the metrics slice: newrelic.oracle.query.transactions_per_second")
					validatedMetrics["newrelic.oracle.query.transactions_per_second"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "User transactions per second", ms.At(i).Description())
					assert.Equal(t, "{transactions}/s", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.redo_log.file_switch":
					assert.False(t, validatedMetrics["newrelic.oracle.redo_log.file_switch"], "Found a duplicate in the metrics slice: newrelic.oracle.redo_log.file_switch")
					validatedMetrics["newrelic.oracle.redo_log.file_switch"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Log file switch completion", ms.At(i).Description())
					assert.Equal(t, "{switches}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.redo_log.file_switch_archiving_needed":
					assert.False(t, validatedMetrics["newrelic.oracle.redo_log.file_switch_archiving_needed"], "Found a duplicate in the metrics slice: newrelic.oracle.redo_log.file_switch_archiving_needed")
					validatedMetrics["newrelic.oracle.redo_log.file_switch_archiving_needed"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Log file switch due to archiving needed", ms.At(i).Description())
					assert.Equal(t, "{switches}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.redo_log.file_switch_checkpoint_incomplete":
					assert.False(t, validatedMetrics["newrelic.oracle.redo_log.file_switch_checkpoint_incomplete"], "Found a duplicate in the metrics slice: newrelic.oracle.redo_log.file_switch_checkpoint_incomplete")
					validatedMetrics["newrelic.oracle.redo_log.file_switch_checkpoint_incomplete"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Log file switch due to checkpoint incomplete", ms.At(i).Description())
					assert.Equal(t, "{switches}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.redo_log.waits":
					assert.False(t, validatedMetrics["newrelic.oracle.redo_log.waits"], "Found a duplicate in the metrics slice: newrelic.oracle.redo_log.waits")
					validatedMetrics["newrelic.oracle.redo_log.waits"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Redo log waits", ms.At(i).Description())
					assert.Equal(t, "{waits}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.rollback_segments.gets":
					assert.False(t, validatedMetrics["newrelic.oracle.rollback_segments.gets"], "Found a duplicate in the metrics slice: newrelic.oracle.rollback_segments.gets")
					validatedMetrics["newrelic.oracle.rollback_segments.gets"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Rollback segment gets", ms.At(i).Description())
					assert.Equal(t, "{gets}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.rollback_segments.ratio_wait":
					assert.False(t, validatedMetrics["newrelic.oracle.rollback_segments.ratio_wait"], "Found a duplicate in the metrics slice: newrelic.oracle.rollback_segments.ratio_wait")
					validatedMetrics["newrelic.oracle.rollback_segments.ratio_wait"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Rollback segment wait ratio", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.rollback_segments.waits":
					assert.False(t, validatedMetrics["newrelic.oracle.rollback_segments.waits"], "Found a duplicate in the metrics slice: newrelic.oracle.rollback_segments.waits")
					validatedMetrics["newrelic.oracle.rollback_segments.waits"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Rollback segment waits", ms.At(i).Description())
					assert.Equal(t, "{waits}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.sga.buffer_busy_waits":
					assert.False(t, validatedMetrics["newrelic.oracle.sga.buffer_busy_waits"], "Found a duplicate in the metrics slice: newrelic.oracle.sga.buffer_busy_waits")
					validatedMetrics["newrelic.oracle.sga.buffer_busy_waits"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Buffer busy waits", ms.At(i).Description())
					assert.Equal(t, "{waits}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.sga.fixed_size_bytes":
					assert.False(t, validatedMetrics["newrelic.oracle.sga.fixed_size_bytes"], "Found a duplicate in the metrics slice: newrelic.oracle.sga.fixed_size_bytes")
					validatedMetrics["newrelic.oracle.sga.fixed_size_bytes"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "SGA fixed size area in bytes", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.sga.free_buffer_inspected":
					assert.False(t, validatedMetrics["newrelic.oracle.sga.free_buffer_inspected"], "Found a duplicate in the metrics slice: newrelic.oracle.sga.free_buffer_inspected")
					validatedMetrics["newrelic.oracle.sga.free_buffer_inspected"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Free buffer inspected", ms.At(i).Description())
					assert.Equal(t, "{buffers}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.sga.free_buffer_waits":
					assert.False(t, validatedMetrics["newrelic.oracle.sga.free_buffer_waits"], "Found a duplicate in the metrics slice: newrelic.oracle.sga.free_buffer_waits")
					validatedMetrics["newrelic.oracle.sga.free_buffer_waits"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Free buffer waits", ms.At(i).Description())
					assert.Equal(t, "{waits}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.sga.hit_ratio":
					assert.False(t, validatedMetrics["newrelic.oracle.sga.hit_ratio"], "Found a duplicate in the metrics slice: newrelic.oracle.sga.hit_ratio")
					validatedMetrics["newrelic.oracle.sga.hit_ratio"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "SGA buffer cache hit ratio", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.sga.log_buffer_allocation_retries_ratio":
					assert.False(t, validatedMetrics["newrelic.oracle.sga.log_buffer_allocation_retries_ratio"], "Found a duplicate in the metrics slice: newrelic.oracle.sga.log_buffer_allocation_retries_ratio")
					validatedMetrics["newrelic.oracle.sga.log_buffer_allocation_retries_ratio"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Log buffer allocation retries ratio", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.sga.log_buffer_redo_allocation_retries":
					assert.False(t, validatedMetrics["newrelic.oracle.sga.log_buffer_redo_allocation_retries"], "Found a duplicate in the metrics slice: newrelic.oracle.sga.log_buffer_redo_allocation_retries")
					validatedMetrics["newrelic.oracle.sga.log_buffer_redo_allocation_retries"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Log buffer redo allocation retries", ms.At(i).Description())
					assert.Equal(t, "{retries}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.sga.log_buffer_redo_entries":
					assert.False(t, validatedMetrics["newrelic.oracle.sga.log_buffer_redo_entries"], "Found a duplicate in the metrics slice: newrelic.oracle.sga.log_buffer_redo_entries")
					validatedMetrics["newrelic.oracle.sga.log_buffer_redo_entries"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Log buffer redo entries", ms.At(i).Description())
					assert.Equal(t, "{entries}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.sga.log_buffer_space_waits":
					assert.False(t, validatedMetrics["newrelic.oracle.sga.log_buffer_space_waits"], "Found a duplicate in the metrics slice: newrelic.oracle.sga.log_buffer_space_waits")
					validatedMetrics["newrelic.oracle.sga.log_buffer_space_waits"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of log buffer space waits", ms.At(i).Description())
					assert.Equal(t, "{waits}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.sga.redo_buffers_bytes":
					assert.False(t, validatedMetrics["newrelic.oracle.sga.redo_buffers_bytes"], "Found a duplicate in the metrics slice: newrelic.oracle.sga.redo_buffers_bytes")
					validatedMetrics["newrelic.oracle.sga.redo_buffers_bytes"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "SGA redo buffers size in bytes", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.sga.shared_pool_dict_cache_miss_ratio":
					assert.False(t, validatedMetrics["newrelic.oracle.sga.shared_pool_dict_cache_miss_ratio"], "Found a duplicate in the metrics slice: newrelic.oracle.sga.shared_pool_dict_cache_miss_ratio")
					validatedMetrics["newrelic.oracle.sga.shared_pool_dict_cache_miss_ratio"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Shared pool dictionary cache miss ratio", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.sga.shared_pool_library_cache_hit_ratio":
					assert.False(t, validatedMetrics["newrelic.oracle.sga.shared_pool_library_cache_hit_ratio"], "Found a duplicate in the metrics slice: newrelic.oracle.sga.shared_pool_library_cache_hit_ratio")
					validatedMetrics["newrelic.oracle.sga.shared_pool_library_cache_hit_ratio"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Shared pool library cache hit ratio", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.sga.shared_pool_library_cache_reload_ratio":
					assert.False(t, validatedMetrics["newrelic.oracle.sga.shared_pool_library_cache_reload_ratio"], "Found a duplicate in the metrics slice: newrelic.oracle.sga.shared_pool_library_cache_reload_ratio")
					validatedMetrics["newrelic.oracle.sga.shared_pool_library_cache_reload_ratio"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Shared pool library cache reload ratio", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
				case "newrelic.oracle.sga.shared_pool_library_cache_shareable_memory_per_statement_bytes":
					assert.False(t, validatedMetrics["newrelic.oracle.sga.shared_pool_library_cache_shareable_memory_per_statement_bytes"], "Found a duplicate in the metrics slice: newrelic.oracle.sga.shared_pool_library_cache_shareable_memory_per_statement_bytes")
					validatedMetrics["newrelic.oracle.sga.shared_pool_library_cache_shareable_memory_per_statement_bytes"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Shared pool library cache shareable memory per statement in bytes", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.sga.shared_pool_library_cache_shareable_memory_per_user_bytes":
					assert.False(t, validatedMetrics["newrelic.oracle.sga.shared_pool_library_cache_shareable_memory_per_user_bytes"], "Found a duplicate in the metrics slice: newrelic.oracle.sga.shared_pool_library_cache_shareable_memory_per_user_bytes")
					validatedMetrics["newrelic.oracle.sga.shared_pool_library_cache_shareable_memory_per_user_bytes"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Shared pool library cache shareable memory per user in bytes", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.sga.uga_total_memory_bytes":
					assert.False(t, validatedMetrics["newrelic.oracle.sga.uga_total_memory_bytes"], "Found a duplicate in the metrics slice: newrelic.oracle.sga.uga_total_memory_bytes")
					validatedMetrics["newrelic.oracle.sga.uga_total_memory_bytes"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "UGA total memory in bytes", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.sorts.disk_bytes":
					assert.False(t, validatedMetrics["newrelic.oracle.sorts.disk_bytes"], "Found a duplicate in the metrics slice: newrelic.oracle.sorts.disk_bytes")
					validatedMetrics["newrelic.oracle.sorts.disk_bytes"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Sorts performed on disk in bytes", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.sorts.memory_bytes":
					assert.False(t, validatedMetrics["newrelic.oracle.sorts.memory_bytes"], "Found a duplicate in the metrics slice: newrelic.oracle.sorts.memory_bytes")
					validatedMetrics["newrelic.oracle.sorts.memory_bytes"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Sorts performed in memory in bytes", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
				case "newrelic.oracle.tablespace.is_offline":
					assert.False(t, validatedMetrics["newrelic.oracle.tablespace.is_offline"], "Found a duplicate in the metrics slice: newrelic.oracle.tablespace.is_offline")
					validatedMetrics["newrelic.oracle.tablespace.is_offline"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Tablespace offline status (1 if offline, 0 if online)", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("tablespace_name")
					assert.True(t, ok)
					assert.Equal(t, "tablespace_name-val", attrVal.Str())
				case "newrelic.oracle.tablespace.offline_cdb_datafiles":
					assert.False(t, validatedMetrics["newrelic.oracle.tablespace.offline_cdb_datafiles"], "Found a duplicate in the metrics slice: newrelic.oracle.tablespace.offline_cdb_datafiles")
					validatedMetrics["newrelic.oracle.tablespace.offline_cdb_datafiles"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of offline CDB datafiles in tablespace", ms.At(i).Description())
					assert.Equal(t, "{datafiles}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("tablespace_name")
					assert.True(t, ok)
					assert.Equal(t, "tablespace_name-val", attrVal.Str())
				case "newrelic.oracle.tablespace.offline_pdb_datafiles":
					assert.False(t, validatedMetrics["newrelic.oracle.tablespace.offline_pdb_datafiles"], "Found a duplicate in the metrics slice: newrelic.oracle.tablespace.offline_pdb_datafiles")
					validatedMetrics["newrelic.oracle.tablespace.offline_pdb_datafiles"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of offline PDB datafiles in tablespace", ms.At(i).Description())
					assert.Equal(t, "{datafiles}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("tablespace_name")
					assert.True(t, ok)
					assert.Equal(t, "tablespace_name-val", attrVal.Str())
				case "newrelic.oracle.tablespace.pdb_datafiles_non_write":
					assert.False(t, validatedMetrics["newrelic.oracle.tablespace.pdb_datafiles_non_write"], "Found a duplicate in the metrics slice: newrelic.oracle.tablespace.pdb_datafiles_non_write")
					validatedMetrics["newrelic.oracle.tablespace.pdb_datafiles_non_write"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Number of PDB datafiles in non-write mode in tablespace", ms.At(i).Description())
					assert.Equal(t, "{datafiles}", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("tablespace_name")
					assert.True(t, ok)
					assert.Equal(t, "tablespace_name-val", attrVal.Str())
				case "newrelic.oracle.tablespace.space_consumed_bytes":
					assert.False(t, validatedMetrics["newrelic.oracle.tablespace.space_consumed_bytes"], "Found a duplicate in the metrics slice: newrelic.oracle.tablespace.space_consumed_bytes")
					validatedMetrics["newrelic.oracle.tablespace.space_consumed_bytes"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Tablespace space consumed in bytes", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("tablespace_name")
					assert.True(t, ok)
					assert.Equal(t, "tablespace_name-val", attrVal.Str())
				case "newrelic.oracle.tablespace.space_reserved_bytes":
					assert.False(t, validatedMetrics["newrelic.oracle.tablespace.space_reserved_bytes"], "Found a duplicate in the metrics slice: newrelic.oracle.tablespace.space_reserved_bytes")
					validatedMetrics["newrelic.oracle.tablespace.space_reserved_bytes"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Tablespace space reserved in bytes", ms.At(i).Description())
					assert.Equal(t, "By", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
					assert.Equal(t, int64(1), dp.IntValue())
					attrVal, ok := dp.Attributes().Get("tablespace_name")
					assert.True(t, ok)
					assert.Equal(t, "tablespace_name-val", attrVal.Str())
				case "newrelic.oracle.tablespace.space_used_percentage":
					assert.False(t, validatedMetrics["newrelic.oracle.tablespace.space_used_percentage"], "Found a duplicate in the metrics slice: newrelic.oracle.tablespace.space_used_percentage")
					validatedMetrics["newrelic.oracle.tablespace.space_used_percentage"] = true
					assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
					assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
					assert.Equal(t, "Tablespace space used percentage", ms.At(i).Description())
					assert.Equal(t, "1", ms.At(i).Unit())
					dp := ms.At(i).Gauge().DataPoints().At(0)
					assert.Equal(t, start, dp.StartTimestamp())
					assert.Equal(t, ts, dp.Timestamp())
					assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
					assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					attrVal, ok := dp.Attributes().Get("tablespace_name")
					assert.True(t, ok)
					assert.Equal(t, "tablespace_name-val", attrVal.Str())
				}
			}
		})
	}
}
